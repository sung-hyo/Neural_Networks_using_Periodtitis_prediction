{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Networks_Dentistry_20181124.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "uYAZ9sCpWI6Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 국민건강영양조사 자료 중 구강검사데이터셋\n",
        "---\n",
        "출처 : https://knhanes.cdc.go.kr/knhanes/main.do\n",
        "   "
      ]
    },
    {
      "metadata": {
        "id": "falgM_6DWI6a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. 구강검사(검진조사) \n",
        " - 질병관리본부에서 수행중인 국민건강양영조사 중 구강검진조사 데이터이다\n",
        " - 매년 만 1세 이상을 대상으로 치아와 보철물 상태, 치주조직 상태, 칫솔질 실천을 포함한 구강건강관련 행태의 자료를 수집하고 있다.\n",
        " - 구강검진은 구강설문조사, 치아상태, 치주조직검사로 이루어져 있다. \n",
        " - 공중보건치과의를 선발하여 교육훈련과정을 이수한 조사원이 구강검진을 수행한다. \n",
        "\n",
        "<center>![구강검진](https://github.com/sung-hyo/Neural_Networks_using_Periodtitis_prediction/blob/master/%EA%B5%AC%EA%B0%95%EA%B2%80%EC%A7%84%EA%B3%BC%EC%A0%95.png?raw=1)</center>\n",
        "<출처: 국민건강영양조사 조사수행지침>"
      ]
    },
    {
      "metadata": {
        "id": "CPZJJ6PYWI6b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 1.1 치아상태\n",
        "----\n",
        "각 치아번호마다 아래의 값으로 코딩한다.\n",
        "\n",
        "0. 건전치면\n",
        "1. 우식치면\n",
        "3. 우식경험처치치면\n",
        "4. 우식경험상실치면\n",
        "5. 우식비경험상실치면\n",
        "6. 전색치면\n",
        "7. 우식비경험처치치면\n",
        "8. 미맹출치면\n",
        "9. 기록불가치면\n",
        "![구강검진](https://github.com/sung-hyo/Neural_Networks_using_Periodtitis_prediction/blob/master/%EA%B5%AC%EA%B0%95%EA%B2%80%EC%A7%84.png?raw=1) \n",
        "<출처: 국민건강영양조사 조사수행지침>"
      ]
    },
    {
      "metadata": {
        "id": "LDrtFs6ZWI6d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 1.2. 치주질환\n",
        "---\n",
        " - 치주질환(또는 치주병, 치주염)은 세균에 의해 발생되는 치아주위 잇몸의 염증성 질환으로 치주인대와 잇몸뼈의 파괴를 일으킨다.\n",
        " - \n",
        " \n",
        "![치주염](https://github.com/sung-hyo/Neural_Networks_using_Periodtitis_prediction/blob/master/periodontitis.png?raw=1)\n",
        "<출처: 대한치주과학회, http://www.kperio.org/patient/disease.php>\n",
        "\n",
        "\n",
        "![치주탐침](https://github.com/sung-hyo/Neural_Networks_using_Periodtitis_prediction/blob/master/cpi_probe.png?raw=1)\n",
        "<출처: 국민건강영양조사 조사수행지침>\n",
        "\n",
        " - 치주탐침을 잇몸에 찔러서 잇몸뼈의 위치까지 얼마나 깊이 들어가는지와 출혈을 관찰한다.\n",
        "![치주낭검사](https://github.com/sung-hyo/Neural_Networks_using_Periodtitis_prediction/blob/master/%EC%B9%98%EC%A3%BC%EB%82%AD%EA%B2%80%EC%82%AC.png?raw=1)\n",
        "<출처: 대한치주과학회, http://www.kperio.org/patient/disease.php>\n",
        "\n",
        "\n",
        " - 치주질환은 국민건강영양조사 구강건강실태 조사방법에 따라 지역사회치주지수(Community Periodontal Index, CPI)를 이용하여 치과의사가 시진과 촉진으로 검진한다.\n",
        " - 만 19세 이상의 대상자의 구강 내 6분악 중 검사표준 치아 상·하악의 좌·우측 제 1,2 대구치, 상악 우측 중절치, 하악 좌측 중절치를 치주 탐침 시 치주낭 깊이가 4 mm 이상 보유자를 치주질환자로 분류한다\n",
        " - 데이터셋의 치주조직상태 변수인 O_CPI_UR, O_CPI_UM, O_CPI_UL, O_CPI_LL으로 산출한 지표이다."
      ]
    },
    {
      "metadata": {
        "id": "R2XXFYOLWI6e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 신경망 학습 목적\n",
        "---\n",
        "    치주질환을 검사하기 위한 치주낭 측정기(periodonal probe)를 치아에 찌르게 되면 출혈(이상이 있을 경우)과 통증이 유발된다. 또한 모든 치아를 검사해야 하는데 이는 시간소모가 많고 힘든 작업으로 알려져 있다. 주기적인 엑스레이 검사와 치주낭 측정 검사를 해야 사전에 치료가 가능하지만 주기적으로 하기 힘든게 현실이다. 치아 상태를 이용하여 치주질환을 분류하고자 한다. "
      ]
    },
    {
      "metadata": {
        "id": "C1kZyjKcP8t3",
        "colab_type": "code",
        "outputId": "a87374d6-c075-4ea8-dab1-38dc6919a430",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pydrive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydrive\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e0/0e64788e5dd58ce2d6934549676243dc69d982f198524be9b99e9c2a4fd5/PyDrive-1.3.1.tar.gz (987kB)\n",
            "\u001b[K    100% |████████████████████████████████| 993kB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.6.7)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.11.3)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.11.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.4)\n",
            "Building wheels for collected packages: pydrive\n",
            "  Running setup.py bdist_wheel for pydrive ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/fa/d2/9a/d3b6b506c2da98289e5d417215ce34b696db856643bad779f4\n",
            "Successfully built pydrive\n",
            "Installing collected packages: pydrive\n",
            "Successfully installed pydrive-1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Mly3ac9oWbJw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xqFXFIkUWkhi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "gauth = GoogleAuth()\n",
        "\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "file_id = '1f0YFEA4tWK2gRUdSLktDCtoV8pjHkJZo'\n",
        "\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "\n",
        "downloaded.GetContentFile('hn_dental_adj.sas7bdat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vrrgyjGyWI6f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "dt_raw = pd.read_sas('hn_dental_adj.sas7bdat', format='sas7bdat').dropna() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iu82Az51WI6l",
        "colab_type": "code",
        "outputId": "baea7578-0805-4b24-837e-8b2785ea5982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "cell_type": "code",
      "source": [
        "dt_raw.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>O_DIP</th>\n",
              "      <th>O_55B</th>\n",
              "      <th>O_55D</th>\n",
              "      <th>O_55O</th>\n",
              "      <th>O_55M</th>\n",
              "      <th>O_55L</th>\n",
              "      <th>O_54B</th>\n",
              "      <th>...</th>\n",
              "      <th>O_TN73</th>\n",
              "      <th>O_TN74</th>\n",
              "      <th>O_TN75</th>\n",
              "      <th>O_CPI_UR</th>\n",
              "      <th>O_CPI_UM</th>\n",
              "      <th>O_CPI_UL</th>\n",
              "      <th>O_CPI_LR</th>\n",
              "      <th>O_CPI_LM</th>\n",
              "      <th>O_CPI_LL</th>\n",
              "      <th>NO_CPI_34</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6224</th>\n",
              "      <td>b'A851913501'</td>\n",
              "      <td>1.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6226</th>\n",
              "      <td>b'A851915601'</td>\n",
              "      <td>2.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6227</th>\n",
              "      <td>b'A851917101'</td>\n",
              "      <td>1.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6228</th>\n",
              "      <td>b'A851917102'</td>\n",
              "      <td>2.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6229</th>\n",
              "      <td>b'A851917701'</td>\n",
              "      <td>1.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 299 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 ID  sex   age  O_DIP  O_55B  O_55D  O_55O  O_55M  O_55L  \\\n",
              "6224  b'A851913501'  1.0  72.0    1.0    9.0    9.0    9.0    9.0    9.0   \n",
              "6226  b'A851915601'  2.0  81.0    0.0    9.0    9.0    9.0    9.0    9.0   \n",
              "6227  b'A851917101'  1.0  62.0    0.0    9.0    9.0    9.0    9.0    9.0   \n",
              "6228  b'A851917102'  2.0  56.0    1.0    9.0    9.0    9.0    9.0    9.0   \n",
              "6229  b'A851917701'  1.0  55.0    0.0    9.0    9.0    9.0    9.0    9.0   \n",
              "\n",
              "      O_54B    ...      O_TN73  O_TN74  O_TN75  O_CPI_UR  O_CPI_UM  O_CPI_UL  \\\n",
              "6224    9.0    ...         0.0     0.0     0.0       3.0       0.0       0.0   \n",
              "6226    9.0    ...         0.0     0.0     0.0       0.0       0.0       0.0   \n",
              "6227    9.0    ...         0.0     0.0     0.0       0.0       0.0       0.0   \n",
              "6228    9.0    ...         0.0     0.0     0.0       2.0       1.0       0.0   \n",
              "6229    9.0    ...         0.0     0.0     0.0       0.0       0.0       0.0   \n",
              "\n",
              "      O_CPI_LR  O_CPI_LM  O_CPI_LL  NO_CPI_34  \n",
              "6224       0.0       2.0       0.0        1.0  \n",
              "6226       0.0       2.0       0.0        0.0  \n",
              "6227       1.0       1.0       0.0        0.0  \n",
              "6228       2.0       2.0       2.0        0.0  \n",
              "6229       0.0       0.0       0.0        0.0  \n",
              "\n",
              "[5 rows x 299 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "19VgytIYWI6t",
        "colab_type": "code",
        "outputId": "8b953ae9-9c78-4b96-c03c-42458d481863",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#자료가 제대로 읽어들여졌는지 확인한다.\n",
        "print(dt_raw.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20453, 299)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "f85W2JRsWI6x",
        "colab_type": "code",
        "outputId": "9c186d69-f807-41d4-fed2-8fb9122f5625",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "# 변수명 속성 확인하기\n",
        "dt_raw.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 20453 entries, 6224 to 29014\n",
            "Columns: 299 entries, ID to NO_CPI_34\n",
            "dtypes: float64(298), object(1)\n",
            "memory usage: 46.8+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xmo7obLVRUHg",
        "colab_type": "code",
        "outputId": "5d072ea1-aa0c-439c-d359-dc6aec537a23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5399
        }
      },
      "cell_type": "code",
      "source": [
        "# 변수명 확인하기 \n",
        "dt_raw.columns.values.tolist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ID',\n",
              " 'sex',\n",
              " 'age',\n",
              " 'O_DIP',\n",
              " 'O_55B',\n",
              " 'O_55D',\n",
              " 'O_55O',\n",
              " 'O_55M',\n",
              " 'O_55L',\n",
              " 'O_54B',\n",
              " 'O_54D',\n",
              " 'O_54O',\n",
              " 'O_54M',\n",
              " 'O_54L',\n",
              " 'O_53B',\n",
              " 'O_53D',\n",
              " 'O_53M',\n",
              " 'O_53L',\n",
              " 'O_52B',\n",
              " 'O_52D',\n",
              " 'O_52M',\n",
              " 'O_52L',\n",
              " 'O_51B',\n",
              " 'O_51D',\n",
              " 'O_51M',\n",
              " 'O_51L',\n",
              " 'O_61B',\n",
              " 'O_61M',\n",
              " 'O_61D',\n",
              " 'O_61L',\n",
              " 'O_62B',\n",
              " 'O_62M',\n",
              " 'O_62D',\n",
              " 'O_62L',\n",
              " 'O_63B',\n",
              " 'O_63M',\n",
              " 'O_63D',\n",
              " 'O_63L',\n",
              " 'O_64B',\n",
              " 'O_64M',\n",
              " 'O_64O',\n",
              " 'O_64D',\n",
              " 'O_64L',\n",
              " 'O_65B',\n",
              " 'O_65M',\n",
              " 'O_65O',\n",
              " 'O_65D',\n",
              " 'O_65L',\n",
              " 'O_18B',\n",
              " 'O_18D',\n",
              " 'O_18O',\n",
              " 'O_18M',\n",
              " 'O_18L',\n",
              " 'O_17B',\n",
              " 'O_17D',\n",
              " 'O_17O',\n",
              " 'O_17M',\n",
              " 'O_17L',\n",
              " 'O_16B',\n",
              " 'O_16D',\n",
              " 'O_16O',\n",
              " 'O_16M',\n",
              " 'O_16L',\n",
              " 'O_15B',\n",
              " 'O_15D',\n",
              " 'O_15O',\n",
              " 'O_15M',\n",
              " 'O_15L',\n",
              " 'O_14B',\n",
              " 'O_14D',\n",
              " 'O_14O',\n",
              " 'O_14M',\n",
              " 'O_14L',\n",
              " 'O_13B',\n",
              " 'O_13D',\n",
              " 'O_13M',\n",
              " 'O_13L',\n",
              " 'O_12B',\n",
              " 'O_12D',\n",
              " 'O_12M',\n",
              " 'O_12L',\n",
              " 'O_11B',\n",
              " 'O_11D',\n",
              " 'O_11M',\n",
              " 'O_11L',\n",
              " 'O_21B',\n",
              " 'O_21M',\n",
              " 'O_21D',\n",
              " 'O_21L',\n",
              " 'O_22B',\n",
              " 'O_22M',\n",
              " 'O_22D',\n",
              " 'O_22L',\n",
              " 'O_23B',\n",
              " 'O_23M',\n",
              " 'O_23D',\n",
              " 'O_23L',\n",
              " 'O_24B',\n",
              " 'O_24M',\n",
              " 'O_24O',\n",
              " 'O_24D',\n",
              " 'O_24L',\n",
              " 'O_25B',\n",
              " 'O_25M',\n",
              " 'O_25O',\n",
              " 'O_25D',\n",
              " 'O_25L',\n",
              " 'O_26B',\n",
              " 'O_26M',\n",
              " 'O_26O',\n",
              " 'O_26D',\n",
              " 'O_26L',\n",
              " 'O_27B',\n",
              " 'O_27M',\n",
              " 'O_27O',\n",
              " 'O_27D',\n",
              " 'O_27L',\n",
              " 'O_28B',\n",
              " 'O_28M',\n",
              " 'O_28O',\n",
              " 'O_28D',\n",
              " 'O_28L',\n",
              " 'O_48L',\n",
              " 'O_48D',\n",
              " 'O_48O',\n",
              " 'O_48M',\n",
              " 'O_48B',\n",
              " 'O_47L',\n",
              " 'O_47D',\n",
              " 'O_47O',\n",
              " 'O_47M',\n",
              " 'O_47B',\n",
              " 'O_46L',\n",
              " 'O_46D',\n",
              " 'O_46O',\n",
              " 'O_46M',\n",
              " 'O_46B',\n",
              " 'O_45L',\n",
              " 'O_45D',\n",
              " 'O_45O',\n",
              " 'O_45M',\n",
              " 'O_45B',\n",
              " 'O_44L',\n",
              " 'O_44D',\n",
              " 'O_44O',\n",
              " 'O_44M',\n",
              " 'O_44B',\n",
              " 'O_43L',\n",
              " 'O_43D',\n",
              " 'O_43M',\n",
              " 'O_43B',\n",
              " 'O_42L',\n",
              " 'O_42D',\n",
              " 'O_42M',\n",
              " 'O_42B',\n",
              " 'O_41L',\n",
              " 'O_41D',\n",
              " 'O_41M',\n",
              " 'O_41B',\n",
              " 'O_31L',\n",
              " 'O_31M',\n",
              " 'O_31D',\n",
              " 'O_31B',\n",
              " 'O_32L',\n",
              " 'O_32M',\n",
              " 'O_32D',\n",
              " 'O_32B',\n",
              " 'O_33L',\n",
              " 'O_33M',\n",
              " 'O_33D',\n",
              " 'O_33B',\n",
              " 'O_34L',\n",
              " 'O_34M',\n",
              " 'O_34O',\n",
              " 'O_34D',\n",
              " 'O_34B',\n",
              " 'O_35L',\n",
              " 'O_35M',\n",
              " 'O_35O',\n",
              " 'O_35D',\n",
              " 'O_35B',\n",
              " 'O_36L',\n",
              " 'O_36M',\n",
              " 'O_36O',\n",
              " 'O_36D',\n",
              " 'O_36B',\n",
              " 'O_37L',\n",
              " 'O_37M',\n",
              " 'O_37O',\n",
              " 'O_37D',\n",
              " 'O_37B',\n",
              " 'O_38L',\n",
              " 'O_38M',\n",
              " 'O_38O',\n",
              " 'O_38D',\n",
              " 'O_38B',\n",
              " 'O_85L',\n",
              " 'O_85D',\n",
              " 'O_85O',\n",
              " 'O_85M',\n",
              " 'O_85B',\n",
              " 'O_84L',\n",
              " 'O_84D',\n",
              " 'O_84O',\n",
              " 'O_84M',\n",
              " 'O_84B',\n",
              " 'O_83L',\n",
              " 'O_83D',\n",
              " 'O_83M',\n",
              " 'O_83B',\n",
              " 'O_82L',\n",
              " 'O_82D',\n",
              " 'O_82M',\n",
              " 'O_82B',\n",
              " 'O_81L',\n",
              " 'O_81D',\n",
              " 'O_81M',\n",
              " 'O_81B',\n",
              " 'O_71L',\n",
              " 'O_71M',\n",
              " 'O_71D',\n",
              " 'O_71B',\n",
              " 'O_72L',\n",
              " 'O_72M',\n",
              " 'O_72D',\n",
              " 'O_72B',\n",
              " 'O_73L',\n",
              " 'O_73M',\n",
              " 'O_73D',\n",
              " 'O_73B',\n",
              " 'O_74L',\n",
              " 'O_74M',\n",
              " 'O_74O',\n",
              " 'O_74D',\n",
              " 'O_74B',\n",
              " 'O_75L',\n",
              " 'O_75M',\n",
              " 'O_75O',\n",
              " 'O_75D',\n",
              " 'O_75B',\n",
              " 'O_TN55',\n",
              " 'O_TN54',\n",
              " 'O_TN53',\n",
              " 'O_TN52',\n",
              " 'O_TN51',\n",
              " 'O_TN61',\n",
              " 'O_TN62',\n",
              " 'O_TN63',\n",
              " 'O_TN64',\n",
              " 'O_TN65',\n",
              " 'O_TN18',\n",
              " 'O_TN17',\n",
              " 'O_TN16',\n",
              " 'O_TN15',\n",
              " 'O_TN14',\n",
              " 'O_TN13',\n",
              " 'O_TN12',\n",
              " 'O_TN11',\n",
              " 'O_TN21',\n",
              " 'O_TN22',\n",
              " 'O_TN23',\n",
              " 'O_TN24',\n",
              " 'O_TN25',\n",
              " 'O_TN26',\n",
              " 'O_TN27',\n",
              " 'O_TN28',\n",
              " 'O_TN48',\n",
              " 'O_TN47',\n",
              " 'O_TN46',\n",
              " 'O_TN45',\n",
              " 'O_TN44',\n",
              " 'O_TN43',\n",
              " 'O_TN42',\n",
              " 'O_TN41',\n",
              " 'O_TN31',\n",
              " 'O_TN32',\n",
              " 'O_TN33',\n",
              " 'O_TN34',\n",
              " 'O_TN35',\n",
              " 'O_TN36',\n",
              " 'O_TN37',\n",
              " 'O_TN38',\n",
              " 'O_TN85',\n",
              " 'O_TN84',\n",
              " 'O_TN83',\n",
              " 'O_TN82',\n",
              " 'O_TN81',\n",
              " 'O_TN71',\n",
              " 'O_TN72',\n",
              " 'O_TN73',\n",
              " 'O_TN74',\n",
              " 'O_TN75',\n",
              " 'O_CPI_UR',\n",
              " 'O_CPI_UM',\n",
              " 'O_CPI_UL',\n",
              " 'O_CPI_LR',\n",
              " 'O_CPI_LM',\n",
              " 'O_CPI_LL',\n",
              " 'NO_CPI_34']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "DVadNrHiWI63",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 자료를 복사하여 사용하고 원자료는 조작하지 않는다\n",
        "dt = dt_raw.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bj69YPvdWI66",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#연령을 범위로 구분하기\n",
        "labels = [\"{0} - {1}\".format(i, i + 10) for i in range(19, 80, 10)]\n",
        "dt['age']=dt.age.astype('int64')\n",
        "dt['age'] = pd.cut(dt.age, range(19, 90, 10), right=False, labels=labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K4nZdpO5WI6-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 불필요한 변수 삭제\n",
        "dt = dt.drop(columns = ['ID','O_CPI_UR','O_CPI_UM','O_CPI_UL','O_CPI_LL'], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ns52BhQ8WI7B",
        "colab_type": "code",
        "outputId": "d9bb03d9-26f7-4a19-983a-b4f7e6bf22af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "dt.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20453, 294)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "dBG3gS5UWI7G",
        "colab_type": "code",
        "outputId": "3ad5e3fb-f47d-4405-ab1b-58e2c18207a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "cell_type": "code",
      "source": [
        "dt.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>O_DIP</th>\n",
              "      <th>O_55B</th>\n",
              "      <th>O_55D</th>\n",
              "      <th>O_55O</th>\n",
              "      <th>O_55M</th>\n",
              "      <th>O_55L</th>\n",
              "      <th>O_54B</th>\n",
              "      <th>O_54D</th>\n",
              "      <th>...</th>\n",
              "      <th>O_TN82</th>\n",
              "      <th>O_TN81</th>\n",
              "      <th>O_TN71</th>\n",
              "      <th>O_TN72</th>\n",
              "      <th>O_TN73</th>\n",
              "      <th>O_TN74</th>\n",
              "      <th>O_TN75</th>\n",
              "      <th>O_CPI_LR</th>\n",
              "      <th>O_CPI_LM</th>\n",
              "      <th>NO_CPI_34</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6224</th>\n",
              "      <td>1.0</td>\n",
              "      <td>69 - 79</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6226</th>\n",
              "      <td>2.0</td>\n",
              "      <td>79 - 89</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6227</th>\n",
              "      <td>1.0</td>\n",
              "      <td>59 - 69</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6228</th>\n",
              "      <td>2.0</td>\n",
              "      <td>49 - 59</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6229</th>\n",
              "      <td>1.0</td>\n",
              "      <td>49 - 59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 294 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      sex      age  O_DIP  O_55B  O_55D  O_55O  O_55M  O_55L  O_54B  O_54D  \\\n",
              "6224  1.0  69 - 79    1.0    9.0    9.0    9.0    9.0    9.0    9.0    9.0   \n",
              "6226  2.0  79 - 89    0.0    9.0    9.0    9.0    9.0    9.0    9.0    9.0   \n",
              "6227  1.0  59 - 69    0.0    9.0    9.0    9.0    9.0    9.0    9.0    9.0   \n",
              "6228  2.0  49 - 59    1.0    9.0    9.0    9.0    9.0    9.0    9.0    9.0   \n",
              "6229  1.0  49 - 59    0.0    9.0    9.0    9.0    9.0    9.0    9.0    9.0   \n",
              "\n",
              "        ...      O_TN82  O_TN81  O_TN71  O_TN72  O_TN73  O_TN74  O_TN75  \\\n",
              "6224    ...         0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "6226    ...         0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "6227    ...         0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "6228    ...         0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "6229    ...         0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "\n",
              "      O_CPI_LR  O_CPI_LM  NO_CPI_34  \n",
              "6224       0.0       2.0        1.0  \n",
              "6226       0.0       2.0        0.0  \n",
              "6227       1.0       1.0        0.0  \n",
              "6228       2.0       2.0        0.0  \n",
              "6229       0.0       0.0        0.0  \n",
              "\n",
              "[5 rows x 294 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "108JP4LlRn3R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 치아상태가 기록불가 일 경우 결측으로 변환\n",
        "import numpy as np\n",
        "dt = dt.replace(9.0, np.nan)\n",
        "dt = dt.replace(8.0, np.nan)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bkOZ0_qLRn53",
        "colab_type": "code",
        "outputId": "af6eedb5-049a-4ef3-faa0-c953118249f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "cell_type": "code",
      "source": [
        "dt.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>O_DIP</th>\n",
              "      <th>O_55B</th>\n",
              "      <th>O_55D</th>\n",
              "      <th>O_55O</th>\n",
              "      <th>O_55M</th>\n",
              "      <th>O_55L</th>\n",
              "      <th>O_54B</th>\n",
              "      <th>O_54D</th>\n",
              "      <th>...</th>\n",
              "      <th>O_TN82</th>\n",
              "      <th>O_TN81</th>\n",
              "      <th>O_TN71</th>\n",
              "      <th>O_TN72</th>\n",
              "      <th>O_TN73</th>\n",
              "      <th>O_TN74</th>\n",
              "      <th>O_TN75</th>\n",
              "      <th>O_CPI_LR</th>\n",
              "      <th>O_CPI_LM</th>\n",
              "      <th>NO_CPI_34</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6224</th>\n",
              "      <td>1.0</td>\n",
              "      <td>69 - 79</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6226</th>\n",
              "      <td>2.0</td>\n",
              "      <td>79 - 89</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6227</th>\n",
              "      <td>1.0</td>\n",
              "      <td>59 - 69</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6228</th>\n",
              "      <td>2.0</td>\n",
              "      <td>49 - 59</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6229</th>\n",
              "      <td>1.0</td>\n",
              "      <td>49 - 59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 294 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      sex      age  O_DIP  O_55B  O_55D  O_55O  O_55M  O_55L  O_54B  O_54D  \\\n",
              "6224  1.0  69 - 79    1.0    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "6226  2.0  79 - 89    0.0    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "6227  1.0  59 - 69    0.0    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "6228  2.0  49 - 59    1.0    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "6229  1.0  49 - 59    0.0    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "\n",
              "        ...      O_TN82  O_TN81  O_TN71  O_TN72  O_TN73  O_TN74  O_TN75  \\\n",
              "6224    ...         0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "6226    ...         0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "6227    ...         0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "6228    ...         0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "6229    ...         0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "\n",
              "      O_CPI_LR  O_CPI_LM  NO_CPI_34  \n",
              "6224       0.0       2.0        1.0  \n",
              "6226       0.0       2.0        0.0  \n",
              "6227       1.0       1.0        0.0  \n",
              "6228       2.0       2.0        0.0  \n",
              "6229       0.0       0.0        0.0  \n",
              "\n",
              "[5 rows x 294 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "KnxZIC7cT73o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 모든 변수가 카테고리 이므로 이를 변환 \n",
        "#범주형 변수를 카테고리 속성으로 변경\n",
        "for i in dt.columns:\n",
        "    dt[i]=pd.Categorical(dt[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ndl_AkGgWI7K",
        "colab_type": "code",
        "outputId": "95fb66c5-58ab-4666-ff16-c64699f3261a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "cell_type": "code",
      "source": [
        "# 전체 자료에서 치주질환 빈도 확인\n",
        "import matplotlib.pyplot as plt\n",
        "dt['NO_CPI_34'].value_counts().plot(kind='bar')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFOCAYAAACvyZWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDQCAYYg3AACGId4AABiGeAMAYJj/BeyHqbnOcaK1AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1929b132b0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "sUl_KtglTf7x",
        "colab_type": "code",
        "outputId": "112621c0-87c2-48f5-d5c3-83e259d4dff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "# 치주질환의 비율확인\n",
        "(dt['NO_CPI_34'].value_counts()/dt['NO_CPI_34'].count())*100"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    69.784384\n",
              "1.0    30.215616\n",
              "Name: NO_CPI_34, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "OVzqXdjoWI7P",
        "colab_type": "code",
        "outputId": "4daf6cf1-6d8e-421f-fe92-4938123bd396",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "cell_type": "code",
      "source": [
        "# 데이터 요약결과 확인\n",
        "dt.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>O_DIP</th>\n",
              "      <th>O_55B</th>\n",
              "      <th>O_55D</th>\n",
              "      <th>O_55O</th>\n",
              "      <th>O_55M</th>\n",
              "      <th>O_55L</th>\n",
              "      <th>O_54B</th>\n",
              "      <th>O_54D</th>\n",
              "      <th>...</th>\n",
              "      <th>O_TN82</th>\n",
              "      <th>O_TN81</th>\n",
              "      <th>O_TN71</th>\n",
              "      <th>O_TN72</th>\n",
              "      <th>O_TN73</th>\n",
              "      <th>O_TN74</th>\n",
              "      <th>O_TN75</th>\n",
              "      <th>O_CPI_LR</th>\n",
              "      <th>O_CPI_LM</th>\n",
              "      <th>NO_CPI_34</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>20453.0</td>\n",
              "      <td>20451</td>\n",
              "      <td>20453.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>18741.0</td>\n",
              "      <td>20018.0</td>\n",
              "      <td>20453.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>2.0</td>\n",
              "      <td>7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>2.0</td>\n",
              "      <td>49 - 59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>11796.0</td>\n",
              "      <td>4064</td>\n",
              "      <td>14251.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>12495.0</td>\n",
              "      <td>10773.0</td>\n",
              "      <td>14273.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 294 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            sex      age    O_DIP  O_55B  O_55D  O_55O  O_55M  O_55L  O_54B  \\\n",
              "count   20453.0    20451  20453.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "unique      2.0        7      2.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
              "top         2.0  49 - 59      0.0    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "freq    11796.0     4064  14251.0    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "\n",
              "        O_54D    ...       O_TN82   O_TN81   O_TN71   O_TN72   O_TN73  \\\n",
              "count     0.0    ...      20452.0  20452.0  20452.0  20452.0  20452.0   \n",
              "unique    0.0    ...          1.0      1.0      1.0      1.0      1.0   \n",
              "top       NaN    ...          0.0      0.0      0.0      0.0      0.0   \n",
              "freq      NaN    ...      20452.0  20452.0  20452.0  20452.0  20452.0   \n",
              "\n",
              "         O_TN74   O_TN75  O_CPI_LR  O_CPI_LM  NO_CPI_34  \n",
              "count   20452.0  20452.0   18741.0   20018.0    20453.0  \n",
              "unique      1.0      1.0       5.0       5.0        2.0  \n",
              "top         0.0      0.0       0.0       2.0        0.0  \n",
              "freq    20452.0  20452.0   12495.0   10773.0    14273.0  \n",
              "\n",
              "[4 rows x 294 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "cpK5GCExWI7R",
        "colab_type": "code",
        "outputId": "e03822b7-f34d-4ae8-aabf-5e173ac2f7b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# 변수 중 unique가 0인 변수 \n",
        "des_columns = dt.describe().T\n",
        "des_columns.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(294, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "WwrhUW3aVH95",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 변수의 항목 값이 없는 변수 추출, unique == 0 \n",
        "miss_columns = des_columns.loc[des_columns.unique==0 , :] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N7_KQVTYXc55",
        "colab_type": "code",
        "outputId": "cf77a1c1-3040-4b78-86fe-2a494ca00d98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#294개 변수 중 총 44개의 변수가 결측(치아상태가 기록불가)\n",
        "miss_columns.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "ms-Wi3WWWI7U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#결측만 있는 변수 삭제하기 \n",
        "miss_column_list = miss_columns.T.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pcB8ZCp_WI7Y",
        "colab_type": "code",
        "outputId": "7c8f4b5e-aa4c-4e2c-acde-104ec6a8b826",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "cell_type": "code",
      "source": [
        "miss_column_list"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['O_55B', 'O_55D', 'O_55O', 'O_55M', 'O_55L', 'O_54B', 'O_54D', 'O_54O',\n",
              "       'O_54M', 'O_54L', 'O_53B', 'O_53D', 'O_53M', 'O_53L', 'O_52B', 'O_52D',\n",
              "       'O_52M', 'O_52L', 'O_51B', 'O_51D', 'O_51M', 'O_51L', 'O_61B', 'O_61M',\n",
              "       'O_61D', 'O_61L', 'O_62B', 'O_62M', 'O_62D', 'O_62L', 'O_63B', 'O_63M',\n",
              "       'O_63D', 'O_63L', 'O_64B', 'O_64M', 'O_64O', 'O_64D', 'O_64L', 'O_65B',\n",
              "       'O_65M', 'O_65O', 'O_65D', 'O_65L'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "_K8nw87TZ2UN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 변수 제외하기\n",
        "for i in miss_column_list:\n",
        "  dt = dt.drop(columns = [i], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FPkroXu1Z2Wp",
        "colab_type": "code",
        "outputId": "ac1075f5-df9f-45ef-d95e-ded5fa3b5c4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "cell_type": "code",
      "source": [
        "dt.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>O_DIP</th>\n",
              "      <th>O_18B</th>\n",
              "      <th>O_18D</th>\n",
              "      <th>O_18O</th>\n",
              "      <th>O_18M</th>\n",
              "      <th>O_18L</th>\n",
              "      <th>O_17B</th>\n",
              "      <th>O_17D</th>\n",
              "      <th>...</th>\n",
              "      <th>O_TN82</th>\n",
              "      <th>O_TN81</th>\n",
              "      <th>O_TN71</th>\n",
              "      <th>O_TN72</th>\n",
              "      <th>O_TN73</th>\n",
              "      <th>O_TN74</th>\n",
              "      <th>O_TN75</th>\n",
              "      <th>O_CPI_LR</th>\n",
              "      <th>O_CPI_LM</th>\n",
              "      <th>NO_CPI_34</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>20453.0</td>\n",
              "      <td>20451</td>\n",
              "      <td>20453.0</td>\n",
              "      <td>10737.0</td>\n",
              "      <td>10737.0</td>\n",
              "      <td>10737.0</td>\n",
              "      <td>10737.0</td>\n",
              "      <td>10737.0</td>\n",
              "      <td>20421.0</td>\n",
              "      <td>20421.0</td>\n",
              "      <td>...</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>18741.0</td>\n",
              "      <td>20018.0</td>\n",
              "      <td>20453.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>2.0</td>\n",
              "      <td>7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>2.0</td>\n",
              "      <td>49 - 59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>11796.0</td>\n",
              "      <td>4064</td>\n",
              "      <td>14251.0</td>\n",
              "      <td>5079.0</td>\n",
              "      <td>5079.0</td>\n",
              "      <td>5079.0</td>\n",
              "      <td>5079.0</td>\n",
              "      <td>5079.0</td>\n",
              "      <td>13164.0</td>\n",
              "      <td>12950.0</td>\n",
              "      <td>...</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>20452.0</td>\n",
              "      <td>12495.0</td>\n",
              "      <td>10773.0</td>\n",
              "      <td>14273.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 250 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            sex      age    O_DIP    O_18B    O_18D    O_18O    O_18M  \\\n",
              "count   20453.0    20451  20453.0  10737.0  10737.0  10737.0  10737.0   \n",
              "unique      2.0        7      2.0      6.0      6.0      6.0      6.0   \n",
              "top         2.0  49 - 59      0.0      5.0      5.0      5.0      5.0   \n",
              "freq    11796.0     4064  14251.0   5079.0   5079.0   5079.0   5079.0   \n",
              "\n",
              "          O_18L    O_17B    O_17D    ...       O_TN82   O_TN81   O_TN71  \\\n",
              "count   10737.0  20421.0  20421.0    ...      20452.0  20452.0  20452.0   \n",
              "unique      6.0      6.0      6.0    ...          1.0      1.0      1.0   \n",
              "top         5.0      0.0      0.0    ...          0.0      0.0      0.0   \n",
              "freq     5079.0  13164.0  12950.0    ...      20452.0  20452.0  20452.0   \n",
              "\n",
              "         O_TN72   O_TN73   O_TN74   O_TN75  O_CPI_LR  O_CPI_LM  NO_CPI_34  \n",
              "count   20452.0  20452.0  20452.0  20452.0   18741.0   20018.0    20453.0  \n",
              "unique      1.0      1.0      1.0      1.0       5.0       5.0        2.0  \n",
              "top         0.0      0.0      0.0      0.0       0.0       2.0        0.0  \n",
              "freq    20452.0  20452.0  20452.0  20452.0   12495.0   10773.0    14273.0  \n",
              "\n",
              "[4 rows x 250 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "bNEx39aJaaUM",
        "colab_type": "code",
        "outputId": "76f249cc-d1c1-4cd6-c0a6-0d97be1a1cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "dt.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20453, 250)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "wfmpTzmgWI7e",
        "colab_type": "code",
        "outputId": "7abc073b-b88a-4355-81d6-b70ed0eed700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "# 변경되었는지 확인\n",
        "dt.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 20453 entries, 6224 to 29014\n",
            "Columns: 250 entries, sex to NO_CPI_34\n",
            "dtypes: category(250)\n",
            "memory usage: 5.1 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t_lz4TxRWI7l",
        "colab_type": "code",
        "outputId": "8e108836-c680-4aed-e3de-2883f83dd389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "cell_type": "code",
      "source": [
        "# 변수의 분포 확인하기 \n",
        "columns_list = dt.columns\n",
        "columns_list"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sex', 'age', 'O_DIP', 'O_18B', 'O_18D', 'O_18O', 'O_18M', 'O_18L',\n",
              "       'O_17B', 'O_17D',\n",
              "       ...\n",
              "       'O_TN82', 'O_TN81', 'O_TN71', 'O_TN72', 'O_TN73', 'O_TN74', 'O_TN75',\n",
              "       'O_CPI_LR', 'O_CPI_LM', 'NO_CPI_34'],\n",
              "      dtype='object', length=250)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "kxz2FELbazqr",
        "colab_type": "code",
        "outputId": "bec69e44-51cd-4946-c940-b368332366e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 26783
        }
      },
      "cell_type": "code",
      "source": [
        "for i in columns_list:\n",
        "  print((dt[i].value_counts()/dt[i].count())*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0    57.673691\n",
            "1.0    42.326309\n",
            "Name: sex, dtype: float64\n",
            "49 - 59    19.871889\n",
            "39 - 49    18.424527\n",
            "59 - 69    17.559044\n",
            "29 - 39    16.346389\n",
            "69 - 79    13.392988\n",
            "19 - 29    10.884553\n",
            "79 - 89     3.520610\n",
            "Name: age, dtype: float64\n",
            "0.0    69.67682\n",
            "1.0    30.32318\n",
            "Name: O_DIP, dtype: float64\n",
            "5.0    47.303716\n",
            "0.0    32.942163\n",
            "4.0    17.444351\n",
            "1.0     1.229394\n",
            "7.0     0.819596\n",
            "3.0     0.260780\n",
            "Name: O_18B, dtype: float64\n",
            "5.0    47.303716\n",
            "0.0    32.672069\n",
            "4.0    17.444351\n",
            "1.0     1.443606\n",
            "7.0     0.828909\n",
            "3.0     0.307348\n",
            "Name: O_18D, dtype: float64\n",
            "5.0    47.303716\n",
            "0.0    23.498184\n",
            "4.0    17.444351\n",
            "1.0     8.084195\n",
            "3.0     2.840645\n",
            "7.0     0.828909\n",
            "Name: O_18O, dtype: float64\n",
            "5.0    47.303716\n",
            "0.0    32.616187\n",
            "4.0    17.444351\n",
            "1.0     1.331843\n",
            "7.0     0.828909\n",
            "3.0     0.474993\n",
            "Name: O_18M, dtype: float64\n",
            "5.0    47.303716\n",
            "0.0    32.811772\n",
            "4.0    17.444351\n",
            "1.0     1.257334\n",
            "7.0     0.828909\n",
            "3.0     0.353916\n",
            "Name: O_18L, dtype: float64\n",
            "0.0    64.463053\n",
            "4.0    13.804417\n",
            "3.0     8.922188\n",
            "5.0     7.066255\n",
            "7.0     4.451300\n",
            "1.0     1.292787\n",
            "Name: O_17B, dtype: float64\n",
            "0.0    63.415112\n",
            "4.0    13.804417\n",
            "3.0     9.921160\n",
            "5.0     7.066255\n",
            "7.0     4.304393\n",
            "1.0     1.488664\n",
            "Name: O_17D, dtype: float64\n",
            "0.0    39.998042\n",
            "3.0    30.280035\n",
            "4.0    13.801038\n",
            "5.0     7.064526\n",
            "7.0     4.318026\n",
            "1.0     4.083031\n",
            "6.0     0.455302\n",
            "Name: O_17O, dtype: float64\n",
            "0.0    62.494491\n",
            "4.0    13.804417\n",
            "3.0    10.861368\n",
            "5.0     7.066255\n",
            "7.0     4.304393\n",
            "1.0     1.469076\n",
            "Name: O_17M, dtype: float64\n",
            "0.0    59.135204\n",
            "3.0    13.897458\n",
            "4.0    13.804417\n",
            "5.0     7.066255\n",
            "7.0     4.323980\n",
            "1.0     1.645365\n",
            "6.0     0.127320\n",
            "Name: O_17L, dtype: float64\n",
            "0.0    59.858121\n",
            "3.0    14.295499\n",
            "4.0    13.375734\n",
            "5.0     6.149706\n",
            "7.0     5.112524\n",
            "1.0     1.203523\n",
            "6.0     0.004892\n",
            "Name: O_16B, dtype: float64\n",
            "0.0    60.068493\n",
            "3.0    15.543053\n",
            "4.0    13.375734\n",
            "5.0     6.149706\n",
            "7.0     3.400196\n",
            "1.0     1.457926\n",
            "6.0     0.004892\n",
            "Name: O_16D, dtype: float64\n",
            "0.0    39.684092\n",
            "3.0    33.894078\n",
            "4.0    13.369847\n",
            "5.0     6.147000\n",
            "7.0     3.408480\n",
            "1.0     2.547802\n",
            "6.0     0.948702\n",
            "Name: O_16O, dtype: float64\n",
            "0.0    58.155577\n",
            "3.0    17.279843\n",
            "4.0    13.375734\n",
            "5.0     6.149706\n",
            "7.0     3.405088\n",
            "1.0     1.634051\n",
            "Name: O_16M, dtype: float64\n",
            "0.0    51.790607\n",
            "3.0    23.155577\n",
            "4.0    13.375734\n",
            "5.0     6.149706\n",
            "7.0     3.449119\n",
            "1.0     1.722114\n",
            "6.0     0.357143\n",
            "Name: O_16L, dtype: float64\n",
            "0.0    67.857668\n",
            "4.0     9.817184\n",
            "7.0     8.400725\n",
            "3.0     7.959614\n",
            "5.0     5.048277\n",
            "1.0     0.916532\n",
            "Name: O_15B, dtype: float64\n",
            "0.0    67.769446\n",
            "3.0    10.184777\n",
            "4.0     9.817184\n",
            "7.0     5.866784\n",
            "5.0     5.048277\n",
            "1.0     1.313532\n",
            "Name: O_15D, dtype: float64\n",
            "0.0    62.691761\n",
            "3.0    14.777239\n",
            "4.0     9.817184\n",
            "7.0     5.861883\n",
            "5.0     5.048277\n",
            "1.0     1.352742\n",
            "6.0     0.450914\n",
            "Name: O_15O, dtype: float64\n",
            "0.0    68.514434\n",
            "4.0     9.817184\n",
            "3.0     9.557418\n",
            "7.0     5.861883\n",
            "5.0     5.048277\n",
            "1.0     1.200804\n",
            "Name: O_15M, dtype: float64\n",
            "0.0    70.421017\n",
            "4.0     9.817184\n",
            "3.0     7.812577\n",
            "7.0     5.905994\n",
            "5.0     5.048277\n",
            "1.0     0.994952\n",
            "Name: O_15L, dtype: float64\n",
            "0.0    71.493589\n",
            "7.0     9.170990\n",
            "4.0     7.237937\n",
            "3.0     5.652344\n",
            "5.0     5.539787\n",
            "1.0     0.905354\n",
            "Name: O_14B, dtype: float64\n",
            "0.0    72.526182\n",
            "3.0     7.717530\n",
            "4.0     7.237937\n",
            "7.0     5.720857\n",
            "5.0     5.539787\n",
            "1.0     1.257708\n",
            "Name: O_14D, dtype: float64\n",
            "0.0    68.268572\n",
            "3.0    11.559166\n",
            "4.0     7.237937\n",
            "7.0     5.725751\n",
            "5.0     5.539787\n",
            "1.0     1.203876\n",
            "6.0     0.464911\n",
            "Name: O_14O, dtype: float64\n",
            "0.0    74.591367\n",
            "4.0     7.237937\n",
            "3.0     5.960654\n",
            "7.0     5.715964\n",
            "5.0     5.539787\n",
            "1.0     0.954292\n",
            "Name: O_14M, dtype: float64\n",
            "0.0    75.242243\n",
            "4.0     7.237937\n",
            "7.0     5.764902\n",
            "5.0     5.539787\n",
            "3.0     5.358716\n",
            "1.0     0.856416\n",
            "Name: O_14L, dtype: float64\n",
            "0.0    80.708546\n",
            "7.0     9.858879\n",
            "5.0     4.444336\n",
            "3.0     2.224618\n",
            "4.0     2.023716\n",
            "1.0     0.739906\n",
            "Name: O_13B, dtype: float64\n",
            "0.0    82.658761\n",
            "7.0     8.036064\n",
            "5.0     4.444336\n",
            "3.0     2.146217\n",
            "4.0     2.023716\n",
            "1.0     0.690906\n",
            "Name: O_13D, dtype: float64\n",
            "0.0    82.668561\n",
            "7.0     8.050764\n",
            "5.0     4.444336\n",
            "3.0     2.116817\n",
            "4.0     2.023716\n",
            "1.0     0.695806\n",
            "Name: O_13M, dtype: float64\n",
            "0.0    82.516660\n",
            "7.0     8.055664\n",
            "5.0     4.444336\n",
            "3.0     2.298118\n",
            "4.0     2.023716\n",
            "1.0     0.656605\n",
            "6.0     0.004900\n",
            "Name: O_13L, dtype: float64\n",
            "0.0    78.935503\n",
            "7.0     8.713978\n",
            "5.0     6.621251\n",
            "4.0     2.871986\n",
            "3.0     2.225054\n",
            "1.0     0.632229\n",
            "Name: O_12B, dtype: float64\n",
            "0.0    79.489316\n",
            "7.0     8.076848\n",
            "5.0     6.621251\n",
            "4.0     2.871986\n",
            "3.0     2.161341\n",
            "1.0     0.779259\n",
            "Name: O_12D, dtype: float64\n",
            "0.0    79.190355\n",
            "7.0     8.106254\n",
            "5.0     6.621251\n",
            "4.0     2.871986\n",
            "3.0     2.381886\n",
            "1.0     0.828269\n",
            "Name: O_12M, dtype: float64\n",
            "0.0    78.371888\n",
            "7.0     8.052343\n",
            "5.0     6.621251\n",
            "3.0     3.175848\n",
            "4.0     2.871986\n",
            "1.0     0.887081\n",
            "6.0     0.019604\n",
            "Name: O_12L, dtype: float64\n",
            "0.0    75.519484\n",
            "7.0    11.333301\n",
            "5.0     7.549015\n",
            "4.0     2.752652\n",
            "3.0     2.356623\n",
            "1.0     0.488926\n",
            "Name: O_11B, dtype: float64\n",
            "0.0    76.199091\n",
            "7.0    10.404342\n",
            "5.0     7.549015\n",
            "4.0     2.752652\n",
            "3.0     2.434851\n",
            "1.0     0.660050\n",
            "Name: O_11D, dtype: float64\n",
            "0.0    75.583044\n",
            "7.0    10.575466\n",
            "5.0     7.549015\n",
            "4.0     2.752652\n",
            "3.0     2.708649\n",
            "1.0     0.831174\n",
            "Name: O_11M, dtype: float64\n",
            "0.0    76.140419\n",
            "7.0    10.389674\n",
            "5.0     7.549015\n",
            "4.0     2.752652\n",
            "3.0     2.698871\n",
            "1.0     0.469369\n",
            "Name: O_11L, dtype: float64\n",
            "0.0    75.662592\n",
            "7.0    11.149144\n",
            "5.0     7.745721\n",
            "4.0     2.586797\n",
            "3.0     2.381418\n",
            "1.0     0.474328\n",
            "Name: O_21B, dtype: float64\n",
            "0.0    75.603912\n",
            "7.0    10.449878\n",
            "5.0     7.745721\n",
            "3.0     2.797066\n",
            "4.0     2.586797\n",
            "1.0     0.816626\n",
            "Name: O_21M, dtype: float64\n",
            "0.0    76.293399\n",
            "7.0    10.278729\n",
            "5.0     7.745721\n",
            "4.0     2.586797\n",
            "3.0     2.464548\n",
            "1.0     0.630807\n",
            "Name: O_21D, dtype: float64\n",
            "0.0    76.249389\n",
            "7.0    10.288509\n",
            "5.0     7.745721\n",
            "3.0     2.660147\n",
            "4.0     2.586797\n",
            "1.0     0.469438\n",
            "Name: O_21L, dtype: float64\n",
            "0.0    78.749265\n",
            "7.0     8.954127\n",
            "5.0     6.670261\n",
            "4.0     2.769065\n",
            "3.0     2.171143\n",
            "1.0     0.686140\n",
            "Name: O_22B, dtype: float64\n",
            "0.0    79.121741\n",
            "7.0     8.326799\n",
            "5.0     6.670261\n",
            "4.0     2.769065\n",
            "3.0     2.254460\n",
            "1.0     0.857675\n",
            "Name: O_22M, dtype: float64\n",
            "0.0    79.288375\n",
            "7.0     8.312096\n",
            "5.0     6.670261\n",
            "4.0     2.769065\n",
            "3.0     2.166242\n",
            "1.0     0.793962\n",
            "Name: O_22D, dtype: float64\n",
            "0.0    78.239561\n",
            "7.0     8.272888\n",
            "5.0     6.670261\n",
            "3.0     3.175848\n",
            "4.0     2.769065\n",
            "1.0     0.852774\n",
            "6.0     0.019604\n",
            "Name: O_22L, dtype: float64\n",
            "0.0    80.679145\n",
            "7.0     9.604077\n",
            "5.0     4.674637\n",
            "3.0     2.185417\n",
            "4.0     2.116817\n",
            "1.0     0.739906\n",
            "Name: O_23B, dtype: float64\n",
            "0.0    82.335359\n",
            "7.0     8.045864\n",
            "5.0     4.674637\n",
            "4.0     2.116817\n",
            "3.0     2.058016\n",
            "1.0     0.769306\n",
            "Name: O_23M, dtype: float64\n",
            "0.0    82.217758\n",
            "7.0     8.031164\n",
            "5.0     4.674637\n",
            "3.0     2.141317\n",
            "4.0     2.116817\n",
            "1.0     0.818307\n",
            "Name: O_23D, dtype: float64\n",
            "0.0    82.109957\n",
            "7.0     8.045864\n",
            "5.0     4.674637\n",
            "3.0     2.317719\n",
            "4.0     2.116817\n",
            "1.0     0.725206\n",
            "6.0     0.009800\n",
            "Name: O_23L, dtype: float64\n",
            "0.0    72.633382\n",
            "7.0     8.556045\n",
            "4.0     7.180617\n",
            "5.0     5.379344\n",
            "3.0     5.359765\n",
            "1.0     0.890847\n",
            "Name: O_24B, dtype: float64\n",
            "0.0    74.557024\n",
            "4.0     7.180617\n",
            "7.0     6.030348\n",
            "3.0     5.859031\n",
            "5.0     5.379344\n",
            "1.0     0.993637\n",
            "Name: O_24M, dtype: float64\n",
            "0.0    67.836515\n",
            "3.0    11.796378\n",
            "4.0     7.180617\n",
            "7.0     6.025453\n",
            "5.0     5.379344\n",
            "1.0     1.297112\n",
            "6.0     0.484581\n",
            "Name: O_24O, dtype: float64\n",
            "0.0    72.584435\n",
            "3.0     7.601566\n",
            "4.0     7.180617\n",
            "7.0     6.030348\n",
            "5.0     5.379344\n",
            "1.0     1.223691\n",
            "Name: O_24D, dtype: float64\n",
            "0.0    75.310817\n",
            "4.0     7.180617\n",
            "7.0     6.045032\n",
            "5.0     5.379344\n",
            "3.0     5.217817\n",
            "1.0     0.866373\n",
            "Name: O_24L, dtype: float64\n",
            "0.0    68.592571\n",
            "4.0     9.903950\n",
            "7.0     8.125061\n",
            "3.0     7.610507\n",
            "5.0     4.915221\n",
            "1.0     0.852690\n",
            "Name: O_25B, dtype: float64\n",
            "0.0    68.445555\n",
            "4.0     9.903950\n",
            "3.0     9.364893\n",
            "7.0     6.257963\n",
            "5.0     4.915221\n",
            "1.0     1.112418\n",
            "Name: O_25M, dtype: float64\n",
            "0.0    62.466921\n",
            "3.0    14.696658\n",
            "4.0     9.903950\n",
            "7.0     6.248162\n",
            "5.0     4.915221\n",
            "1.0     1.298638\n",
            "6.0     0.470450\n",
            "Name: O_25O, dtype: float64\n",
            "0.0    68.068215\n",
            "4.0     9.903950\n",
            "3.0     9.717730\n",
            "7.0     6.253063\n",
            "5.0     4.915221\n",
            "1.0     1.141821\n",
            "Name: O_25D, dtype: float64\n",
            "0.0    70.508674\n",
            "4.0     9.903950\n",
            "3.0     7.512496\n",
            "7.0     6.257963\n",
            "5.0     4.915221\n",
            "1.0     0.901696\n",
            "Name: O_25L, dtype: float64\n",
            "0.0    59.254367\n",
            "3.0    14.721855\n",
            "4.0    14.217917\n",
            "5.0     6.233182\n",
            "7.0     4.525662\n",
            "1.0     1.037233\n",
            "6.0     0.009785\n",
            "Name: O_26B, dtype: float64\n",
            "0.0    56.832526\n",
            "3.0    17.838446\n",
            "4.0    14.217917\n",
            "5.0     6.233182\n",
            "7.0     3.312295\n",
            "1.0     1.560742\n",
            "6.0     0.004893\n",
            "Name: O_26M, dtype: float64\n",
            "0.0    38.833195\n",
            "3.0    33.933200\n",
            "4.0    14.210964\n",
            "5.0     6.230134\n",
            "7.0     3.320456\n",
            "1.0     2.630935\n",
            "6.0     0.841117\n",
            "Name: O_26O, dtype: float64\n",
            "0.0    58.593865\n",
            "3.0    16.218993\n",
            "4.0    14.217917\n",
            "5.0     6.233182\n",
            "7.0     3.322080\n",
            "1.0     1.409071\n",
            "6.0     0.004893\n",
            "Name: O_26D, dtype: float64\n",
            "0.0    50.359607\n",
            "3.0    23.836783\n",
            "4.0    14.217917\n",
            "5.0     6.233182\n",
            "7.0     3.331866\n",
            "1.0     1.722198\n",
            "6.0     0.298449\n",
            "Name: O_26L, dtype: float64\n",
            "0.0    62.867773\n",
            "4.0    13.873794\n",
            "3.0    10.182601\n",
            "5.0     7.034807\n",
            "7.0     4.807363\n",
            "1.0     1.233661\n",
            "Name: O_27B, dtype: float64\n",
            "0.0    60.997699\n",
            "4.0    13.873794\n",
            "3.0    12.033093\n",
            "5.0     7.034807\n",
            "7.0     4.680080\n",
            "1.0     1.380526\n",
            "Name: O_27M, dtype: float64\n",
            "0.0    38.632470\n",
            "3.0    31.466889\n",
            "4.0    13.871078\n",
            "5.0     7.033430\n",
            "7.0     4.684059\n",
            "1.0     3.871568\n",
            "6.0     0.440507\n",
            "Name: O_27O, dtype: float64\n",
            "0.0    61.986586\n",
            "4.0    13.873794\n",
            "3.0    10.946297\n",
            "5.0     7.034807\n",
            "7.0     4.684976\n",
            "1.0     1.473540\n",
            "Name: O_27D, dtype: float64\n",
            "0.0    57.751995\n",
            "3.0    14.906741\n",
            "4.0    13.873794\n",
            "5.0     7.034807\n",
            "7.0     4.689871\n",
            "1.0     1.649777\n",
            "6.0     0.093014\n",
            "Name: O_27L, dtype: float64\n",
            "5.0    47.830559\n",
            "0.0    31.700019\n",
            "4.0    17.795025\n",
            "1.0     1.402656\n",
            "7.0     0.925753\n",
            "3.0     0.345988\n",
            "Name: O_28B, dtype: float64\n",
            "5.0    47.830559\n",
            "0.0    31.634561\n",
            "4.0    17.795025\n",
            "1.0     1.309145\n",
            "7.0     0.925753\n",
            "3.0     0.504956\n",
            "Name: O_28M, dtype: float64\n",
            "5.0    47.830559\n",
            "0.0    22.900692\n",
            "4.0    17.795025\n",
            "1.0     7.677202\n",
            "3.0     2.852067\n",
            "7.0     0.925753\n",
            "6.0     0.018702\n",
            "Name: O_28O, dtype: float64\n",
            "5.0    47.830559\n",
            "0.0    31.587806\n",
            "4.0    17.795025\n",
            "1.0     1.468113\n",
            "7.0     0.916402\n",
            "3.0     0.402095\n",
            "Name: O_28D, dtype: float64\n",
            "5.0    47.830559\n",
            "0.0    31.840284\n",
            "4.0    17.795025\n",
            "1.0     1.187582\n",
            "7.0     0.925753\n",
            "3.0     0.420797\n",
            "Name: O_28L, dtype: float64\n",
            "5.0    44.096880\n",
            "0.0    37.101806\n",
            "4.0    15.862069\n",
            "7.0     1.568144\n",
            "1.0     0.738916\n",
            "3.0     0.632184\n",
            "Name: O_48L, dtype: float64\n",
            "5.0    44.096880\n",
            "0.0    36.756979\n",
            "4.0    15.862069\n",
            "7.0     1.568144\n",
            "1.0     0.960591\n",
            "3.0     0.755337\n",
            "Name: O_48D, dtype: float64\n",
            "5.0    44.089640\n",
            "0.0    24.601872\n",
            "4.0    15.859465\n",
            "3.0     7.486455\n",
            "1.0     6.378263\n",
            "7.0     1.567887\n",
            "6.0     0.016418\n",
            "Name: O_48O, dtype: float64\n",
            "5.0    44.096880\n",
            "0.0    36.174056\n",
            "4.0    15.862069\n",
            "7.0     1.568144\n",
            "1.0     1.157635\n",
            "3.0     1.141215\n",
            "Name: O_48M, dtype: float64\n",
            "5.0    44.096880\n",
            "0.0    35.919540\n",
            "4.0    15.862069\n",
            "7.0     1.568144\n",
            "1.0     1.280788\n",
            "3.0     1.272578\n",
            "Name: O_48B, dtype: float64\n",
            "0.0    59.816927\n",
            "4.0    16.280777\n",
            "3.0    10.661315\n",
            "5.0     6.383083\n",
            "7.0     5.878898\n",
            "1.0     0.979000\n",
            "Name: O_47L, dtype: float64\n",
            "0.0    58.926037\n",
            "4.0    16.280777\n",
            "3.0    11.336825\n",
            "5.0     6.383083\n",
            "7.0     5.874003\n",
            "1.0     1.199276\n",
            "Name: O_47D, dtype: float64\n",
            "3.0    36.985564\n",
            "0.0    30.658184\n",
            "4.0    16.275997\n",
            "5.0     6.381209\n",
            "7.0     5.891852\n",
            "1.0     3.386347\n",
            "6.0     0.420847\n",
            "Name: O_47O, dtype: float64\n",
            "0.0    57.979244\n",
            "4.0    16.281574\n",
            "3.0    12.336009\n",
            "5.0     6.383395\n",
            "7.0     5.888976\n",
            "1.0     1.130801\n",
            "Name: O_47M, dtype: float64\n",
            "0.0    49.975524\n",
            "3.0    19.233405\n",
            "4.0    16.281574\n",
            "5.0     6.383395\n",
            "7.0     5.957509\n",
            "1.0     2.031525\n",
            "6.0     0.137067\n",
            "Name: O_47B, dtype: float64\n",
            "0.0    57.504892\n",
            "4.0    17.416830\n",
            "3.0    15.963796\n",
            "5.0     5.127202\n",
            "7.0     2.886497\n",
            "1.0     1.100783\n",
            "Name: O_46L, dtype: float64\n",
            "0.0    55.078278\n",
            "3.0    17.974560\n",
            "4.0    17.416830\n",
            "5.0     5.127202\n",
            "7.0     2.881605\n",
            "1.0     1.521526\n",
            "Name: O_46D, dtype: float64\n",
            "3.0    39.134474\n",
            "0.0    31.970660\n",
            "4.0    17.408313\n",
            "5.0     5.124694\n",
            "7.0     2.889976\n",
            "1.0     2.606357\n",
            "6.0     0.865526\n",
            "Name: O_46O, dtype: float64\n",
            "0.0    55.479452\n",
            "3.0    17.793542\n",
            "4.0    17.416830\n",
            "5.0     5.127202\n",
            "7.0     2.886497\n",
            "1.0     1.296477\n",
            "Name: O_46M, dtype: float64\n",
            "0.0    42.935421\n",
            "3.0    28.458904\n",
            "4.0    17.416830\n",
            "5.0     5.127202\n",
            "7.0     3.669276\n",
            "1.0     2.049902\n",
            "6.0     0.342466\n",
            "Name: O_46B, dtype: float64\n",
            "0.0    72.426308\n",
            "4.0     8.087694\n",
            "7.0     7.984698\n",
            "3.0     7.082250\n",
            "5.0     3.742214\n",
            "1.0     0.676836\n",
            "Name: O_45L, dtype: float64\n",
            "0.0    69.846486\n",
            "3.0     9.318750\n",
            "4.0     8.087694\n",
            "7.0     7.989602\n",
            "5.0     3.742214\n",
            "1.0     1.015253\n",
            "Name: O_45D, dtype: float64\n",
            "0.0    64.992643\n",
            "3.0    13.727317\n",
            "4.0     8.087298\n",
            "7.0     7.979402\n",
            "5.0     3.742030\n",
            "1.0     1.069152\n",
            "6.0     0.402158\n",
            "Name: O_45O, dtype: float64\n",
            "0.0    71.891706\n",
            "4.0     8.087694\n",
            "7.0     7.984698\n",
            "3.0     7.553092\n",
            "5.0     3.742214\n",
            "1.0     0.740595\n",
            "Name: O_45M, dtype: float64\n",
            "0.0    70.827407\n",
            "7.0     9.274609\n",
            "4.0     8.087694\n",
            "3.0     7.288244\n",
            "5.0     3.742214\n",
            "1.0     0.774928\n",
            "6.0     0.004905\n",
            "Name: O_45B, dtype: float64\n",
            "0.0    81.718536\n",
            "7.0     6.424936\n",
            "3.0     4.076140\n",
            "4.0     3.963594\n",
            "5.0     3.302995\n",
            "1.0     0.513799\n",
            "Name: O_44L, dtype: float64\n",
            "0.0    81.043257\n",
            "7.0     6.410256\n",
            "3.0     4.604619\n",
            "4.0     3.963594\n",
            "5.0     3.302995\n",
            "1.0     0.675279\n",
            "Name: O_44D, dtype: float64\n",
            "0.0    78.782541\n",
            "3.0     6.424936\n",
            "7.0     6.415150\n",
            "4.0     3.963594\n",
            "5.0     3.302995\n",
            "1.0     0.763359\n",
            "6.0     0.347426\n",
            "Name: O_44O, dtype: float64\n",
            "0.0    81.601096\n",
            "7.0     6.420043\n",
            "3.0     4.159327\n",
            "4.0     3.963594\n",
            "5.0     3.302995\n",
            "1.0     0.552946\n",
            "Name: O_44M, dtype: float64\n",
            "0.0    79.883539\n",
            "7.0     7.985907\n",
            "3.0     4.183793\n",
            "4.0     3.963594\n",
            "5.0     3.302995\n",
            "1.0     0.680172\n",
            "Name: O_44B, dtype: float64\n",
            "0.0    88.641589\n",
            "7.0     6.926576\n",
            "5.0     1.922418\n",
            "3.0     1.354987\n",
            "4.0     0.748422\n",
            "1.0     0.406007\n",
            "Name: O_43L, dtype: float64\n",
            "0.0    88.641589\n",
            "7.0     6.926576\n",
            "5.0     1.922418\n",
            "3.0     1.354987\n",
            "4.0     0.748422\n",
            "1.0     0.406007\n",
            "Name: O_43D, dtype: float64\n",
            "0.0    88.666047\n",
            "7.0     6.907010\n",
            "5.0     1.922418\n",
            "3.0     1.325637\n",
            "4.0     0.748422\n",
            "1.0     0.430465\n",
            "Name: O_43M, dtype: float64\n",
            "0.0    87.937191\n",
            "7.0     7.435308\n",
            "5.0     1.922418\n",
            "3.0     1.413687\n",
            "4.0     0.748422\n",
            "1.0     0.542973\n",
            "Name: O_43B, dtype: float64\n",
            "0.0    87.440397\n",
            "7.0     5.028757\n",
            "5.0     4.881286\n",
            "4.0     1.617264\n",
            "3.0     0.752101\n",
            "1.0     0.280195\n",
            "Name: O_42L, dtype: float64\n",
            "0.0    87.450229\n",
            "7.0     4.984516\n",
            "5.0     4.881286\n",
            "4.0     1.617264\n",
            "3.0     0.712776\n",
            "1.0     0.353930\n",
            "Name: O_42D, dtype: float64\n",
            "0.0    87.519048\n",
            "7.0     5.004178\n",
            "5.0     4.881286\n",
            "4.0     1.617264\n",
            "3.0     0.707860\n",
            "1.0     0.270363\n",
            "Name: O_42M, dtype: float64\n",
            "0.0    87.120877\n",
            "7.0     5.348277\n",
            "5.0     4.881286\n",
            "4.0     1.617264\n",
            "3.0     0.747186\n",
            "1.0     0.285110\n",
            "Name: O_42B, dtype: float64\n",
            "0.0    86.120909\n",
            "5.0     6.971389\n",
            "7.0     3.605722\n",
            "4.0     2.302567\n",
            "3.0     0.823045\n",
            "1.0     0.176367\n",
            "Name: O_41L, dtype: float64\n",
            "0.0    86.140506\n",
            "5.0     6.971389\n",
            "7.0     3.600823\n",
            "4.0     2.297668\n",
            "3.0     0.769155\n",
            "1.0     0.220459\n",
            "Name: O_41D, dtype: float64\n",
            "0.0    86.150304\n",
            "5.0     6.971389\n",
            "7.0     3.605722\n",
            "4.0     2.297668\n",
            "3.0     0.778954\n",
            "1.0     0.195963\n",
            "Name: O_41M, dtype: float64\n",
            "0.0    85.753478\n",
            "5.0     6.971389\n",
            "7.0     3.938859\n",
            "4.0     2.297668\n",
            "3.0     0.837743\n",
            "1.0     0.200862\n",
            "Name: O_41B, dtype: float64\n",
            "0.0    86.173964\n",
            "5.0     7.140758\n",
            "7.0     3.354883\n",
            "4.0     2.385150\n",
            "3.0     0.754236\n",
            "1.0     0.191008\n",
            "Name: O_31L, dtype: float64\n",
            "0.0    86.208248\n",
            "5.0     7.140758\n",
            "7.0     3.340190\n",
            "4.0     2.385150\n",
            "3.0     0.719953\n",
            "1.0     0.205701\n",
            "Name: O_31M, dtype: float64\n",
            "0.0    86.232736\n",
            "5.0     7.140758\n",
            "7.0     3.335292\n",
            "4.0     2.385150\n",
            "3.0     0.715055\n",
            "1.0     0.191008\n",
            "Name: O_31D, dtype: float64\n",
            "0.0    85.777255\n",
            "5.0     7.140758\n",
            "7.0     3.717308\n",
            "4.0     2.385150\n",
            "3.0     0.773827\n",
            "1.0     0.205701\n",
            "Name: O_31B, dtype: float64\n",
            "0.0    87.628259\n",
            "7.0     5.208896\n",
            "5.0     4.555943\n",
            "4.0     1.551377\n",
            "3.0     0.795326\n",
            "1.0     0.260199\n",
            "Name: O_32L, dtype: float64\n",
            "0.0    87.638077\n",
            "7.0     5.208896\n",
            "5.0     4.555943\n",
            "4.0     1.551377\n",
            "3.0     0.756051\n",
            "1.0     0.289656\n",
            "Name: O_32M, dtype: float64\n",
            "0.0    87.623349\n",
            "7.0     5.189258\n",
            "5.0     4.555943\n",
            "4.0     1.551377\n",
            "3.0     0.751141\n",
            "1.0     0.328931\n",
            "Name: O_32D, dtype: float64\n",
            "0.0    87.147135\n",
            "7.0     5.611468\n",
            "5.0     4.555943\n",
            "4.0     1.551377\n",
            "3.0     0.819873\n",
            "1.0     0.314203\n",
            "Name: O_32B, dtype: float64\n",
            "0.0    88.764430\n",
            "7.0     6.945803\n",
            "5.0     1.888085\n",
            "3.0     1.359812\n",
            "4.0     0.689689\n",
            "1.0     0.352182\n",
            "Name: O_33L, dtype: float64\n",
            "0.0    88.744864\n",
            "7.0     6.940912\n",
            "5.0     1.888085\n",
            "3.0     1.350029\n",
            "4.0     0.689689\n",
            "1.0     0.386421\n",
            "Name: O_33M, dtype: float64\n",
            "0.0    88.735081\n",
            "7.0     6.945803\n",
            "5.0     1.888085\n",
            "3.0     1.364704\n",
            "4.0     0.689689\n",
            "1.0     0.376639\n",
            "Name: O_33D, dtype: float64\n",
            "0.0    87.820387\n",
            "7.0     7.713755\n",
            "5.0     1.888085\n",
            "3.0     1.462532\n",
            "4.0     0.689689\n",
            "1.0     0.425553\n",
            "Name: O_33B, dtype: float64\n",
            "0.0    81.890688\n",
            "7.0     6.390370\n",
            "4.0     4.056368\n",
            "3.0     3.752997\n",
            "5.0     3.351764\n",
            "1.0     0.557812\n",
            "Name: O_34L, dtype: float64\n",
            "0.0    81.758575\n",
            "7.0     6.375691\n",
            "4.0     4.056368\n",
            "3.0     3.885110\n",
            "5.0     3.351764\n",
            "1.0     0.572491\n",
            "Name: O_34M, dtype: float64\n",
            "0.0    78.578069\n",
            "3.0     6.473553\n",
            "7.0     6.385477\n",
            "4.0     4.056368\n",
            "5.0     3.351764\n",
            "1.0     0.782894\n",
            "6.0     0.371875\n",
            "Name: O_34O, dtype: float64\n",
            "0.0    81.161619\n",
            "7.0     6.390370\n",
            "3.0     4.291236\n",
            "4.0     4.056368\n",
            "5.0     3.351764\n",
            "1.0     0.748642\n",
            "Name: O_34D, dtype: float64\n",
            "0.0    79.571366\n",
            "7.0     8.308460\n",
            "4.0     4.056368\n",
            "3.0     3.973186\n",
            "5.0     3.351764\n",
            "1.0     0.733963\n",
            "6.0     0.004893\n",
            "Name: O_34B, dtype: float64\n",
            "0.0    72.247301\n",
            "4.0     8.243376\n",
            "7.0     8.164868\n",
            "3.0     6.889107\n",
            "5.0     3.709519\n",
            "1.0     0.745829\n",
            "Name: O_35L, dtype: float64\n",
            "0.0    71.786065\n",
            "4.0     8.243376\n",
            "7.0     8.150147\n",
            "3.0     7.281649\n",
            "5.0     3.709519\n",
            "1.0     0.829244\n",
            "Name: O_35M, dtype: float64\n",
            "0.0    64.793916\n",
            "3.0    13.503435\n",
            "4.0     8.243376\n",
            "7.0     8.145240\n",
            "5.0     3.709519\n",
            "1.0     1.221786\n",
            "6.0     0.382728\n",
            "Name: O_35O, dtype: float64\n",
            "0.0    69.838077\n",
            "3.0     8.949951\n",
            "4.0     8.243376\n",
            "7.0     8.140334\n",
            "5.0     3.709519\n",
            "1.0     1.118744\n",
            "Name: O_35D, dtype: float64\n",
            "0.0    70.368008\n",
            "7.0     9.681060\n",
            "4.0     8.243376\n",
            "3.0     7.139352\n",
            "5.0     3.709519\n",
            "1.0     0.858685\n",
            "Name: O_35B, dtype: float64\n",
            "0.0    56.849315\n",
            "4.0    17.788650\n",
            "3.0    15.963796\n",
            "5.0     5.161448\n",
            "7.0     3.111546\n",
            "1.0     1.125245\n",
            "Name: O_36L, dtype: float64\n",
            "0.0    55.156556\n",
            "4.0    17.788650\n",
            "3.0    17.514677\n",
            "5.0     5.161448\n",
            "7.0     3.101761\n",
            "1.0     1.276908\n",
            "Name: O_36M, dtype: float64\n",
            "3.0    38.224939\n",
            "0.0    32.312958\n",
            "4.0    17.779951\n",
            "5.0     5.158924\n",
            "7.0     3.110024\n",
            "1.0     2.621027\n",
            "6.0     0.792176\n",
            "Name: O_36O, dtype: float64\n",
            "0.0    54.271037\n",
            "3.0    18.096869\n",
            "4.0    17.788650\n",
            "5.0     5.161448\n",
            "7.0     3.106654\n",
            "1.0     1.575342\n",
            "Name: O_36D, dtype: float64\n",
            "0.0    43.067515\n",
            "3.0    27.783757\n",
            "4.0    17.788650\n",
            "5.0     5.161448\n",
            "7.0     3.928571\n",
            "1.0     1.947162\n",
            "6.0     0.322896\n",
            "Name: O_36B, dtype: float64\n",
            "0.0    59.960851\n",
            "4.0    17.054074\n",
            "3.0     9.669684\n",
            "5.0     6.537803\n",
            "7.0     5.745045\n",
            "1.0     1.032542\n",
            "Name: O_37L, dtype: float64\n",
            "0.0    58.272572\n",
            "4.0    17.054074\n",
            "3.0    11.162222\n",
            "5.0     6.537803\n",
            "7.0     5.759726\n",
            "1.0     1.213604\n",
            "Name: O_37M, dtype: float64\n",
            "3.0    35.829950\n",
            "0.0    30.844871\n",
            "4.0    17.049068\n",
            "5.0     6.535884\n",
            "7.0     5.758035\n",
            "1.0     3.571254\n",
            "6.0     0.410939\n",
            "Name: O_37O, dtype: float64\n",
            "0.0    58.938096\n",
            "4.0    17.054074\n",
            "3.0    10.418400\n",
            "5.0     6.537803\n",
            "7.0     5.749939\n",
            "1.0     1.296795\n",
            "6.0     0.004894\n",
            "Name: O_37D, dtype: float64\n",
            "0.0    50.139467\n",
            "3.0    18.292146\n",
            "4.0    17.054074\n",
            "5.0     6.537803\n",
            "7.0     5.828236\n",
            "1.0     2.060191\n",
            "6.0     0.088084\n",
            "Name: O_37B, dtype: float64\n",
            "5.0    45.262288\n",
            "0.0    36.009913\n",
            "4.0    15.580339\n",
            "7.0     1.561338\n",
            "1.0     1.057414\n",
            "3.0     0.528707\n",
            "Name: O_38L, dtype: float64\n",
            "5.0    45.262288\n",
            "0.0    35.423379\n",
            "4.0    15.580339\n",
            "7.0     1.561338\n",
            "1.0     1.222635\n",
            "3.0     0.950021\n",
            "Name: O_38M, dtype: float64\n",
            "5.0    45.262288\n",
            "0.0    24.378356\n",
            "4.0    15.580339\n",
            "1.0     6.658406\n",
            "3.0     6.559273\n",
            "7.0     1.561338\n",
            "Name: O_38O, dtype: float64\n",
            "5.0    45.262288\n",
            "0.0    35.671210\n",
            "4.0    15.580339\n",
            "7.0     1.561338\n",
            "1.0     1.288724\n",
            "3.0     0.636101\n",
            "Name: O_38D, dtype: float64\n",
            "5.0    45.262288\n",
            "0.0    34.927716\n",
            "4.0    15.580339\n",
            "7.0     1.561338\n",
            "1.0     1.544816\n",
            "3.0     1.123503\n",
            "Name: O_38B, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_85L, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_85D, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_85O, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_85M, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_85B, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_84L, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_84D, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_84O, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_84M, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_84B, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_83L, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_83D, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_83M, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_83B, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_82L, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_82D, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_82M, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_82B, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_81L, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_81D, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_81M, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_81B, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_71L, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_71M, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_71D, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_71B, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_72L, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_72M, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_72D, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_72B, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_73L, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_73M, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_73D, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_73B, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_74L, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_74M, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_74O, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_74D, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_74B, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_75L, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_75M, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_75O, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_75D, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_75B, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_TN55, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_TN54, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_TN53, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_TN52, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_TN51, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_TN61, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_TN62, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_TN63, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_TN64, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_TN65, dtype: float64\n",
            "0.0    95.597608\n",
            "6.0     2.465928\n",
            "1.0     1.627611\n",
            "2.0     0.171585\n",
            "7.0     0.117659\n",
            "5.0     0.014707\n",
            "3.0     0.004902\n",
            "Name: O_TN18, dtype: float64\n",
            "0.0    94.929095\n",
            "1.0     2.503667\n",
            "6.0     1.036675\n",
            "2.0     0.929095\n",
            "5.0     0.254279\n",
            "7.0     0.180929\n",
            "3.0     0.166259\n",
            "Name: O_TN17, dtype: float64\n",
            "0.0    96.474328\n",
            "6.0     1.061125\n",
            "2.0     0.885086\n",
            "1.0     0.870416\n",
            "5.0     0.278729\n",
            "3.0     0.239609\n",
            "7.0     0.190709\n",
            "Name: O_TN16, dtype: float64\n",
            "0.0    98.073632\n",
            "6.0     0.806728\n",
            "2.0     0.488926\n",
            "5.0     0.220017\n",
            "1.0     0.146678\n",
            "7.0     0.132010\n",
            "3.0     0.132010\n",
            "Name: O_TN15, dtype: float64\n",
            "0.0    98.205642\n",
            "6.0     0.723610\n",
            "2.0     0.459590\n",
            "5.0     0.220017\n",
            "1.0     0.195570\n",
            "7.0     0.097785\n",
            "3.0     0.097785\n",
            "Name: O_TN14, dtype: float64\n",
            "0.0    98.806846\n",
            "6.0     0.498778\n",
            "1.0     0.268949\n",
            "2.0     0.190709\n",
            "5.0     0.107579\n",
            "7.0     0.073350\n",
            "3.0     0.053790\n",
            "Name: O_TN13, dtype: float64\n",
            "0.0    98.298455\n",
            "1.0     0.503618\n",
            "2.0     0.484060\n",
            "6.0     0.376491\n",
            "5.0     0.185801\n",
            "7.0     0.088011\n",
            "3.0     0.063563\n",
            "Name: O_TN12, dtype: float64\n",
            "0.0    98.405712\n",
            "2.0     0.537950\n",
            "1.0     0.410798\n",
            "6.0     0.264085\n",
            "7.0     0.151604\n",
            "5.0     0.151604\n",
            "3.0     0.078247\n",
            "Name: O_TN11, dtype: float64\n",
            "0.0    98.469512\n",
            "2.0     0.464525\n",
            "1.0     0.420517\n",
            "6.0     0.278715\n",
            "5.0     0.161361\n",
            "7.0     0.136913\n",
            "3.0     0.068456\n",
            "Name: O_TN21, dtype: float64\n",
            "0.0    98.440098\n",
            "1.0     0.459658\n",
            "6.0     0.430318\n",
            "2.0     0.352078\n",
            "5.0     0.171149\n",
            "7.0     0.097800\n",
            "3.0     0.048900\n",
            "Name: O_TN22, dtype: float64\n",
            "0.0    98.689422\n",
            "6.0     0.528143\n",
            "2.0     0.293413\n",
            "1.0     0.205389\n",
            "5.0     0.151597\n",
            "7.0     0.068463\n",
            "3.0     0.063573\n",
            "Name: O_TN23, dtype: float64\n",
            "0.0    98.190532\n",
            "6.0     0.762911\n",
            "2.0     0.405908\n",
            "5.0     0.229851\n",
            "1.0     0.205399\n",
            "7.0     0.112480\n",
            "3.0     0.092919\n",
            "Name: O_TN24, dtype: float64\n",
            "0.0    98.195687\n",
            "6.0     0.709012\n",
            "2.0     0.474304\n",
            "5.0     0.244487\n",
            "1.0     0.151582\n",
            "7.0     0.132023\n",
            "3.0     0.092905\n",
            "Name: O_TN25, dtype: float64\n",
            "0.0    96.405692\n",
            "6.0     1.066067\n",
            "2.0     0.924251\n",
            "1.0     0.870458\n",
            "5.0     0.278742\n",
            "7.0     0.244511\n",
            "3.0     0.210279\n",
            "Name: O_TN26, dtype: float64\n",
            "0.0    95.242286\n",
            "1.0     2.239499\n",
            "6.0     0.992616\n",
            "2.0     0.894822\n",
            "5.0     0.254266\n",
            "7.0     0.200479\n",
            "3.0     0.176031\n",
            "Name: O_TN27, dtype: float64\n",
            "0.0    95.866026\n",
            "6.0     2.373480\n",
            "1.0     1.485877\n",
            "2.0     0.152020\n",
            "7.0     0.093174\n",
            "5.0     0.019616\n",
            "3.0     0.009808\n",
            "Name: O_TN28, dtype: float64\n",
            "0.0    95.956661\n",
            "6.0     2.285151\n",
            "1.0     1.442994\n",
            "2.0     0.206846\n",
            "7.0     0.083723\n",
            "5.0     0.014775\n",
            "3.0     0.009850\n",
            "Name: O_TN48, dtype: float64\n",
            "0.0    95.535452\n",
            "1.0     2.141809\n",
            "6.0     0.919315\n",
            "2.0     0.718826\n",
            "5.0     0.322738\n",
            "7.0     0.224939\n",
            "3.0     0.136919\n",
            "Name: O_TN47, dtype: float64\n",
            "0.0    96.204451\n",
            "1.0     1.237466\n",
            "6.0     0.899976\n",
            "2.0     0.782587\n",
            "5.0     0.376620\n",
            "3.0     0.303253\n",
            "7.0     0.195647\n",
            "Name: O_TN46, dtype: float64\n",
            "0.0    98.459808\n",
            "6.0     0.620966\n",
            "2.0     0.356933\n",
            "1.0     0.205359\n",
            "5.0     0.156464\n",
            "7.0     0.117348\n",
            "3.0     0.083121\n",
            "Name: O_TN45, dtype: float64\n",
            "0.0    98.777566\n",
            "6.0     0.430297\n",
            "1.0     0.229818\n",
            "2.0     0.220038\n",
            "5.0     0.136913\n",
            "7.0     0.107574\n",
            "3.0     0.097795\n",
            "Name: O_TN44, dtype: float64\n",
            "0.0    99.163896\n",
            "6.0     0.308038\n",
            "2.0     0.146685\n",
            "1.0     0.122237\n",
            "5.0     0.102679\n",
            "7.0     0.092900\n",
            "3.0     0.063563\n",
            "Name: O_TN43, dtype: float64\n",
            "0.0    99.398592\n",
            "6.0     0.200469\n",
            "7.0     0.132016\n",
            "2.0     0.097790\n",
            "5.0     0.063563\n",
            "3.0     0.053784\n",
            "1.0     0.053784\n",
            "Name: O_TN42, dtype: float64\n",
            "0.0    99.550078\n",
            "7.0     0.176056\n",
            "6.0     0.136933\n",
            "2.0     0.048905\n",
            "1.0     0.039124\n",
            "5.0     0.029343\n",
            "3.0     0.019562\n",
            "Name: O_TN41, dtype: float64\n",
            "0.0    99.550144\n",
            "7.0     0.180920\n",
            "6.0     0.156472\n",
            "5.0     0.034228\n",
            "2.0     0.034228\n",
            "1.0     0.024449\n",
            "3.0     0.019559\n",
            "Name: O_TN31, dtype: float64\n",
            "0.0    99.467045\n",
            "6.0     0.200469\n",
            "7.0     0.107569\n",
            "2.0     0.097790\n",
            "1.0     0.053784\n",
            "5.0     0.044005\n",
            "3.0     0.029337\n",
            "Name: O_TN32, dtype: float64\n",
            "0.0    99.344775\n",
            "6.0     0.249377\n",
            "1.0     0.132023\n",
            "2.0     0.078236\n",
            "7.0     0.073346\n",
            "5.0     0.073346\n",
            "3.0     0.048897\n",
            "Name: O_TN33, dtype: float64\n",
            "0.0    98.797184\n",
            "6.0     0.474281\n",
            "1.0     0.220027\n",
            "2.0     0.190690\n",
            "5.0     0.117348\n",
            "3.0     0.112458\n",
            "7.0     0.088011\n",
            "Name: O_TN34, dtype: float64\n",
            "0.0    98.317931\n",
            "6.0     0.645445\n",
            "2.0     0.332502\n",
            "1.0     0.249377\n",
            "5.0     0.200479\n",
            "3.0     0.136913\n",
            "7.0     0.117354\n",
            "Name: O_TN35, dtype: float64\n",
            "0.0    96.161369\n",
            "1.0     1.227384\n",
            "6.0     0.963325\n",
            "2.0     0.811736\n",
            "5.0     0.352078\n",
            "3.0     0.332518\n",
            "7.0     0.151589\n",
            "Name: O_TN36, dtype: float64\n",
            "0.0    95.491663\n",
            "1.0     2.190602\n",
            "6.0     0.909491\n",
            "2.0     0.704122\n",
            "5.0     0.410738\n",
            "3.0     0.185810\n",
            "7.0     0.107574\n",
            "Name: O_TN37, dtype: float64\n",
            "0.0    95.812808\n",
            "6.0     2.241379\n",
            "1.0     1.581281\n",
            "2.0     0.211823\n",
            "7.0     0.123153\n",
            "5.0     0.014778\n",
            "3.0     0.014778\n",
            "Name: O_TN38, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_TN85, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_TN84, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_TN83, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_TN82, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_TN81, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_TN71, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_TN72, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_TN73, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_TN74, dtype: float64\n",
            "0.0    100.0\n",
            "Name: O_TN75, dtype: float64\n",
            "0.0    66.672003\n",
            "1.0    12.571368\n",
            "3.0    11.915053\n",
            "2.0     6.269676\n",
            "4.0     2.571901\n",
            "Name: O_CPI_LR, dtype: float64\n",
            "2.0    53.816565\n",
            "0.0    38.505345\n",
            "3.0     3.636727\n",
            "1.0     3.192127\n",
            "4.0     0.849236\n",
            "Name: O_CPI_LM, dtype: float64\n",
            "0.0    69.784384\n",
            "1.0    30.215616\n",
            "Name: NO_CPI_34, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mQBl-4bBc_a7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##신경망 모형 학습을 위한 데이터 분리 및 모형 구축"
      ]
    },
    {
      "metadata": {
        "id": "KKv1tV6EWI8D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 피쳐와 타겟을 분리한다.\n",
        "\n",
        "periodontitis = dt[['NO_CPI_34']]\n",
        "features_dt = dt.drop(columns = ['NO_CPI_34'], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eYeijsxAWI8O",
        "colab_type": "code",
        "outputId": "2211ab54-c70f-41c3-be17-0bb31231e001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "periodontitis.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NO_CPI_34</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6224</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6226</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6227</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6228</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6229</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     NO_CPI_34\n",
              "6224       1.0\n",
              "6226       0.0\n",
              "6227       0.0\n",
              "6228       0.0\n",
              "6229       0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "CZ9_g5FtWI8R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features_dt_sc =  pd.get_dummies(features_dt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "85YSdHLOWI8W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train데이터와 Test를 나눈다.\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_dt_sc, periodontitis, random_state=20181121)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "_1vgJ3O-WI8e",
        "colab_type": "code",
        "outputId": "f9d9ebad-c35e-42a1-f136-248eb3909777",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "cell_type": "code",
      "source": [
        "# test set 의 target 빈도 확인\n",
        "import matplotlib.pyplot as plt\n",
        "y_train['NO_CPI_34'].value_counts().plot(kind='bar')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFOCAYAAACvyZWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAFXpJREFUeJzt3X9MVff9x/HXhcsdob0MLrmnCY0j\nq0tqYhBLXJ0g61DYMrfky9JiheC26JKRsa5bSJUQY107W6pj6cyYXeyMxE2lpd3G1zRAOrFZ55Wt\nuwlhJs1W/1isdtx7EyjIj4F6v38su9NvsdrLxdP35fn4Sz/3HHyf5J487zkH0BOPx+MCAABmZLg9\nAAAA+GiINwAAxhBvAACMId4AABhDvAEAMIZ4AwBgjNftAW5XNDrh9ghYgPz8HI2OTrk9BrDkcO7Z\nFgz6513nyht3hNeb6fYIwJLEuZeeiDcAAMYQbwAAjCHeAAAYQ7wBADCGeAMAYAzxBgDAGOINAIAx\nxBsAAGOINwAAxhBvAACMId4AABhDvAEAMMbM/yqW7ra1nXJ7BCzA4ZYNbo8AYAnhyhsAAGOINwAA\nxhBvAACMId4AABhDvAEAMIZ4AwBgDPEGAMAY4g0AgDHEGwAAY4g3AADGEG8AAIwh3gAAGEO8AQAw\n5rbi/be//U1VVVX61a9+JUl67733tHXrVtXX1+vxxx/X7OysJKmnp0cPP/ywamtr9fLLL0uS5ubm\n1NzcrLq6OjU0NOjChQuSpLfffltbtmzRli1b9OSTTy7GsQEAkJZuGe+pqSk9/fTTWrduXWLtwIED\nqq+v17Fjx1RUVKTu7m5NTU2po6NDR44c0dGjR9XZ2amxsTGdPHlSubm5On78uBobG9Xe3i5J2rt3\nr1pbW3XixAldvnxZb7zxxuIdJQAAaeSW8fb5fDp06JAcx0msDQ4OauPGjZKkyspKhUIhDQ0Nqbi4\nWH6/X9nZ2SotLVU4HFYoFFJ1dbUkqaysTOFwWLOzs7p48aJWrVp1w9cAAAC35r3lBl6vvN4bN5ue\nnpbP55MkFRQUKBqNKhaLKRAIJLYJBAIfWM/IyJDH41EsFlNubm5i2/98DQAAcGu3jPetxOPxBa/f\nbNvr5efnyOvN/GjDAXdIMOh3ewTgpnh/pp+k4p2Tk6OZmRllZ2drZGREjuPIcRzFYrHENpFIRKtX\nr5bjOIpGo1qxYoXm5uYUj8cVDAY1NjaW2PY/X+PDjI5OJTMqcEdEoxNujwDMKxj08/407GYfvJL6\nUbGysjL19fVJkvr7+1VRUaGSkhINDw9rfHxck5OTCofDWrNmjcrLy9Xb2ytJGhgY0Nq1a5WVlaX7\n7rtPb7311g1fAwAA3Notr7z/+te/6rnnntPFixfl9XrV19enH//4x2ppaVFXV5cKCwtVU1OjrKws\nNTc3a/v27fJ4PGpqapLf79emTZt05swZ1dXVyefzqa2tTZLU2tqq3bt369q1ayopKVFZWdmiHywA\nAOnAE7+dB84fA+l+22db2ym3R8ACHG7Z4PYIwLy4bW5bSm+bAwAA9xBvAACMId4AABhDvAEAMIZ4\nAwBgDPEGAMAY4g0AgDHEGwAAY4g3AADGEG8AAIwh3gAAGEO8AQAwhngDAGAM8QYAwBjiDQCAMcQb\nAABjiDcAAMYQbwAAjCHeAAAYQ7wBADCGeAMAYAzxBgDAGOINAIAxxBsAAGOINwAAxhBvAACMId4A\nABhDvAEAMIZ4AwBgDPEGAMAY4g0AgDHEGwAAY4g3AADGEG8AAIwh3gAAGEO8AQAwhngDAGAM8QYA\nwBjiDQCAMcQbAABjiDcAAMYQbwAAjCHeAAAYQ7wBADCGeAMAYIw3mZ0mJye1c+dOvf/++5qbm1NT\nU5OCwaD27NkjSbr//vv1wx/+UJL04osvqre3Vx6PR9/97nf10EMPaWJiQs3NzZqYmFBOTo7a29uV\nl5eXsoMCACCdJRXv3/zmN/r0pz+t5uZmjYyM6Bvf+IaCwaBaW1u1atUqNTc364033tB9992n1157\nTSdOnNDly5dVX1+v9evXq7OzUw8++KC+9a1vqaurS4cOHdITTzyR6mMDACAtJXXbPD8/X2NjY5Kk\n8fFx5eXl6eLFi1q1apUkqbKyUqFQSIODg6qoqJDP51MgENC9996rd955R6FQSNXV1TdsCwAAbk9S\nV95f+cpX9Oqrr6q6ulrj4+M6ePCgnnrqqcTrBQUFikajysvLUyAQSKwHAgFFo1HFYrHEekFBgSKR\nyC3/zfz8HHm9mcmMCyy6YNDv9gjATfH+TD9Jxft3v/udCgsL9ctf/lJvv/22mpqa5Pf/980Rj8fn\n3W++9Ztt+/+Njk4lMypwR0SjE26PAMwrGPTz/jTsZh+8krptHg6HtX79eknSihUr9K9//Uujo6OJ\n10dGRuQ4jhzHUSwWm3c9Go3esAYAAG5PUvEuKirS0NCQJOnixYu66667tHz5cr311luSpP7+flVU\nVOhzn/ucTp8+rdnZWY2MjCgSiegzn/mMysvL1dvbe8O2AADg9iR12/zRRx9Va2urGhoadOXKFe3Z\ns0fBYFC7d+/WtWvXVFJSorKyMknS5s2b1dDQII/Hoz179igjI0Nbt27VE088ofr6euXm5mr//v0p\nPSgAANKZJ367D51dlu7PbLa1nXJ7BCzA4ZYNbo8AzItn3ral9Jk3AABwD/EGAMAY4g0AgDHEGwAA\nY4g3AADGEG8AAIwh3gAAGEO8AQAwhngDAGAM8QYAwBjiDQCAMcQbAABjiDcAAMYQbwAAjCHeAAAY\nQ7wBADCGeAMAYAzxBgDAGOINAIAxxBsAAGOINwAAxhBvAACMId4AABhDvAEAMIZ4AwBgDPEGAMAY\n4g0AgDHEGwAAY4g3AADGEG8AAIwh3gAAGEO8AQAwhngDAGAM8QYAwBjiDQCAMcQbAABjiDcAAMYQ\nbwAAjCHeAAAYQ7wBADCGeAMAYAzxBgDAGOINAIAxxBsAAGO8ye7Y09OjF198UV6vV9/73vd0//33\na8eOHbp69aqCwaD2798vn8+nnp4edXZ2KiMjQ5s3b1Ztba3m5ubU0tKiS5cuKTMzU88++6yWLVuW\nyuMCACBtJXXlPTo6qo6ODh07dkwvvPCCfv/73+vAgQOqr6/XsWPHVFRUpO7ubk1NTamjo0NHjhzR\n0aNH1dnZqbGxMZ08eVK5ubk6fvy4Ghsb1d7enurjAgAgbSUV71AopHXr1unuu++W4zh6+umnNTg4\nqI0bN0qSKisrFQqFNDQ0pOLiYvn9fmVnZ6u0tFThcFihUEjV1dWSpLKyMoXD4dQdEQAAaS6p2+bv\nvvuuZmZm1NjYqPHxcT322GOanp6Wz+eTJBUUFCgajSoWiykQCCT2CwQCH1jPyMiQx+PR7OxsYn8A\nAHBzST/zHhsb089+9jNdunRJX//61xWPxxOvXf/n633U9evl5+fI681MblhgkQWDfrdHAG6K92f6\nSSreBQUFeuCBB+T1evWpT31Kd911lzIzMzUzM6Ps7GyNjIzIcRw5jqNYLJbYLxKJaPXq1XIcR9Fo\nVCtWrNDc3Jzi8fgtr7pHR6eSGRW4I6LRCbdHAOYVDPp5fxp2sw9eST3zXr9+vc6ePatr165pdHRU\nU1NTKisrU19fnySpv79fFRUVKikp0fDwsMbHxzU5OalwOKw1a9aovLxcvb29kqSBgQGtXbs2ycMC\nAGDpSerK+5577tGXvvQlbd68WZK0a9cuFRcXa+fOnerq6lJhYaFqamqUlZWl5uZmbd++XR6PR01N\nTfL7/dq0aZPOnDmjuro6+Xw+tbW1pfSgAABIZ5747Txw/hhI99s+29pOuT0CFuBwywa3RwDmxW1z\n21J62xwAALiHeAMAYAzxBgDAGOINAIAxxBsAAGOINwAAxhBvAACMId4AABhDvAEAMIZ4AwBgDPEG\nAMAY4g0AgDHEGwAAY4g3AADGEG8AAIwh3gAAGEO8AQAwhngDAGAM8QYAwBjiDQCAMcQbAABjiDcA\nAMYQbwAAjCHeAAAYQ7wBADCGeAMAYAzxBgDAGOINAIAxxBsAAGOINwAAxnjdHgAA3NR0aofbI2AB\nOjbsc3sEV3DlDQCAMcQbAABjiDcAAMYQbwAAjCHeAAAYQ7wBADCGeAMAYAzxBgDAGOINAIAxxBsA\nAGOINwAAxhBvAACMId4AABizoHjPzMyoqqpKr776qt577z1t3bpV9fX1evzxxzU7OytJ6unp0cMP\nP6za2lq9/PLLkqS5uTk1Nzerrq5ODQ0NunDhwsKPBACAJWJB8T548KA++clPSpIOHDig+vp6HTt2\nTEVFReru7tbU1JQ6Ojp05MgRHT16VJ2dnRobG9PJkyeVm5ur48ePq7GxUe3t7Sk5GAAAloKk433+\n/Hm98847+sIXviBJGhwc1MaNGyVJlZWVCoVCGhoaUnFxsfx+v7Kzs1VaWqpwOKxQKKTq6mpJUllZ\nmcLh8MKPBACAJSLpeD/33HNqaWlJ/H16elo+n0+SVFBQoGg0qlgspkAgkNgmEAh8YD0jI0Mejydx\nmx0AAHw4bzI7/fa3v9Xq1au1bNmyeV+Px+MpWb9efn6OvN7M2x8SuIOCQb/bIwBL0lI995KK9+nT\np3XhwgWdPn1a//znP+Xz+ZSTk6OZmRllZ2drZGREjuPIcRzFYrHEfpFIRKtXr5bjOIpGo1qxYoXm\n5uYUj8cTV+03Mzo6lcyowB0RjU64PQKwJKX7uXezDydJ3TZ//vnn9corr+ill15SbW2tvvOd76is\nrEx9fX2SpP7+flVUVKikpETDw8MaHx/X5OSkwuGw1qxZo/LycvX29kqSBgYGtHbt2iQPCwCApSep\nK+/5PPbYY9q5c6e6urpUWFiompoaZWVlqbm5Wdu3b5fH41FTU5P8fr82bdqkM2fOqK6uTj6fT21t\nbakaAwCAtOeJ384D54+BdL81sq3tlNsjYAEOt2xwewQkqenUDrdHwAJ0bNjn9giLKqW3zQEAgHuI\nNwAAxhBvAACMId4AABhDvAEAMIZ4AwBgDPEGAMAY4g0AgDHEGwAAY4g3AADGEG8AAIwh3gAAGEO8\nAQAwhngDAGAM8QYAwBjiDQCAMcQbAABjiDcAAMYQbwAAjCHeAAAYQ7wBADCGeAMAYAzxBgDAGOIN\nAIAxxBsAAGOINwAAxhBvAACMId4AABhDvAEAMIZ4AwBgDPEGAMAY4g0AgDHEGwAAY4g3AADGEG8A\nAIwh3gAAGEO8AQAwhngDAGAM8QYAwBjiDQCAMcQbAABjiDcAAMYQbwAAjCHeAAAYQ7wBADDGm+yO\n+/bt01/+8hdduXJF3/72t1VcXKwdO3bo6tWrCgaD2r9/v3w+n3p6etTZ2amMjAxt3rxZtbW1mpub\nU0tLiy5duqTMzEw9++yzWrZsWSqPCwCAtJVUvM+ePau///3v6urq0ujoqL72ta9p3bp1qq+v15e/\n/GX95Cc/UXd3t2pqatTR0aHu7m5lZWXpkUceUXV1tQYGBpSbm6v29na9+eabam9v1/PPP5/qYwMA\nIC0lddv8s5/9rH76059KknJzczU9Pa3BwUFt3LhRklRZWalQKKShoSEVFxfL7/crOztbpaWlCofD\nCoVCqq6uliSVlZUpHA6n6HAAAEh/SV15Z2ZmKicnR5LU3d2tz3/+83rzzTfl8/kkSQUFBYpGo4rF\nYgoEAon9AoHAB9YzMjLk8Xg0Ozub2H8++fk58nozkxkXWHTBoN/tEYAlaamee0k/85ak119/Xd3d\n3Tp8+LC++MUvJtbj8fi823/U9euNjk4lNyRwB0SjE26PACxJ6X7u3ezDSdLfbf6HP/xBL7zwgg4d\nOiS/36+cnBzNzMxIkkZGRuQ4jhzHUSwWS+wTiUQS69FoVJI0NzeneDz+oVfdAADgv5KK98TEhPbt\n26df/OIXysvLk/TvZ9d9fX2SpP7+flVUVKikpETDw8MaHx/X5OSkwuGw1qxZo/LycvX29kqSBgYG\ntHbt2hQdDgAA6S+p2+avvfaaRkdH9f3vfz+x1tbWpl27dqmrq0uFhYWqqalRVlaWmpubtX37dnk8\nHjU1Ncnv92vTpk06c+aM6urq5PP51NbWlrIDAgAg3Xnit/PA+WMg3Z9rbGs75fYIWIDDLRvcHgFJ\najq1w+0RsAAdG/a5PcKiSvkzbwAA4A7iDQCAMcQbAABjiDcAAMYQbwAAjCHeAAAYQ7wBADCGeAMA\nYAzxBgDAGOINAIAxxBsAAGOINwAAxhBvAACMId4AABhDvAEAMIZ4AwBgDPEGAMAY4g0AgDHEGwAA\nY4g3AADGEG8AAIwh3gAAGEO8AQAwhngDAGAM8QYAwBjiDQCAMcQbAABjiDcAAMYQbwAAjCHeAAAY\nQ7wBADCGeAMAYAzxBgDAGOINAIAxxBsAAGOINwAAxhBvAACMId4AABhDvAEAMIZ4AwBgDPEGAMAY\n4g0AgDHEGwAAY4g3AADGeN38x5955hkNDQ3J4/GotbVVq1atcnMcAABMcC3ef/rTn/SPf/xDXV1d\nOn/+vFpbW9XV1eXWOAAAmOHabfNQKKSqqipJ0vLly/X+++/r8uXLbo0DAIAZrsU7FospPz8/8fdA\nIKBoNOrWOAAAmOHqM+/rxePxD309GPTfoUnc8b/t/+P2CMCS9NKjB90eAfjIXLvydhxHsVgs8fdI\nJKJgMOjWOAAAmOFavMvLy9XX1ydJOnfunBzH0d133+3WOAAAmOHabfPS0lKtXLlSW7Zskcfj0ZNP\nPunWKAAAmOKJ3+phMwAA+FjhN6wBAGAM8QYAwBjiDQCAMcQbAABjPja/pAXp4/z58zp79qwikYik\nf/9M//r161VUVOTyZED64/xbGvhuc6TUz3/+c/3xj3/UQw89pEAgoHg8rpGREZ0+fVpf/epX9c1v\nftPtEYG0xfm3dBBvpNSWLVt0/PhxeTyeG9avXLmihoYGnThxwqXJgPTH+bd08MwbKXX16tXE7brr\nzbcGILU4/5YOnnkjpX7wgx9o27ZtysvLUyAQkCRFo1FNTk7yW/SARcb5t3Rw2xyL4sKFC4n/eMZx\nHN17770uTwQsHZx/6Y944455/fXXVVVV5fYYwJLE+ZdeuG2ORTE5OZn45B8MBpWTk6OJiQmXpwKW\nrnfffdftEZBCxBspNTw8rL1792p8fFz5+fmKx+OKRCK65557tHv3brfHA5asU6dO8aNiaYR4I6We\neeYZ7d27V8uXL79h/dy5c3rqqaf061//2qXJgPT3YefXyMjIHZwEi414I6Xi8fgHwi1JK1eu1NWr\nV12YCFg6jhw5onXr1slxnA+8duXKFRcmwmIh3kipkpISNTY2qqqqKvGjKrFYTH19fXrwwQddng5I\nbx0dHfrRj36kXbt2yefz3fDa4OCgS1NhMfDd5ki5P//5zwqFQjf8qEp5ebkeeOABlycD0t/09LQ+\n8YlPKCPjxt/Bde7cOa1cudKlqZBqxBsAAGP49agAABhDvAEAMIZ4AwBgDPEGAMAY4g0AgDH/B7vb\nvO3w6DkNAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1929bc3d30>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "TTS5EWNmeBaM",
        "colab_type": "code",
        "outputId": "38c2daa0-1fa1-4f19-c539-ca927d88ecd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "cell_type": "code",
      "source": [
        "# test set 의 target 비율확인\n",
        "rate = (y_train['NO_CPI_34'].value_counts()/y_train['NO_CPI_34'].count())*100 \n",
        "xaxis = (0, 1)\n",
        "plt.bar(xaxis, rate)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Container object of 2 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFKCAYAAABcq1WoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAFo9JREFUeJzt3X9sVfX9x/FX6eWua6nQlnsrnYLT\noTAQhglbWihYCpqyLdZFtNwoOhkbE2pdROiwCsa48aM2k82MDaRZXLo1dIzUxa3N/MJi3KXCRpzM\nZYCJSy1wvbCiZW1HKef7h+GmDL2n1t53e0+fj796z7339P3J9fjsPbc9pDiO4wgAAJgZNdQDAAAw\n0hBfAACMEV8AAIwRXwAAjBFfAACMEV8AAIz5LL5JNNph8W2GRFZWutrbO4d6jIRhfcnP62tkfcnP\nq2sMBDI/9j7e+X5KPl/qUI+QUKwv+Xl9jawv+Y2ENf4v4gsAgDHiCwCAMeILAIAx4gsAgDHiCwCA\nMeILAIAx4gsAgDHXi2zs3r1bjY2NsdtHjhzRr371K23cuFGSdNNNN+mpp55K2IAAAHiNa3yXLFmi\nJUuWSJJef/11/f73v9czzzyj9evXa8aMGXr00Uf1pz/9SfPnz0/4sAAAeMEnOu38/PPPa8WKFWpr\na9OMGTMkSUVFRQqHwwkZDgAAL+r3tZ3/9re/acKECUpNTdVVV10V256Tk6NoNBr3uVlZ6Z6+fFi8\n63d6AetLfl5fI+tLfiNhjX31O74NDQ268847r9juOI7rc714wexLAoFMT//DEawv+Xl9jawv+Xl1\njfF+oOh3fFtaWlRVVaWUlBSdPXs2tj0SiSgYDH66CQfgwU3/Z/49gUTZVblgqEcAYKhfn/lGIhFl\nZGTI7/dr9OjRuv7663Xo0CFJUnNzswoLCxM6JAAAXtKvd77RaFTZ2dmx2+vXr9eTTz6pixcvaubM\nmSooKEjYgAAAeE2/4jt9+nTt3LkzdvsLX/iC6urqEjYUAABexhWuAAAwRnwBADBGfAEAMEZ8AQAw\nRnwBADBGfAEAMEZ8AQAwRnwBADBGfAEAMEZ8AQAwRnwBADBGfAEAMEZ8AQAwRnwBADBGfAEAMEZ8\nAQAwRnwBADBGfAEAMEZ8AQAwRnwBADBGfAEAMEZ8AQAwRnwBADBGfAEAMEZ8AQAwRnwBADBGfAEA\nMEZ8AQAwRnwBADBGfAEAMEZ8AQAwRnwBADDm68+DGhsbtXPnTvl8Pj388MO66aabtHbtWvX29ioQ\nCGjr1q3y+/2JnhUAAE9wfefb3t6u559/XnV1ddq+fbteeeUVbdu2TaFQSHV1dZo0aZIaGhosZgUA\nwBNc4xsOh5Wfn68xY8YoGAzq6aefVktLi4qLiyVJRUVFCofDCR8UAACvcD3t/O6776q7u1srV67U\nBx98oPLycnV1dcVOM+fk5CgajcbdR1ZWuny+1MGZGPCgQCAzqfc/1Fhf8hsJa+yrX5/5nj17Vj/5\nyU904sQJLVu2TI7jxO7r+/XHaW/vHPiEwAgQjXYkbN+BQGZC9z/UWF/y8+oa4/1A4XraOScnR7Nm\nzZLP59PEiROVkZGhjIwMdXd3S5IikYiCweDgTQsAgMe5xnfu3Lk6cOCALl68qPb2dnV2dqqgoEBN\nTU2SpObmZhUWFiZ8UAAAvML1tHNubq5uv/123X333ZKkqqoq3XzzzVq3bp3q6+uVl5en0tLShA8K\nAIBX9Osz37KyMpWVlV22rba2NiEDAQDgdVzhCgAAY8QXAABjxBcAAGPEFwAAY8QXAABjxBcAAGPE\nFwAAY8QXAABjxBcAAGPEFwAAY8QXAABjxBcAAGPEFwAAY8QXAABjxBcAAGPEFwAAY8QXAABjxBcA\nAGPEFwAAY8QXAABjxBcAAGPEFwAAY8QXAABjxBcAAGPEFwAAY8QXAABjxBcAAGPEFwAAY8QXAABj\nxBcAAGPEFwAAYz63B7S0tKiiokKTJ0+WJN1444361re+pbVr16q3t1eBQEBbt26V3+9P+LAAAHiB\na3wl6ctf/rK2bdsWu/39739foVBIJSUlqqmpUUNDg0KhUMKGBADASwZ02rmlpUXFxcWSpKKiIoXD\n4UEdCgAAL+vXO9/jx49r5cqVev/997V69Wp1dXXFTjPn5OQoGo0mdEgAALzENb7XXXedVq9erZKS\nErW2tmrZsmXq7e2N3e84jus3ycpKl8+X+ukmBTwsEMhM6v0PNdaX/EbCGvtyjW9ubq4WL14sSZo4\ncaLGjx+vN998U93d3UpLS1MkElEwGIy7j/b2zsGZFvCoaLQjYfsOBDITuv+hxvqSn1fXGO8HCtfP\nfBsbG/XCCy9IkqLRqM6cOaNvfOMbampqkiQ1NzersLBwkEYFAMD7XN/5LliwQGvWrNErr7yinp4e\nbdy4UVOnTtW6detUX1+vvLw8lZaWWswKAIAnuMZ3zJgx2r59+xXba2trEzIQAABexxWuAAAwRnwB\nADBGfAEAMEZ8AQAwRnwBADBGfAEAMEZ8AQAwRnwBADBGfAEAMEZ8AQAwRnwBADBGfAEAMEZ8AQAw\nRnwBADBGfAEAMEZ8AQAwRnwBADBGfAEAMEZ8AQAwRnwBADBGfAEAMEZ8AQAwRnwBADBGfAEAMEZ8\nAQAwRnwBADBGfAEAMEZ8AQAwRnwBADBGfAEAMEZ8AQAwRnwBADDWr/h2d3dr4cKF2rNnj06ePKn7\n7rtPoVBIFRUVOn/+fKJnBADAU/oV35/+9KcaO3asJGnbtm0KhUKqq6vTpEmT1NDQkNABAQDwGtf4\nvv322zp+/LhuvfVWSVJLS4uKi4slSUVFRQqHwwkdEAAAr3GN7+bNm1VZWRm73dXVJb/fL0nKyclR\nNBpN3HQAAHiQL96de/fu1Ze+9CVde+21H3m/4zj9+iZZWeny+VI/+XTACBEIZCb1/oca60t+I2GN\nfcWN7/79+9Xa2qr9+/fr1KlT8vv9Sk9PV3d3t9LS0hSJRBQMBl2/SXt756ANDHhRNNqRsH0HApkJ\n3f9QY33Jz6trjPcDRdz4/uhHP4p9/eMf/1if+9zndPjwYTU1NemOO+5Qc3OzCgsLB29SAABGgE/8\nd77l5eXau3evQqGQzp49q9LS0kTMBQCAZ8V959tXeXl57Ova2tqEDAMAwEjAFa4AADBGfAEAMEZ8\nAQAwRnwBADBGfAEAMEZ8AQAwRnwBADBGfAEAMEZ8AQAwRnwBADBGfAEAMEZ8AQAwRnwBADBGfAEA\nMEZ8AQAwRnwBADBGfAEAMEZ8AQAwRnwBADBGfAEAMEZ8AQAwRnwBADBGfAEAMEZ8AQAwRnwBADBG\nfAEAMEZ8AQAwRnwBADBGfAEAMEZ8AQAwRnwBADBGfAEAMOZze0BXV5cqKyt15swZ/fe//9VDDz2k\nKVOmaO3atert7VUgENDWrVvl9/st5gUAIOm5xnffvn2aPn26VqxYoba2Nj344IO65ZZbFAqFVFJS\nopqaGjU0NCgUClnMCwBA0nON7+LFi2Nfnzx5Urm5uWppadFTTz0lSSoqKtKuXbuILzDCPLjp/4Z6\nBGBQ7apcYPa9XON7SVlZmU6dOqXt27frm9/8Zuw0c05OjqLRaMIGBADAa/od31//+tf6xz/+occe\ne0yO48S29/3642RlpcvnSx3YhMAIEAhkJvX+AS+wPE5c43vkyBHl5ORowoQJmjp1qnp7e5WRkaHu\n7m6lpaUpEokoGAzG3Ud7e+egDQx4UTTakbB9BwKZCd0/4BWDfZzEi7nrnxodOnRIu3btkiSdPn1a\nnZ2dKigoUFNTkySpublZhYWFgzQqAADe5/rOt6ysTI8//rhCoZC6u7v15JNPavr06Vq3bp3q6+uV\nl5en0tJSi1kBAPAE1/impaXp2WefvWJ7bW1tQgYCAMDruMIVAADGiC8AAMaILwAAxogvAADGiC8A\nAMaILwAAxogvAADGiC8AAMaILwAAxogvAADGiC8AAMaILwAAxogvAADGiC8AAMaILwAAxogvAADG\niC8AAMaILwAAxogvAADGiC8AAMaILwAAxogvAADGiC8AAMaILwAAxogvAADGiC8AAMaILwAAxogv\nAADGiC8AAMaILwAAxogvAADGiC8AAMZ8/XnQli1b9Je//EUXLlzQd77zHd18881au3atent7FQgE\ntHXrVvn9/kTPCgCAJ7jG98CBAzp27Jjq6+vV3t6uO++8U/n5+QqFQiopKVFNTY0aGhoUCoUs5gUA\nIOm5nnaePXu2nnvuOUnSVVddpa6uLrW0tKi4uFiSVFRUpHA4nNgpAQDwENf4pqamKj09XZLU0NCg\nefPmqaurK3aaOScnR9FoNLFTAgDgIf36zFeS/vjHP6qhoUG7du3SbbfdFtvuOI7rc7Oy0uXzpQ5s\nQmAECAQyk3r/gBdYHif9iu+rr76q7du3a+fOncrMzFR6erq6u7uVlpamSCSiYDAY9/nt7Z2DMizg\nVdFoR8L2HQhkJnT/gFcM9nESL+aup507Ojq0ZcsW/exnP9O4ceMkSQUFBWpqapIkNTc3q7CwcJBG\nBQDA+1zf+b788stqb2/XI488Etu2adMmVVVVqb6+Xnl5eSotLU3okAAAeIlrfO+55x7dc889V2yv\nra1NyEAAAHgdV7gCAMAY8QUAwBjxBQDAGPEFAMAY8QUAwBjxBQDAGPEFAMAY8QUAwBjxBQDAGPEF\nAMAY8QUAwBjxBQDAGPEFAMAY8QUAwBjxBQDAGPEFAMAY8QUAwBjxBQDAGPEFAMAY8QUAwBjxBQDA\nGPEFAMAY8QUAwBjxBQDAGPEFAMAY8QUAwBjxBQDAGPEFAMAY8QUAwBjxBQDAGPEFAMAY8QUAwFi/\n4nv06FEtXLhQv/zlLyVJJ0+e1H333adQKKSKigqdP38+oUMCAOAlrvHt7OzU008/rfz8/Ni2bdu2\nKRQKqa6uTpMmTVJDQ0NChwQAwEtc4+v3+7Vjxw4Fg8HYtpaWFhUXF0uSioqKFA6HEzchAAAe43N9\ngM8nn+/yh3V1dcnv90uScnJyFI1GEzMdAAAe5BpfN47juD4mKytdPl/qp/1WgGcFAplJvX/ACyyP\nkwHFNz09Xd3d3UpLS1MkErnslPRHaW/vHNBwwEgRjXYkbN+BQGZC9w94xWAfJ/FiPqA/NSooKFBT\nU5Mkqbm5WYWFhQObDACAEcj1ne+RI0e0efNmtbW1yefzqampSdXV1aqsrFR9fb3y8vJUWlpqMSsA\nAJ7gGt/p06frxRdfvGJ7bW1tQgYCAMDruMIVAADGiC8AAMaILwAAxogvAADGiC8AAMaILwAAxogv\nAADGiC8AAMaILwAAxogvAADGiC8AAMaILwAAxogvAADGiC8AAMaILwAAxogvAADGiC8AAMaILwAA\nxogvAADGiC8AAMaILwAAxogvAADGiC8AAMaILwAAxogvAADGiC8AAMaILwAAxogvAADGiC8AAMaI\nLwAAxogvAADGiC8AAMZ8A33iD37wA73xxhtKSUnR+vXrNWPGjMGcCwAAzxpQfF9//XX961//Un19\nvd5++22tX79e9fX1gz0bAACeNKDTzuFwWAsXLpQk3XDDDXr//fd17ty5QR0MAACvGlB8T58+rays\nrNjt7OxsRaPRQRsKAAAvG/Bnvn05jhP3/kAgczC+zWVeevaOQd8n4FUcg8DwMqB3vsFgUKdPn47d\nfu+99xQIBAZtKAAAvGxA8Z0zZ46ampokSX//+98VDAY1ZsyYQR0MAACvGtBp51tuuUXTpk1TWVmZ\nUlJStGHDhsGeCwAAz0px3D6wBQAAg4orXAEAYIz4AgBgbFD+1MjLenp6VFlZqRMnTig1NVU//OEP\nde211172mJdfflm7du3SqFGjlJ+fr+9973vas2ePnnvuOU2cOFGSVFBQoO9+97tDsYSPFe8SoX/+\n859VU1Oj1NRUzZs3T6tWrXJ9znAUb94DBw6opqZGo0aN0uc//3k988wzOnjwoCoqKjR58mRJ0o03\n3qgnnnhiqMZ3FW99CxYs0NVXX63U1FRJUnV1tXJzcz3zGkYiEa1Zsyb2uNbWVj366KPq6ekZ9sde\nX0ePHtVDDz2kBx54QPfee+9l93nlOIy3Ri8chwPiIK49e/Y4GzdudBzHcV599VWnoqLisvs7Ozud\noqIip6Ojw7l48aJz1113OceOHXN+85vfOJs2bRqKkfulpaXF+fa3v+04juMcP37cufvuuy+7v6Sk\nxDlx4oTT29vrLF261Dl27Jjrc4Ybt3kXLVrknDx50nEcxykvL3f279/vHDhwwCkvLzefdSDc1ldU\nVOScO3fuEz1nuOnvvD09PU5ZWZlz7ty5YX/s9fWf//zHuffee52qqirnxRdfvOJ+LxyHbmtM9uNw\noDjt7CIcDmvRokWSPvwJ+q9//etl93/2s59VY2OjxowZo5SUFI0bN05nz54dilE/kXiXCG1tbdXY\nsWM1YcIEjRo1SvPnz1c4HE66y4q6zbtnzx5dffXVkj68Slt7e/uQzDlQA3k9vPYaXvLb3/5Wt99+\nuzIyMqxH/FT8fr927NihYDB4xX1eOQ7jrVFK/uNwoIivi9OnTys7O1uSNGrUKKWkpOj8+fOXPebS\n3zj/85//VFtbm2bOnCnpw3+AYvny5br//vv11ltv2Q7uIt4lQqPRaGzNfe9LtsuKus176XV77733\n9Nprr2n+/PmSpOPHj2vlypVaunSpXnvtNduhP4H+vB4bNmzQ0qVLVV1dLcdxPPcaXrJ7927ddddd\nsdvD+djry+fzKS0t7SPv88pxGG+NUvIfhwPFZ7597N69W7t3775s2xtvvHHZbedj/jLrnXfe0Zo1\na/Tss89q9OjRmjlzprKzs3Xrrbfq8OHDWrdunV566aWEzf5pfdy6Bvs5Q+mj5j1z5oxWrlypDRs2\nKCsrS9ddd51Wr16tkpIStba2atmyZWpubpbf7x+CiT+Z/13fww8/rMLCQo0dO1arVq2KXRgn3nOG\nu4+a9/Dhw7r++utj/xNPtmPv00q21/CjeOk47C/i28eSJUu0ZMmSy7ZVVlYqGo1qypQp6unpkeM4\nV/wHcOrUKa1atUpbtmzR1KlTJX14OuiGG26QJM2aNUv//ve/1dvbG/vll6EW7xKh/3tfJBJRMBjU\n6NGjk+qyom6XQT137pxWrFihRx55RHPnzpUk5ebmavHixZKkiRMnavz48YpEIlf8kt1w4La+0tLS\n2Nfz5s3T0aNHk+7SsP2Zd//+/crPz4/dHu7HXn955Th0k+zH4UBx2tnFnDlz9Ic//EGStG/fPn3l\nK1+54jGPP/64Nm7cqGnTpsW27dixQ7/73e8kffibftnZ2cPq4I93idBrrrlG586d07vvvqsLFy5o\n3759mjNnTtJdVtRt3k2bNun+++/XvHnzYtsaGxv1wgsvSPrwtN+ZM2eUm5trO3g/xVtfR0eHli9f\nHvuI5ODBg5o8ebLnXkNJevPNNzVlypTY7eF+7PWXV45DN8l+HA4UV7hy0dvbq6qqKr3zzjvy+/3a\ntGmTJkyYoJ///OeaPXu2xo0bp9LS0st+1f+BBx7QtGnT9Nhjj8lxHF24cGFY/jlAdXW1Dh06FLtE\n6FtvvaXMzEwtWrRIBw8eVHV1tSTptttu0/Llyz/yOX3/pzccfdwa586dq9mzZ2vWrFmxx37ta1/T\nV7/6Va1Zs0YffPCBenp6tHr16thnUMNRvNfwF7/4hfbu3avPfOYz+uIXv6gnnnhCKSkpnnkNL/0i\n5Ne//nXV1tZq/Pjxkj48EzXcj71Ljhw5os2bN6utrU0+n0+5ublasGCBrrnmGs8ch/HW6JXjcCCI\nLwAAxjjtDACAMeILAIAx4gsAgDHiCwCAMeILAIAx4gsAgDHiCwCAMeILAICx/wdygN78VSu3eQAA\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f19299aec88>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "MjRNA5RFeLBf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "54qfuRpbWI8g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 신경망 모형 만들기 "
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "4bgFkqCDWI8h",
        "colab_type": "code",
        "outputId": "916f8b51-fd18-4612-abd5-40abcca160b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#target의 척도를 지정한다. 중요하다.\n",
        "target_cat = pd.api.types.CategoricalDtype(categories=range(2), ordered=False)\n",
        "print(target_cat.categories)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RangeIndex(start=0, stop=2, step=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vcw35D9sWI8m",
        "colab_type": "code",
        "outputId": "8a6b84c5-308c-47e3-fabb-c7479e7fd161",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15339, 1235)\n",
            "(5114, 1235)\n",
            "(15339, 1)\n",
            "(5114, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tU789SzxWI8u",
        "colab_type": "code",
        "outputId": "b7f49282-42f6-4f67-f3f3-7338d0e25cfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "##nb = number\n",
        "nb_tr_examples, nb_inputs = X_train.shape\n",
        "#hidden layer\n",
        "nb_units_hl_1 = 250\n",
        "#output number를 타겟의 행과열의수 1\n",
        "nb_outputs = y_train.shape[1]\n",
        "print(nb_tr_examples, nb_inputs, nb_units_hl_1, nb_outputs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15339 1235 250 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5wnHNsXdWI82",
        "colab_type": "code",
        "outputId": "0ad42406-0f48-458f-d270-292311115565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#필요한 모듈 가져오기\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras import metrics\n",
        "\n",
        "from keras.optimizers import SGD, Adam, RMSprop"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "u9ELqoIXWI83",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 기본 모형 만들기, 히든 노드 1개\n",
        "import numpy\n",
        "seed = 20181121\n",
        "numpy. random.seed(seed)\n",
        "\n",
        "# model parameters를 매개변수로 받아 모형을 동적으로 생성한다. \n",
        "\n",
        "def create_model(optimizer, lr, activation):\n",
        "    \n",
        "    model = Sequential()\n",
        "    hl_1 = Dense(nb_units_hl_1, input_dim = nb_inputs)\n",
        "    model.add(hl_1)\n",
        "    hl_1_act = Activation(activation)\n",
        "    model.add(hl_1_act)\n",
        "    ol = Dense(nb_outputs)\n",
        "    model.add(ol)\n",
        "    ol_act = Activation(activation)\n",
        "    model.add(ol_act)\n",
        "    \n",
        "    if optimizer == 'sgd':\n",
        "        optim = SGD(lr=lr)\n",
        "    if optimizer == 'rmsprop':\n",
        "        optim = RMSprop(lr=lr)\n",
        "    if optimizer == 'adam':\n",
        "        optim = Adam(lr=lr)\n",
        "    \n",
        "    model.compile(optimizer=optim, loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5zB7FL9iWI8_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = KerasClassifier(build_fn=create_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-8RYHxULWI9I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 모형을 컴파일할 때와 컴파일된 모형을 훈력(fit)할 때 전달한 매개변수에\n",
        "# 전달할 값들을 사전으로 만든다.\n",
        "# 전달할 매개변수의 이름과 개수가 다른 경우에는 list of dictionaries를 만든다. \n",
        "\n",
        "#optimizers = ['sgd','adam','rmsprop']\n",
        "\n",
        "#속도개선을 위해 학습률은 0.001로 지정\n",
        "optimizers = ['rmsprop']\n",
        "lr = [0.001]\n",
        "act = ['sigmoid','tanh']\n",
        "\n",
        "epochs = [10, 30]\n",
        "batches = [50, 100]\n",
        "\n",
        "param_grid = dict(optimizer = optimizers, lr=lr, activation=act, epochs=epochs, batch_size=batches)\n",
        "\n",
        "#교차 검증을 위해 k-fold 객체를 생성한다. \n",
        "from sklearn.model_selection import StratifiedKFold \n",
        "kfold = StratifiedKFold(n_splits=5, random_state=20181121)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "trfGfYZzWI9R",
        "colab_type": "code",
        "outputId": "b42571ed-f0fd-4d3c-e499-871106b1bb2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87654
        }
      },
      "cell_type": "code",
      "source": [
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=['accuracy'], refit=\"accuracy\", return_train_score=True, cv=kfold)\n",
        "\n",
        "# KerasClassifier 내에서 target을 one-hot encoding하므로\n",
        "# Keras NN model을 sklearn을 연결할 때 one-hot encoding 하지 않은 target을 사용한다. \n",
        "\n",
        "grid_result = grid.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 2s 185us/step - loss: 9.9490 - acc: 0.0732\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 116us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 117us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 115us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 115us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 117us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 116us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 115us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 120us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 10.6680 - acc: 0.0258\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 115us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 119us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 2s 143us/step - loss: 0.9131 - acc: 0.6912\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 129us/step - loss: 3.1586 - acc: 0.6126\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 129us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 2s 149us/step - loss: 3.7616 - acc: 0.6639\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 129us/step - loss: 5.7776 - acc: 0.3626\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 11.0610 - acc: 0.0117\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 1.5578 - acc: 0.6604\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 0.7674 - acc: 0.7335\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 0.5029 - acc: 0.7625\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 0.4937 - acc: 0.7773\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 0.4624 - acc: 0.7975\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 0.4971 - acc: 0.8014\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 0.4490 - acc: 0.8135\n",
            "Epoch 1/10\n",
            "12272/12272 [==============================] - 2s 145us/step - loss: 11.0030 - acc: 0.0070\n",
            "Epoch 2/10\n",
            "12272/12272 [==============================] - 2s 128us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 3/10\n",
            "12272/12272 [==============================] - 2s 126us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 4/10\n",
            "12272/12272 [==============================] - 2s 124us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 5/10\n",
            "12272/12272 [==============================] - 2s 124us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 6/10\n",
            "12272/12272 [==============================] - 2s 126us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 7/10\n",
            "12272/12272 [==============================] - 1s 119us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 8/10\n",
            "12272/12272 [==============================] - 1s 118us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 9/10\n",
            "12272/12272 [==============================] - 2s 124us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 10/10\n",
            "12272/12272 [==============================] - 1s 121us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 3s 207us/step - loss: 3.4042 - acc: 0.6289\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 180us/step - loss: 5.9306 - acc: 0.5733\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 180us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 185us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 181us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 191us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 3s 212us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 185us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 192us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 188us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 187us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 187us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 185us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 186us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 3s 212us/step - loss: 4.8400 - acc: 0.6564\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 4.8122 - acc: 0.6682\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 4.8246 - acc: 0.6664\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 4.7324 - acc: 0.6632\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 4.6089 - acc: 0.6456\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 179us/step - loss: 4.5309 - acc: 0.6485\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 181us/step - loss: 4.7947 - acc: 0.6896\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 175us/step - loss: 5.6155 - acc: 0.5300\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 163us/step - loss: 4.2919 - acc: 0.6523\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 165us/step - loss: 4.6849 - acc: 0.6329\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 2s 197us/step - loss: 4.9075 - acc: 0.6955\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 173us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 169us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 171us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 171us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 179us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 1/10\n",
            "12272/12272 [==============================] - 3s 222us/step - loss: 4.9220 - acc: 0.6875\n",
            "Epoch 2/10\n",
            "12272/12272 [==============================] - 2s 185us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 3/10\n",
            "12272/12272 [==============================] - 2s 184us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 4/10\n",
            "12272/12272 [==============================] - 2s 184us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 5/10\n",
            "12272/12272 [==============================] - 2s 183us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 6/10\n",
            "12272/12272 [==============================] - 2s 180us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 7/10\n",
            "12272/12272 [==============================] - 2s 184us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 8/10\n",
            "12272/12272 [==============================] - 2s 182us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 9/10\n",
            "12272/12272 [==============================] - 2s 183us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 10/10\n",
            "12272/12272 [==============================] - 2s 179us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 2s 203us/step - loss: 11.0599 - acc: 0.0036\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 154us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 161us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 157us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 158us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 161us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 155us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 152us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 152us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 154us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 2s 197us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 160us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 160us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 161us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 160us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 161us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 161us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 162us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 162us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 161us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 3s 205us/step - loss: 4.9334 - acc: 0.6929\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 160us/step - loss: 4.9078 - acc: 0.6951\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 157us/step - loss: 4.9047 - acc: 0.6957\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 159us/step - loss: 4.9047 - acc: 0.6957\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 155us/step - loss: 4.9047 - acc: 0.6957\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 155us/step - loss: 4.9047 - acc: 0.6957\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 156us/step - loss: 4.9047 - acc: 0.6957\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 152us/step - loss: 4.9047 - acc: 0.6957\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 153us/step - loss: 4.9047 - acc: 0.6957\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 159us/step - loss: 4.9047 - acc: 0.6957\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 3s 208us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 157us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 157us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 160us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 161us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 158us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 160us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 163us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 160us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 157us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 1/10\n",
            "12272/12272 [==============================] - 3s 208us/step - loss: 4.9027 - acc: 0.6943\n",
            "Epoch 2/10\n",
            "12272/12272 [==============================] - 2s 166us/step - loss: 4.9056 - acc: 0.6956\n",
            "Epoch 3/10\n",
            "12272/12272 [==============================] - 2s 169us/step - loss: 4.9056 - acc: 0.6956\n",
            "Epoch 4/10\n",
            "12272/12272 [==============================] - 2s 169us/step - loss: 4.9056 - acc: 0.6956\n",
            "Epoch 5/10\n",
            "12272/12272 [==============================] - 2s 165us/step - loss: 4.9056 - acc: 0.6956\n",
            "Epoch 6/10\n",
            "12272/12272 [==============================] - 2s 167us/step - loss: 4.9056 - acc: 0.6956\n",
            "Epoch 7/10\n",
            "12272/12272 [==============================] - 2s 158us/step - loss: 4.9056 - acc: 0.6956\n",
            "Epoch 8/10\n",
            "12272/12272 [==============================] - 2s 157us/step - loss: 4.9056 - acc: 0.6956\n",
            "Epoch 9/10\n",
            "12272/12272 [==============================] - 2s 157us/step - loss: 4.9056 - acc: 0.6956\n",
            "Epoch 10/10\n",
            "12272/12272 [==============================] - 2s 161us/step - loss: 4.9056 - acc: 0.6956\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 2s 172us/step - loss: 4.4636 - acc: 0.6836\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 131us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 131us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 129us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 130us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 131us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 130us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 129us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 131us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 132us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 133us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 140us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 137us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 133us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 2s 181us/step - loss: 10.8918 - acc: 0.0121\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 133us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 131us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 122us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 11.0886 - acc: 1.6299e-04\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 2s 194us/step - loss: 9.4179 - acc: 0.1150\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 11.0852 - acc: 0.0077\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 10.8795 - acc: 0.0300\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 5.2068 - acc: 0.6519\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 130us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 122us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 131us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 2s 190us/step - loss: 4.4961 - acc: 0.6795\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 9.0542 - acc: 0.1534\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 129us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 131us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 129us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 129us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 130us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 129us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 130us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 1/30\n",
            "12272/12272 [==============================] - 2s 192us/step - loss: 5.2784 - acc: 0.3839\n",
            "Epoch 2/30\n",
            "12272/12272 [==============================] - 2s 125us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 3/30\n",
            "12272/12272 [==============================] - 2s 123us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 4/30\n",
            "12272/12272 [==============================] - 2s 124us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 5/30\n",
            "12272/12272 [==============================] - 2s 128us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 6/30\n",
            "12272/12272 [==============================] - 2s 127us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 7/30\n",
            "12272/12272 [==============================] - 2s 127us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 8/30\n",
            "12272/12272 [==============================] - 2s 131us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 9/30\n",
            "12272/12272 [==============================] - 2s 126us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 10/30\n",
            "12272/12272 [==============================] - 2s 124us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 11/30\n",
            "12272/12272 [==============================] - 2s 126us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 12/30\n",
            "12272/12272 [==============================] - 2s 128us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 13/30\n",
            "12272/12272 [==============================] - 2s 126us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 14/30\n",
            "12272/12272 [==============================] - 1s 121us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 15/30\n",
            "12272/12272 [==============================] - 2s 126us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 16/30\n",
            "12272/12272 [==============================] - 2s 122us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 17/30\n",
            "12272/12272 [==============================] - 2s 125us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 18/30\n",
            "12272/12272 [==============================] - 2s 124us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 19/30\n",
            "12272/12272 [==============================] - 2s 126us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 20/30\n",
            "12272/12272 [==============================] - 2s 125us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 21/30\n",
            "12272/12272 [==============================] - 2s 125us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 22/30\n",
            "12272/12272 [==============================] - 2s 125us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 23/30\n",
            "12272/12272 [==============================] - 2s 125us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 24/30\n",
            "12272/12272 [==============================] - 1s 122us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 25/30\n",
            "12272/12272 [==============================] - 2s 123us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 26/30\n",
            "12272/12272 [==============================] - 2s 125us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 27/30\n",
            "12272/12272 [==============================] - 2s 124us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 28/30\n",
            "12272/12272 [==============================] - 2s 126us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 29/30\n",
            "12272/12272 [==============================] - 2s 126us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 30/30\n",
            "12272/12272 [==============================] - 2s 124us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 3s 254us/step - loss: 4.9027 - acc: 0.6934\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 187us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 187us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 181us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 181us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 185us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 186us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 180us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 191us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 197us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 197us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 200us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 190us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 181us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 3s 260us/step - loss: 4.8435 - acc: 0.6801\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 185us/step - loss: 4.9049 - acc: 0.6954\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 4.9055 - acc: 0.6952\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 185us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 185us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 187us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 192us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 192us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 187us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 188us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 186us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 185us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 180us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 186us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 185us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 185us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 187us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 181us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 3s 264us/step - loss: 5.0163 - acc: 0.5636\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 4.7512 - acc: 0.6599\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 4.7878 - acc: 0.6845\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 4.7971 - acc: 0.6252\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 187us/step - loss: 4.9104 - acc: 0.6556\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 191us/step - loss: 4.8985 - acc: 0.6572\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 185us/step - loss: 4.8882 - acc: 0.6739\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 187us/step - loss: 4.8636 - acc: 0.6852\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 185us/step - loss: 4.8834 - acc: 0.6937\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 4.8796 - acc: 0.6935\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 4.8271 - acc: 0.6874\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 179us/step - loss: 4.8523 - acc: 0.6926\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 4.8002 - acc: 0.6911\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 4.7103 - acc: 0.6797\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 179us/step - loss: 4.6622 - acc: 0.6568\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 4.6622 - acc: 0.6611\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 4.6373 - acc: 0.6673\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 177us/step - loss: 4.9085 - acc: 0.6951\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 177us/step - loss: 4.9085 - acc: 0.6951\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 4.9085 - acc: 0.6951\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 4.9085 - acc: 0.6951\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 187us/step - loss: 4.9085 - acc: 0.6951\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 185us/step - loss: 4.9085 - acc: 0.6951\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 189us/step - loss: 4.9085 - acc: 0.6951\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 186us/step - loss: 4.9085 - acc: 0.6951\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 4.9085 - acc: 0.6951\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 187us/step - loss: 4.9085 - acc: 0.6951\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 186us/step - loss: 4.9085 - acc: 0.6951\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 186us/step - loss: 4.9085 - acc: 0.6951\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 4.9085 - acc: 0.6951\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 3s 272us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 188us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 188us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 190us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 185us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 186us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 186us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 187us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 188us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 186us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 188us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 187us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 186us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 188us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 185us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 187us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 181us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 186us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 192us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 189us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 188us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 186us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 192us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 192us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 1/30\n",
            "12272/12272 [==============================] - 3s 275us/step - loss: 4.9012 - acc: 0.6937\n",
            "Epoch 2/30\n",
            "12272/12272 [==============================] - 2s 185us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 3/30\n",
            "12272/12272 [==============================] - 2s 186us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 4/30\n",
            "12272/12272 [==============================] - 2s 187us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 5/30\n",
            "12272/12272 [==============================] - 2s 190us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 6/30\n",
            "12272/12272 [==============================] - 2s 189us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 7/30\n",
            "12272/12272 [==============================] - 2s 189us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 8/30\n",
            "12272/12272 [==============================] - 2s 191us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 9/30\n",
            "12272/12272 [==============================] - 2s 187us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 10/30\n",
            "12272/12272 [==============================] - 2s 187us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 11/30\n",
            "12272/12272 [==============================] - 2s 188us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 12/30\n",
            "12272/12272 [==============================] - 2s 188us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 13/30\n",
            "12272/12272 [==============================] - 2s 187us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 14/30\n",
            "12272/12272 [==============================] - 2s 188us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 15/30\n",
            "12272/12272 [==============================] - 2s 188us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 16/30\n",
            "12272/12272 [==============================] - 2s 188us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 17/30\n",
            "12272/12272 [==============================] - 2s 187us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 18/30\n",
            "12272/12272 [==============================] - 2s 187us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 19/30\n",
            "12272/12272 [==============================] - 2s 185us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 20/30\n",
            "12272/12272 [==============================] - 2s 192us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 21/30\n",
            "12272/12272 [==============================] - 2s 187us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 22/30\n",
            "12272/12272 [==============================] - 2s 183us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 23/30\n",
            "12272/12272 [==============================] - 2s 187us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 24/30\n",
            "12272/12272 [==============================] - 2s 189us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 25/30\n",
            "12272/12272 [==============================] - 2s 183us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 26/30\n",
            "12272/12272 [==============================] - 2s 182us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 27/30\n",
            "12272/12272 [==============================] - 2s 180us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 28/30\n",
            "12272/12272 [==============================] - 2s 184us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 29/30\n",
            "12272/12272 [==============================] - 2s 184us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 30/30\n",
            "12272/12272 [==============================] - 2s 184us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 3s 250us/step - loss: 4.7715 - acc: 0.6626\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 162us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 167us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 177us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 174us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 176us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 175us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 168us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 163us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 166us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 163us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 165us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 162us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 161us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 160us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 163us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 161us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 163us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 162us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 166us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 169us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 170us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 160us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 164us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 162us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 162us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 163us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 164us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 162us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 162us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 3s 253us/step - loss: 4.7859 - acc: 0.6206\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 168us/step - loss: 4.1625 - acc: 0.6299\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 163us/step - loss: 3.8689 - acc: 0.6492\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 167us/step - loss: 3.3406 - acc: 0.6236\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 167us/step - loss: 3.0715 - acc: 0.6663\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 165us/step - loss: 2.7114 - acc: 0.6708\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 170us/step - loss: 2.6375 - acc: 0.6816\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 164us/step - loss: 2.5004 - acc: 0.6722\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 166us/step - loss: 2.4435 - acc: 0.6737\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 165us/step - loss: 2.4166 - acc: 0.6848\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 166us/step - loss: 2.4332 - acc: 0.6778\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 169us/step - loss: 2.2925 - acc: 0.6829\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 169us/step - loss: 2.7234 - acc: 0.6434\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 168us/step - loss: 2.3947 - acc: 0.6769\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 166us/step - loss: 2.2685 - acc: 0.6878\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 169us/step - loss: 2.2283 - acc: 0.6787\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 167us/step - loss: 2.2954 - acc: 0.6831\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 167us/step - loss: 2.2537 - acc: 0.6890\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 167us/step - loss: 2.4138 - acc: 0.6752\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 167us/step - loss: 2.5424 - acc: 0.6551\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 165us/step - loss: 2.3810 - acc: 0.6823\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 169us/step - loss: 2.2386 - acc: 0.6846\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 167us/step - loss: 2.1914 - acc: 0.6880\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 165us/step - loss: 2.1723 - acc: 0.6867\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 166us/step - loss: 2.1617 - acc: 0.6875\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 168us/step - loss: 2.1613 - acc: 0.6853\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 169us/step - loss: 2.1852 - acc: 0.6796\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 168us/step - loss: 2.2054 - acc: 0.6820\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 171us/step - loss: 2.1725 - acc: 0.6852\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 167us/step - loss: 2.1443 - acc: 0.6879\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 3s 258us/step - loss: 5.2200 - acc: 0.6581\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 168us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 164us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 166us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 166us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 166us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 166us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 169us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 164us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 164us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 163us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 163us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 166us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 165us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 161us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 165us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 167us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 167us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 169us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 163us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 164us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 163us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 164us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 164us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 173us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 165us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 169us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 162us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 168us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 167us/step - loss: 4.9060 - acc: 0.6955\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 3s 264us/step - loss: 4.9090 - acc: 0.6909\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 168us/step - loss: 4.7794 - acc: 0.6723\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 168us/step - loss: 4.1942 - acc: 0.6686\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 167us/step - loss: 3.6027 - acc: 0.6411\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 166us/step - loss: 3.1133 - acc: 0.6656\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 168us/step - loss: 2.8976 - acc: 0.6626\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 165us/step - loss: 2.6343 - acc: 0.6767\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 162us/step - loss: 2.5866 - acc: 0.6543\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 164us/step - loss: 2.6650 - acc: 0.6678\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 163us/step - loss: 2.4039 - acc: 0.6823\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 164us/step - loss: 2.4321 - acc: 0.6841\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 165us/step - loss: 2.4314 - acc: 0.6710\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 168us/step - loss: 2.4116 - acc: 0.6828\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 165us/step - loss: 2.4669 - acc: 0.6714\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 166us/step - loss: 2.3020 - acc: 0.6761\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 171us/step - loss: 2.3920 - acc: 0.6776\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 168us/step - loss: 2.2799 - acc: 0.6776\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 166us/step - loss: 2.3468 - acc: 0.6841\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 166us/step - loss: 2.2889 - acc: 0.6843\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 168us/step - loss: 2.2780 - acc: 0.6832\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 165us/step - loss: 2.4019 - acc: 0.6685\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 168us/step - loss: 2.3360 - acc: 0.6778\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 169us/step - loss: 2.2727 - acc: 0.6802\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 167us/step - loss: 2.3067 - acc: 0.6822\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 169us/step - loss: 2.2235 - acc: 0.6902\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 166us/step - loss: 2.1557 - acc: 0.6864\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 165us/step - loss: 2.2231 - acc: 0.6849\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 169us/step - loss: 2.2356 - acc: 0.6828\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 166us/step - loss: 2.2421 - acc: 0.6839\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 169us/step - loss: 2.1620 - acc: 0.6883\n",
            "Epoch 1/30\n",
            "12272/12272 [==============================] - 3s 264us/step - loss: 4.8928 - acc: 0.6948\n",
            "Epoch 2/30\n",
            "12272/12272 [==============================] - 2s 167us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 3/30\n",
            "12272/12272 [==============================] - 2s 165us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 4/30\n",
            "12272/12272 [==============================] - 2s 168us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 5/30\n",
            "12272/12272 [==============================] - 2s 171us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 6/30\n",
            "12272/12272 [==============================] - 2s 171us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 7/30\n",
            "12272/12272 [==============================] - 2s 175us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 8/30\n",
            "12272/12272 [==============================] - 2s 173us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 9/30\n",
            "12272/12272 [==============================] - 2s 170us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 10/30\n",
            "12272/12272 [==============================] - 2s 171us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 11/30\n",
            "12272/12272 [==============================] - 2s 171us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 12/30\n",
            "12272/12272 [==============================] - 2s 173us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 13/30\n",
            "12272/12272 [==============================] - 2s 173us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 14/30\n",
            "12272/12272 [==============================] - 2s 169us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 15/30\n",
            "12272/12272 [==============================] - 2s 170us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 16/30\n",
            "12272/12272 [==============================] - 2s 171us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 17/30\n",
            "12272/12272 [==============================] - 2s 169us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 18/30\n",
            "12272/12272 [==============================] - 2s 170us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 19/30\n",
            "12272/12272 [==============================] - 2s 166us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 20/30\n",
            "12272/12272 [==============================] - 2s 170us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 21/30\n",
            "12272/12272 [==============================] - 2s 170us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 22/30\n",
            "12272/12272 [==============================] - 2s 170us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 23/30\n",
            "12272/12272 [==============================] - 2s 172us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 24/30\n",
            "12272/12272 [==============================] - 2s 167us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 25/30\n",
            "12272/12272 [==============================] - 2s 168us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 26/30\n",
            "12272/12272 [==============================] - 2s 166us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 27/30\n",
            "12272/12272 [==============================] - 2s 166us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 28/30\n",
            "12272/12272 [==============================] - 2s 167us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 29/30\n",
            "12272/12272 [==============================] - 2s 169us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 30/30\n",
            "12272/12272 [==============================] - 2s 174us/step - loss: 4.9069 - acc: 0.6956\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 2s 197us/step - loss: 2.1009 - acc: 0.6550\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 99us/step - loss: 5.1117 - acc: 0.4085\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 7.7590 - acc: 0.2472\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 98us/step - loss: 2.4138 - acc: 0.5917\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 10.7460 - acc: 0.0372\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 6.5568 - acc: 0.5198\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 92us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 91us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 92us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 90us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 2s 190us/step - loss: 6.9990 - acc: 0.3658\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 92us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 91us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 92us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 91us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 92us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 2s 199us/step - loss: 1.2987 - acc: 0.6315\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 91us/step - loss: 3.0032 - acc: 0.6938\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 92us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 92us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 90us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 92us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 2s 196us/step - loss: 2.2201 - acc: 0.5876\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 91us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 90us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 90us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 92us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 92us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 91us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 91us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 1/10\n",
            "12272/12272 [==============================] - 2s 199us/step - loss: 4.8292 - acc: 0.5947\n",
            "Epoch 2/10\n",
            "12272/12272 [==============================] - 1s 95us/step - loss: 2.8554 - acc: 0.6273\n",
            "Epoch 3/10\n",
            "12272/12272 [==============================] - 1s 95us/step - loss: 7.9719 - acc: 0.2598\n",
            "Epoch 4/10\n",
            "12272/12272 [==============================] - 1s 92us/step - loss: 11.0843 - acc: 0.0073\n",
            "Epoch 5/10\n",
            "12272/12272 [==============================] - 1s 95us/step - loss: 11.0843 - acc: 0.0075\n",
            "Epoch 6/10\n",
            "12272/12272 [==============================] - 1s 94us/step - loss: 11.0843 - acc: 0.0081\n",
            "Epoch 7/10\n",
            "12272/12272 [==============================] - 1s 93us/step - loss: 11.0843 - acc: 0.0085\n",
            "Epoch 8/10\n",
            "12272/12272 [==============================] - 1s 94us/step - loss: 11.0842 - acc: 0.0090\n",
            "Epoch 9/10\n",
            "12272/12272 [==============================] - 1s 92us/step - loss: 11.0842 - acc: 0.0094\n",
            "Epoch 10/10\n",
            "12272/12272 [==============================] - 1s 93us/step - loss: 11.0842 - acc: 0.0095\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 3s 235us/step - loss: 4.9197 - acc: 0.6930\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 119us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 119us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 118us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 118us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 118us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 120us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 118us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 118us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 117us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 3s 233us/step - loss: 4.0531 - acc: 0.6462\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 118us/step - loss: 4.5158 - acc: 0.6887\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 118us/step - loss: 4.8079 - acc: 0.6370\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 118us/step - loss: 4.6995 - acc: 0.6694\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 119us/step - loss: 4.6671 - acc: 0.5758\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 118us/step - loss: 4.6548 - acc: 0.6255\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 119us/step - loss: 4.8393 - acc: 0.6743\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 4.6771 - acc: 0.6121\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 119us/step - loss: 4.5956 - acc: 0.6167\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 120us/step - loss: 4.6741 - acc: 0.6520\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 3s 240us/step - loss: 4.8904 - acc: 0.6944\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 120us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 118us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 118us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 120us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 119us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 120us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 3s 247us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 120us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 1/10\n",
            "12272/12272 [==============================] - 3s 254us/step - loss: 4.7676 - acc: 0.6658\n",
            "Epoch 2/10\n",
            "12272/12272 [==============================] - 2s 125us/step - loss: 4.8262 - acc: 0.6312\n",
            "Epoch 3/10\n",
            "12272/12272 [==============================] - 2s 123us/step - loss: 4.7566 - acc: 0.6282\n",
            "Epoch 4/10\n",
            "12272/12272 [==============================] - 1s 121us/step - loss: 4.4527 - acc: 0.6771\n",
            "Epoch 5/10\n",
            "12272/12272 [==============================] - 1s 117us/step - loss: 4.1902 - acc: 0.6455\n",
            "Epoch 6/10\n",
            "12272/12272 [==============================] - 1s 119us/step - loss: 4.4975 - acc: 0.6296\n",
            "Epoch 7/10\n",
            "12272/12272 [==============================] - 1s 117us/step - loss: 4.1883 - acc: 0.6472\n",
            "Epoch 8/10\n",
            "12272/12272 [==============================] - 1s 122us/step - loss: 4.2105 - acc: 0.5981\n",
            "Epoch 9/10\n",
            "12272/12272 [==============================] - 1s 121us/step - loss: 4.3565 - acc: 0.5924\n",
            "Epoch 10/10\n",
            "12272/12272 [==============================] - 1s 119us/step - loss: 6.3690 - acc: 0.4018\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 3s 239us/step - loss: 4.5315 - acc: 0.6612\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 108us/step - loss: 3.7323 - acc: 0.6646\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 3.9776 - acc: 0.6157\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 107us/step - loss: 3.2564 - acc: 0.6566\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 110us/step - loss: 3.6008 - acc: 0.5971\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 107us/step - loss: 3.2927 - acc: 0.6739\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 106us/step - loss: 2.6946 - acc: 0.6823\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 108us/step - loss: 3.7950 - acc: 0.5795\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 107us/step - loss: 2.8318 - acc: 0.6552\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 2.5591 - acc: 0.6914\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 3s 242us/step - loss: 4.9264 - acc: 0.6920\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 106us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 110us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 108us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 110us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 106us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 110us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 109us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 108us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 3s 248us/step - loss: 10.9193 - acc: 0.0171\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 113us/step - loss: 11.0886 - acc: 2.4448e-04\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 11.0886 - acc: 2.4448e-04\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 11.0886 - acc: 2.4448e-04\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 11.0886 - acc: 2.4448e-04\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 11.0886 - acc: 2.4448e-04\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 11.0886 - acc: 2.4448e-04\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 11.0886 - acc: 2.4448e-04\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 110us/step - loss: 11.0886 - acc: 2.4448e-04\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 11.0886 - acc: 2.4448e-04\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 3s 250us/step - loss: 4.8949 - acc: 0.6923\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 110us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 113us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 110us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 1/10\n",
            "12272/12272 [==============================] - 3s 251us/step - loss: 8.1525 - acc: 0.2877\n",
            "Epoch 2/10\n",
            "12272/12272 [==============================] - 1s 105us/step - loss: 4.5911 - acc: 0.6662\n",
            "Epoch 3/10\n",
            "12272/12272 [==============================] - 1s 109us/step - loss: 3.8214 - acc: 0.6021\n",
            "Epoch 4/10\n",
            "12272/12272 [==============================] - 1s 109us/step - loss: 3.7082 - acc: 0.6518\n",
            "Epoch 5/10\n",
            "12272/12272 [==============================] - 1s 110us/step - loss: 3.5188 - acc: 0.6261\n",
            "Epoch 6/10\n",
            "12272/12272 [==============================] - 1s 107us/step - loss: 3.2663 - acc: 0.6367\n",
            "Epoch 7/10\n",
            "12272/12272 [==============================] - 1s 107us/step - loss: 3.2501 - acc: 0.6279\n",
            "Epoch 8/10\n",
            "12272/12272 [==============================] - 1s 104us/step - loss: 2.5954 - acc: 0.6729\n",
            "Epoch 9/10\n",
            "12272/12272 [==============================] - 1s 109us/step - loss: 2.7901 - acc: 0.6613\n",
            "Epoch 10/10\n",
            "12272/12272 [==============================] - 1s 108us/step - loss: 2.7401 - acc: 0.6555\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 3s 241us/step - loss: 2.4144 - acc: 0.5828\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 0.6846 - acc: 0.7200\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 0.5907 - acc: 0.7377\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 0.5166 - acc: 0.7593\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 1s 91us/step - loss: 0.5015 - acc: 0.7699\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 1.7781 - acc: 0.7195\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 1s 91us/step - loss: 0.5861 - acc: 0.7668\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 1s 92us/step - loss: 0.4867 - acc: 0.7825\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 0.4709 - acc: 0.7942\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 0.4675 - acc: 0.7942\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 0.4591 - acc: 0.8017\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 0.4547 - acc: 0.8074\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 1s 92us/step - loss: 0.4451 - acc: 0.8144\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 1s 92us/step - loss: 0.4418 - acc: 0.8144\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 1s 92us/step - loss: 0.4538 - acc: 0.8069\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 0.4302 - acc: 0.8218\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 0.4272 - acc: 0.8219\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 0.4288 - acc: 0.8236\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 0.4165 - acc: 0.8241\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 0.4140 - acc: 0.8289\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 0.4129 - acc: 0.8283\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 0.4238 - acc: 0.8263\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 0.4063 - acc: 0.8326\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 1.9736 - acc: 0.7105\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 1s 91us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 1s 91us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 3s 242us/step - loss: 2.4576 - acc: 0.5687\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 2.2998 - acc: 0.6986\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 1s 98us/step - loss: 0.7723 - acc: 0.7162\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 0.5789 - acc: 0.7370\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 0.5162 - acc: 0.7512\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 0.4943 - acc: 0.7686\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 2.3819 - acc: 0.6435\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 1s 92us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 1s 91us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 1s 91us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 1s 91us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 1s 90us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 1s 99us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 1s 99us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 1s 98us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 1s 101us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 1s 98us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 1s 98us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 1s 101us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 3s 245us/step - loss: 4.0926 - acc: 0.4728\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 1s 91us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 1s 91us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 1s 91us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 1s 92us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 1s 91us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 1s 98us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 1s 99us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 1s 91us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 3s 246us/step - loss: 2.0834 - acc: 0.6321\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 3.6305 - acc: 0.6801\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 10.2328 - acc: 0.0667\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 11.0886 - acc: 0.0000e+00\n",
            "Epoch 1/30\n",
            "12272/12272 [==============================] - 3s 251us/step - loss: 2.7785 - acc: 0.6702\n",
            "Epoch 2/30\n",
            "12272/12272 [==============================] - 1s 95us/step - loss: 0.7074 - acc: 0.7137\n",
            "Epoch 3/30\n",
            "12272/12272 [==============================] - 1s 96us/step - loss: 0.5708 - acc: 0.7436\n",
            "Epoch 4/30\n",
            "12272/12272 [==============================] - 1s 94us/step - loss: 0.5335 - acc: 0.7680\n",
            "Epoch 5/30\n",
            "12272/12272 [==============================] - 1s 94us/step - loss: 0.5119 - acc: 0.7776\n",
            "Epoch 6/30\n",
            "12272/12272 [==============================] - 1s 101us/step - loss: 0.4992 - acc: 0.7823\n",
            "Epoch 7/30\n",
            "12272/12272 [==============================] - 1s 96us/step - loss: 1.0233 - acc: 0.7502\n",
            "Epoch 8/30\n",
            "12272/12272 [==============================] - 1s 96us/step - loss: 0.4802 - acc: 0.8017\n",
            "Epoch 9/30\n",
            "12272/12272 [==============================] - 1s 94us/step - loss: 0.4907 - acc: 0.7994\n",
            "Epoch 10/30\n",
            "12272/12272 [==============================] - 1s 95us/step - loss: 0.4672 - acc: 0.8092\n",
            "Epoch 11/30\n",
            "12272/12272 [==============================] - 1s 96us/step - loss: 6.6763 - acc: 0.3378\n",
            "Epoch 12/30\n",
            "12272/12272 [==============================] - 1s 95us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 13/30\n",
            "12272/12272 [==============================] - 1s 96us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 14/30\n",
            "12272/12272 [==============================] - 1s 95us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 15/30\n",
            "12272/12272 [==============================] - 1s 98us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 16/30\n",
            "12272/12272 [==============================] - 1s 97us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 17/30\n",
            "12272/12272 [==============================] - 1s 95us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 18/30\n",
            "12272/12272 [==============================] - 1s 97us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 19/30\n",
            "12272/12272 [==============================] - 1s 95us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 20/30\n",
            "12272/12272 [==============================] - 1s 95us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 21/30\n",
            "12272/12272 [==============================] - 1s 96us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 22/30\n",
            "12272/12272 [==============================] - 1s 95us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 23/30\n",
            "12272/12272 [==============================] - 1s 96us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 24/30\n",
            "12272/12272 [==============================] - 1s 95us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 25/30\n",
            "12272/12272 [==============================] - 1s 96us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 26/30\n",
            "12272/12272 [==============================] - 1s 95us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 27/30\n",
            "12272/12272 [==============================] - 1s 96us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 28/30\n",
            "12272/12272 [==============================] - 1s 99us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 29/30\n",
            "12272/12272 [==============================] - 1s 95us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 30/30\n",
            "12272/12272 [==============================] - 1s 97us/step - loss: 11.0890 - acc: 0.0000e+00\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 4s 291us/step - loss: 4.9623 - acc: 0.6852\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 122us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 122us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 1s 120us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 122us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 4s 290us/step - loss: 11.0297 - acc: 0.0063\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 122us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 1s 120us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 1s 119us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 11.0873 - acc: 8.1493e-05\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 4s 293us/step - loss: 4.7061 - acc: 0.6836\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 4.5276 - acc: 0.6750\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 4.8741 - acc: 0.6959\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 4.7980 - acc: 0.6620\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 122us/step - loss: 4.5584 - acc: 0.6255\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 4.7582 - acc: 0.5650\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 4.4655 - acc: 0.6506\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 4.2046 - acc: 0.6561\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 10.6825 - acc: 0.0421\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 10.6854 - acc: 0.0473\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 10.6272 - acc: 0.0562\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 10.5938 - acc: 0.0658\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 8.1010 - acc: 0.3490\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 4s 301us/step - loss: 4.9046 - acc: 0.6930\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.9294 - acc: 0.6924\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 4.6720 - acc: 0.6570\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 7.3032 - acc: 0.3987\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.8988 - acc: 0.6905\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 4.9002 - acc: 0.6951\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 130us/step - loss: 4.8942 - acc: 0.6957\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.8876 - acc: 0.6911\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.9029 - acc: 0.6754\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 4.8619 - acc: 0.6708\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.8413 - acc: 0.6702\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 5.3588 - acc: 0.5418\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 4.6788 - acc: 0.6565\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 5.1714 - acc: 0.5964\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 10.7384 - acc: 0.0376\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.8691 - acc: 0.5599\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 4.4968 - acc: 0.5775\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 4.2279 - acc: 0.6227\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 4.4487 - acc: 0.6542\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 6.5135 - acc: 0.4141\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 4.0952 - acc: 0.6030\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.1761 - acc: 0.5974\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 4.4279 - acc: 0.6416\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 131us/step - loss: 5.7926 - acc: 0.4458\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 130us/step - loss: 8.5077 - acc: 0.2131\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 131us/step - loss: 5.2362 - acc: 0.5275\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 131us/step - loss: 10.6850 - acc: 0.0392\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 129us/step - loss: 10.6238 - acc: 0.0449\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 132us/step - loss: 10.1602 - acc: 0.0890\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 4.9389 - acc: 0.5712\n",
            "Epoch 1/30\n",
            "12272/12272 [==============================] - 4s 296us/step - loss: 4.2323 - acc: 0.6654\n",
            "Epoch 2/30\n",
            "12272/12272 [==============================] - 2s 127us/step - loss: 4.2553 - acc: 0.6410\n",
            "Epoch 3/30\n",
            "12272/12272 [==============================] - 2s 124us/step - loss: 4.3949 - acc: 0.6660\n",
            "Epoch 4/30\n",
            "12272/12272 [==============================] - 2s 130us/step - loss: 4.1334 - acc: 0.6541\n",
            "Epoch 5/30\n",
            "12272/12272 [==============================] - 2s 125us/step - loss: 4.8853 - acc: 0.6895\n",
            "Epoch 6/30\n",
            "12272/12272 [==============================] - 2s 127us/step - loss: 4.8883 - acc: 0.6754\n",
            "Epoch 7/30\n",
            "12272/12272 [==============================] - 2s 124us/step - loss: 4.8702 - acc: 0.6764\n",
            "Epoch 8/30\n",
            "12272/12272 [==============================] - 2s 127us/step - loss: 4.8259 - acc: 0.6283\n",
            "Epoch 9/30\n",
            "12272/12272 [==============================] - 2s 126us/step - loss: 4.6647 - acc: 0.5858\n",
            "Epoch 10/30\n",
            "12272/12272 [==============================] - 2s 125us/step - loss: 4.5607 - acc: 0.6116\n",
            "Epoch 11/30\n",
            "12272/12272 [==============================] - 2s 124us/step - loss: 4.5214 - acc: 0.5904\n",
            "Epoch 12/30\n",
            "12272/12272 [==============================] - 2s 123us/step - loss: 4.4747 - acc: 0.6605\n",
            "Epoch 13/30\n",
            "12272/12272 [==============================] - 2s 125us/step - loss: 4.4509 - acc: 0.6593\n",
            "Epoch 14/30\n",
            "12272/12272 [==============================] - 2s 127us/step - loss: 3.7464 - acc: 0.6100\n",
            "Epoch 15/30\n",
            "12272/12272 [==============================] - 2s 123us/step - loss: 4.6446 - acc: 0.6684\n",
            "Epoch 16/30\n",
            "12272/12272 [==============================] - 2s 124us/step - loss: 4.7501 - acc: 0.6755\n",
            "Epoch 17/30\n",
            "12272/12272 [==============================] - 2s 125us/step - loss: 4.8395 - acc: 0.6692\n",
            "Epoch 18/30\n",
            "12272/12272 [==============================] - 2s 124us/step - loss: 4.8164 - acc: 0.6659\n",
            "Epoch 19/30\n",
            "12272/12272 [==============================] - 2s 127us/step - loss: 4.7879 - acc: 0.6712\n",
            "Epoch 20/30\n",
            "12272/12272 [==============================] - 2s 125us/step - loss: 4.7642 - acc: 0.6669\n",
            "Epoch 21/30\n",
            "12272/12272 [==============================] - 2s 126us/step - loss: 4.7630 - acc: 0.6799\n",
            "Epoch 22/30\n",
            "12272/12272 [==============================] - 1s 122us/step - loss: 4.8427 - acc: 0.6925\n",
            "Epoch 23/30\n",
            "12272/12272 [==============================] - 2s 124us/step - loss: 4.8295 - acc: 0.6923\n",
            "Epoch 24/30\n",
            "12272/12272 [==============================] - 2s 126us/step - loss: 4.8913 - acc: 0.6956\n",
            "Epoch 25/30\n",
            "12272/12272 [==============================] - 2s 124us/step - loss: 4.8887 - acc: 0.6953\n",
            "Epoch 26/30\n",
            "12272/12272 [==============================] - 2s 126us/step - loss: 4.8874 - acc: 0.6952\n",
            "Epoch 27/30\n",
            "12272/12272 [==============================] - 2s 127us/step - loss: 4.7579 - acc: 0.6930\n",
            "Epoch 28/30\n",
            "12272/12272 [==============================] - 2s 126us/step - loss: 4.6701 - acc: 0.6849\n",
            "Epoch 29/30\n",
            "12272/12272 [==============================] - 2s 124us/step - loss: 4.6907 - acc: 0.6852\n",
            "Epoch 30/30\n",
            "12272/12272 [==============================] - 2s 127us/step - loss: 4.8219 - acc: 0.6950\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 4s 291us/step - loss: 4.9073 - acc: 0.6359\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 4.2878 - acc: 0.6227\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 3.5062 - acc: 0.6715\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 3.0122 - acc: 0.6594\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 3.4322 - acc: 0.5987\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 1s 113us/step - loss: 2.8849 - acc: 0.6604\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 1s 114us/step - loss: 2.5272 - acc: 0.6805\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 2.8148 - acc: 0.6540\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 1s 114us/step - loss: 2.7097 - acc: 0.6621\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 1s 116us/step - loss: 2.5090 - acc: 0.6694\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 1s 113us/step - loss: 2.3900 - acc: 0.6733\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 1s 114us/step - loss: 2.6653 - acc: 0.6371\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 1s 113us/step - loss: 2.5154 - acc: 0.6545\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 1s 114us/step - loss: 2.3499 - acc: 0.6833\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 1s 113us/step - loss: 2.8148 - acc: 0.6414\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 2.4358 - acc: 0.6672\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 1s 114us/step - loss: 2.4681 - acc: 0.6644\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 1s 114us/step - loss: 2.3593 - acc: 0.6757\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 1s 113us/step - loss: 2.2724 - acc: 0.6883\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 1s 114us/step - loss: 2.4531 - acc: 0.6441\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 2.3654 - acc: 0.6625\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 1s 113us/step - loss: 3.1439 - acc: 0.6006\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 2.5593 - acc: 0.6560\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 2.1935 - acc: 0.6841\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 2.2584 - acc: 0.6683\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 2.2464 - acc: 0.6805\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 1s 115us/step - loss: 2.2201 - acc: 0.6752\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 2.3608 - acc: 0.6642\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 1s 113us/step - loss: 2.1332 - acc: 0.6815\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 1s 113us/step - loss: 2.1972 - acc: 0.6752\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 4s 291us/step - loss: 4.9809 - acc: 0.6842\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 1s 115us/step - loss: 4.8876 - acc: 0.6955\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 1s 113us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 1s 114us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 1s 113us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 1s 114us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 1s 116us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 1s 110us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 1s 116us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 1s 110us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 1s 110us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 1s 109us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 1s 108us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 1s 115us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 1s 110us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 1s 116us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 1s 106us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 1s 113us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 1s 109us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 1s 113us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 4s 295us/step - loss: 4.4392 - acc: 0.6180\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 1s 113us/step - loss: 3.5782 - acc: 0.6106\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 1s 113us/step - loss: 3.0695 - acc: 0.6494\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 1s 109us/step - loss: 2.8167 - acc: 0.6782\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 3.1983 - acc: 0.6159\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 1s 110us/step - loss: 3.3137 - acc: 0.6222\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 2.7688 - acc: 0.6453\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 1s 110us/step - loss: 2.7525 - acc: 0.6336\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 1s 109us/step - loss: 2.6490 - acc: 0.6587\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 1s 110us/step - loss: 2.4687 - acc: 0.6866\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 1s 109us/step - loss: 2.2919 - acc: 0.6779\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 2.3707 - acc: 0.6743\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 2.2621 - acc: 0.6810\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 2.3361 - acc: 0.6717\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 2.3482 - acc: 0.6678\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 1s 108us/step - loss: 2.2177 - acc: 0.6882\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 2.3975 - acc: 0.6687\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 2.3222 - acc: 0.6887\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 1s 110us/step - loss: 2.4223 - acc: 0.6743\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 1s 115us/step - loss: 2.2364 - acc: 0.6803\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 1s 113us/step - loss: 2.4319 - acc: 0.6593\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 1s 116us/step - loss: 2.2475 - acc: 0.6805\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 1s 106us/step - loss: 2.3848 - acc: 0.6701\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 1s 109us/step - loss: 2.1610 - acc: 0.6749\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 1s 107us/step - loss: 2.2507 - acc: 0.6731\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 1s 106us/step - loss: 2.1986 - acc: 0.6873\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 2.1404 - acc: 0.6921\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 1s 108us/step - loss: 2.1936 - acc: 0.6774\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 1s 109us/step - loss: 2.0982 - acc: 0.6918\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 1s 108us/step - loss: 2.1017 - acc: 0.6866\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 4s 298us/step - loss: 4.9002 - acc: 0.6929\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 1s 110us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 1s 110us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 1s 106us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 1s 110us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 1s 110us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 1s 112us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 1s 110us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 1s 107us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 1s 107us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 1s 109us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 1s 107us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 1s 108us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 1s 114us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 1s 109us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 1s 111us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 1s 110us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 1s 107us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 1s 108us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 1s 110us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 1s 110us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 1s 109us/step - loss: 4.9073 - acc: 0.6955\n",
            "Epoch 1/30\n",
            "12272/12272 [==============================] - 4s 298us/step - loss: 4.6400 - acc: 0.6613\n",
            "Epoch 2/30\n",
            "12272/12272 [==============================] - 1s 111us/step - loss: 4.4340 - acc: 0.6024\n",
            "Epoch 3/30\n",
            "12272/12272 [==============================] - 1s 114us/step - loss: 3.1066 - acc: 0.6567\n",
            "Epoch 4/30\n",
            "12272/12272 [==============================] - 1s 109us/step - loss: 4.0062 - acc: 0.5830\n",
            "Epoch 5/30\n",
            "12272/12272 [==============================] - 1s 114us/step - loss: 3.5265 - acc: 0.6232\n",
            "Epoch 6/30\n",
            "12272/12272 [==============================] - 1s 110us/step - loss: 3.1587 - acc: 0.6520\n",
            "Epoch 7/30\n",
            "12272/12272 [==============================] - 1s 110us/step - loss: 3.4336 - acc: 0.6155\n",
            "Epoch 8/30\n",
            "12272/12272 [==============================] - 1s 109us/step - loss: 3.1918 - acc: 0.6572\n",
            "Epoch 9/30\n",
            "12272/12272 [==============================] - 1s 111us/step - loss: 2.6679 - acc: 0.6499\n",
            "Epoch 10/30\n",
            "12272/12272 [==============================] - 1s 108us/step - loss: 2.7968 - acc: 0.6543\n",
            "Epoch 11/30\n",
            "12272/12272 [==============================] - 1s 112us/step - loss: 2.5459 - acc: 0.6689\n",
            "Epoch 12/30\n",
            "12272/12272 [==============================] - 1s 110us/step - loss: 2.4672 - acc: 0.6780\n",
            "Epoch 13/30\n",
            "12272/12272 [==============================] - 1s 110us/step - loss: 2.4143 - acc: 0.6754\n",
            "Epoch 14/30\n",
            "12272/12272 [==============================] - 1s 113us/step - loss: 2.3995 - acc: 0.6807\n",
            "Epoch 15/30\n",
            "12272/12272 [==============================] - 1s 109us/step - loss: 2.4680 - acc: 0.6763\n",
            "Epoch 16/30\n",
            "12272/12272 [==============================] - 1s 110us/step - loss: 2.8421 - acc: 0.6337\n",
            "Epoch 17/30\n",
            "12272/12272 [==============================] - 1s 109us/step - loss: 2.3841 - acc: 0.6765\n",
            "Epoch 18/30\n",
            "12272/12272 [==============================] - 1s 110us/step - loss: 2.2931 - acc: 0.6823\n",
            "Epoch 19/30\n",
            "12272/12272 [==============================] - 1s 108us/step - loss: 2.3151 - acc: 0.6855\n",
            "Epoch 20/30\n",
            "12272/12272 [==============================] - 1s 107us/step - loss: 2.2868 - acc: 0.6776\n",
            "Epoch 21/30\n",
            "12272/12272 [==============================] - 1s 108us/step - loss: 2.3276 - acc: 0.6804\n",
            "Epoch 22/30\n",
            "12272/12272 [==============================] - 1s 108us/step - loss: 2.4226 - acc: 0.6861\n",
            "Epoch 23/30\n",
            "12272/12272 [==============================] - 1s 108us/step - loss: 2.2945 - acc: 0.6774\n",
            "Epoch 24/30\n",
            "12272/12272 [==============================] - 1s 110us/step - loss: 2.2502 - acc: 0.6808\n",
            "Epoch 25/30\n",
            "12272/12272 [==============================] - 1s 109us/step - loss: 2.3202 - acc: 0.6742\n",
            "Epoch 26/30\n",
            "12272/12272 [==============================] - 1s 113us/step - loss: 2.2755 - acc: 0.6864\n",
            "Epoch 27/30\n",
            "12272/12272 [==============================] - 1s 113us/step - loss: 2.4308 - acc: 0.6578\n",
            "Epoch 28/30\n",
            "12272/12272 [==============================] - 1s 111us/step - loss: 2.1650 - acc: 0.6846\n",
            "Epoch 29/30\n",
            "12272/12272 [==============================] - 1s 112us/step - loss: 2.1920 - acc: 0.6729\n",
            "Epoch 30/30\n",
            "12272/12272 [==============================] - 1s 111us/step - loss: 2.2216 - acc: 0.6868\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 4s 323us/step - loss: 0.6154 - acc: 0.6955\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 131us/step - loss: 0.6110 - acc: 0.6955\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 133us/step - loss: 0.6076 - acc: 0.6955\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 0.6047 - acc: 0.6955\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 137us/step - loss: 0.6019 - acc: 0.6955\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 130us/step - loss: 0.5995 - acc: 0.6955\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 137us/step - loss: 0.5974 - acc: 0.6955\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.5954 - acc: 0.6956\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.5935 - acc: 0.6957\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.5917 - acc: 0.6957\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 4s 340us/step - loss: 0.6171 - acc: 0.6955\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 145us/step - loss: 0.6067 - acc: 0.6955\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 141us/step - loss: 0.6034 - acc: 0.6955\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 140us/step - loss: 0.6001 - acc: 0.6955\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 147us/step - loss: 0.5974 - acc: 0.6955\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 145us/step - loss: 0.5948 - acc: 0.6955\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.5926 - acc: 0.6955\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 142us/step - loss: 0.5905 - acc: 0.6956\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 143us/step - loss: 0.5885 - acc: 0.6955\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 138us/step - loss: 0.5867 - acc: 0.6951\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 4s 326us/step - loss: 0.6987 - acc: 0.6000\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 140us/step - loss: 0.6061 - acc: 0.6955\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 132us/step - loss: 0.6032 - acc: 0.6955\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 133us/step - loss: 0.6005 - acc: 0.6955\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.5981 - acc: 0.6955\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 132us/step - loss: 0.5958 - acc: 0.6955\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 133us/step - loss: 0.5939 - acc: 0.6955\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.5919 - acc: 0.6956\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 132us/step - loss: 0.5902 - acc: 0.6957\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.5886 - acc: 0.6959\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 4s 340us/step - loss: 0.6452 - acc: 0.6365\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 141us/step - loss: 0.6023 - acc: 0.6955\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 139us/step - loss: 0.5993 - acc: 0.6955\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 140us/step - loss: 0.5965 - acc: 0.6955\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 141us/step - loss: 0.5941 - acc: 0.6955\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 139us/step - loss: 0.5919 - acc: 0.6956\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 148us/step - loss: 0.5898 - acc: 0.6956\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 138us/step - loss: 0.5880 - acc: 0.6955\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 145us/step - loss: 0.5862 - acc: 0.6957\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 146us/step - loss: 0.5846 - acc: 0.6964\n",
            "Epoch 1/10\n",
            "12272/12272 [==============================] - 4s 336us/step - loss: 0.6154 - acc: 0.6954\n",
            "Epoch 2/10\n",
            "12272/12272 [==============================] - 2s 139us/step - loss: 0.6088 - acc: 0.6956\n",
            "Epoch 3/10\n",
            "12272/12272 [==============================] - 2s 138us/step - loss: 0.6061 - acc: 0.6956\n",
            "Epoch 4/10\n",
            "12272/12272 [==============================] - 2s 139us/step - loss: 0.6036 - acc: 0.6956\n",
            "Epoch 5/10\n",
            "12272/12272 [==============================] - 2s 134us/step - loss: 0.6014 - acc: 0.6956\n",
            "Epoch 6/10\n",
            "12272/12272 [==============================] - 2s 138us/step - loss: 0.5993 - acc: 0.6956\n",
            "Epoch 7/10\n",
            "12272/12272 [==============================] - 2s 138us/step - loss: 0.5975 - acc: 0.6955\n",
            "Epoch 8/10\n",
            "12272/12272 [==============================] - 2s 135us/step - loss: 0.5957 - acc: 0.6948\n",
            "Epoch 9/10\n",
            "12272/12272 [==============================] - 2s 133us/step - loss: 0.5941 - acc: 0.6943\n",
            "Epoch 10/10\n",
            "12272/12272 [==============================] - 2s 134us/step - loss: 0.5925 - acc: 0.6931\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 5s 405us/step - loss: 0.4977 - acc: 0.7632\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 197us/step - loss: 0.3938 - acc: 0.8307\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 197us/step - loss: 0.3611 - acc: 0.8466\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 197us/step - loss: 0.3505 - acc: 0.8491\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 197us/step - loss: 0.3509 - acc: 0.8487\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 198us/step - loss: 0.3373 - acc: 0.8547\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 194us/step - loss: 0.3291 - acc: 0.8568\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 193us/step - loss: 0.3322 - acc: 0.8573\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 194us/step - loss: 0.3238 - acc: 0.8638\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 192us/step - loss: 0.3173 - acc: 0.8627\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 5s 408us/step - loss: 0.5167 - acc: 0.7535\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 187us/step - loss: 0.3980 - acc: 0.8309\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 194us/step - loss: 0.3649 - acc: 0.8449\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 202us/step - loss: 0.3513 - acc: 0.8504\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 197us/step - loss: 0.3406 - acc: 0.8567\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 192us/step - loss: 0.3391 - acc: 0.8584\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 3s 204us/step - loss: 0.3278 - acc: 0.8626\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 199us/step - loss: 0.3230 - acc: 0.8604\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 201us/step - loss: 0.3244 - acc: 0.8608\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 199us/step - loss: 0.3105 - acc: 0.8671\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 5s 420us/step - loss: 0.4942 - acc: 0.7585\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 3s 204us/step - loss: 0.4098 - acc: 0.8196\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 201us/step - loss: 0.3727 - acc: 0.8445\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 197us/step - loss: 0.3594 - acc: 0.8462\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 3s 205us/step - loss: 0.3466 - acc: 0.8539\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 199us/step - loss: 0.3501 - acc: 0.8509\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 203us/step - loss: 0.3340 - acc: 0.8561\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 3s 204us/step - loss: 0.3324 - acc: 0.8583\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 3s 204us/step - loss: 0.3260 - acc: 0.8602\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 3s 207us/step - loss: 0.3207 - acc: 0.8631\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 5s 425us/step - loss: 0.4976 - acc: 0.7602\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 3s 207us/step - loss: 0.3968 - acc: 0.8325\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 202us/step - loss: 0.3688 - acc: 0.8439\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 204us/step - loss: 0.3497 - acc: 0.8517\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 200us/step - loss: 0.3445 - acc: 0.8540\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 202us/step - loss: 0.3372 - acc: 0.8548\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 200us/step - loss: 0.3322 - acc: 0.8566\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 3s 209us/step - loss: 0.3300 - acc: 0.8604\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 203us/step - loss: 0.3217 - acc: 0.8633\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 201us/step - loss: 0.3161 - acc: 0.8664\n",
            "Epoch 1/10\n",
            "12272/12272 [==============================] - 5s 433us/step - loss: 0.4909 - acc: 0.7638\n",
            "Epoch 2/10\n",
            "12272/12272 [==============================] - 3s 204us/step - loss: 0.3919 - acc: 0.8333\n",
            "Epoch 3/10\n",
            "12272/12272 [==============================] - 2s 202us/step - loss: 0.3698 - acc: 0.8431\n",
            "Epoch 4/10\n",
            "12272/12272 [==============================] - 3s 204us/step - loss: 0.3514 - acc: 0.8506\n",
            "Epoch 5/10\n",
            "12272/12272 [==============================] - 3s 208us/step - loss: 0.3425 - acc: 0.8549\n",
            "Epoch 6/10\n",
            "12272/12272 [==============================] - 2s 198us/step - loss: 0.3355 - acc: 0.8572\n",
            "Epoch 7/10\n",
            "12272/12272 [==============================] - 2s 202us/step - loss: 0.3313 - acc: 0.8590\n",
            "Epoch 8/10\n",
            "12272/12272 [==============================] - 2s 201us/step - loss: 0.3249 - acc: 0.8594\n",
            "Epoch 9/10\n",
            "12272/12272 [==============================] - 2s 193us/step - loss: 0.3199 - acc: 0.8648\n",
            "Epoch 10/10\n",
            "12272/12272 [==============================] - 2s 196us/step - loss: 0.3131 - acc: 0.8679\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 5s 403us/step - loss: 0.5063 - acc: 0.7525\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 164us/step - loss: 0.4076 - acc: 0.8231\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 160us/step - loss: 0.3762 - acc: 0.8373\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 166us/step - loss: 0.3583 - acc: 0.8465\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 167us/step - loss: 0.3502 - acc: 0.8500\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 171us/step - loss: 0.3429 - acc: 0.8530\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 175us/step - loss: 0.3393 - acc: 0.8554\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 180us/step - loss: 0.3328 - acc: 0.8571\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 178us/step - loss: 0.3283 - acc: 0.8622\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 175us/step - loss: 0.3248 - acc: 0.8622\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 5s 394us/step - loss: 0.5077 - acc: 0.7537\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 168us/step - loss: 0.4024 - acc: 0.8236\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 171us/step - loss: 0.3715 - acc: 0.8433\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 174us/step - loss: 0.3580 - acc: 0.8478\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 175us/step - loss: 0.3507 - acc: 0.8533\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 173us/step - loss: 0.3410 - acc: 0.8554\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 174us/step - loss: 0.3358 - acc: 0.8587\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 175us/step - loss: 0.3308 - acc: 0.8594\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 175us/step - loss: 0.3234 - acc: 0.8635\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 174us/step - loss: 0.3203 - acc: 0.8640\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 5s 413us/step - loss: 0.5099 - acc: 0.7487\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 178us/step - loss: 0.4115 - acc: 0.8182\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 176us/step - loss: 0.3783 - acc: 0.8385\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 177us/step - loss: 0.3650 - acc: 0.8414\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 176us/step - loss: 0.3549 - acc: 0.8489\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 180us/step - loss: 0.3481 - acc: 0.8494\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 177us/step - loss: 0.3424 - acc: 0.8505\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 176us/step - loss: 0.3367 - acc: 0.8562\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 175us/step - loss: 0.3306 - acc: 0.8576\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 175us/step - loss: 0.3288 - acc: 0.8600\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 5s 421us/step - loss: 0.5052 - acc: 0.7554\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 180us/step - loss: 0.4067 - acc: 0.8242\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 0.3763 - acc: 0.8392\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 177us/step - loss: 0.3591 - acc: 0.8485\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 178us/step - loss: 0.3501 - acc: 0.8524\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 174us/step - loss: 0.3426 - acc: 0.8551\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 179us/step - loss: 0.3356 - acc: 0.8584\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 169us/step - loss: 0.3319 - acc: 0.8582\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 171us/step - loss: 0.3286 - acc: 0.8592\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 169us/step - loss: 0.3221 - acc: 0.8635\n",
            "Epoch 1/10\n",
            "12272/12272 [==============================] - 5s 410us/step - loss: 0.5017 - acc: 0.7577\n",
            "Epoch 2/10\n",
            "12272/12272 [==============================] - 2s 177us/step - loss: 0.4061 - acc: 0.8257\n",
            "Epoch 3/10\n",
            "12272/12272 [==============================] - 2s 178us/step - loss: 0.3747 - acc: 0.8392\n",
            "Epoch 4/10\n",
            "12272/12272 [==============================] - 2s 174us/step - loss: 0.3580 - acc: 0.8485\n",
            "Epoch 5/10\n",
            "12272/12272 [==============================] - 2s 178us/step - loss: 0.3475 - acc: 0.8514\n",
            "Epoch 6/10\n",
            "12272/12272 [==============================] - 2s 175us/step - loss: 0.3410 - acc: 0.8554\n",
            "Epoch 7/10\n",
            "12272/12272 [==============================] - 2s 178us/step - loss: 0.3351 - acc: 0.8566\n",
            "Epoch 8/10\n",
            "12272/12272 [==============================] - 2s 173us/step - loss: 0.3297 - acc: 0.8605\n",
            "Epoch 9/10\n",
            "12272/12272 [==============================] - 2s 174us/step - loss: 0.3243 - acc: 0.8609\n",
            "Epoch 10/10\n",
            "12272/12272 [==============================] - 2s 173us/step - loss: 0.3213 - acc: 0.8607\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 5s 374us/step - loss: 0.6204 - acc: 0.6786\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 150us/step - loss: 0.6031 - acc: 0.6955\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 137us/step - loss: 0.6004 - acc: 0.6955\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 137us/step - loss: 0.5980 - acc: 0.6955\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 139us/step - loss: 0.5957 - acc: 0.6955\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 145us/step - loss: 0.5937 - acc: 0.6957\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.5918 - acc: 0.6959\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 143us/step - loss: 0.5899 - acc: 0.6961\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.5882 - acc: 0.6955\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 139us/step - loss: 0.5866 - acc: 0.6951\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.5851 - acc: 0.6946\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 137us/step - loss: 0.5835 - acc: 0.6942\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 139us/step - loss: 0.5821 - acc: 0.6949\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 138us/step - loss: 0.5808 - acc: 0.6936\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.5794 - acc: 0.6949\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 134us/step - loss: 0.5781 - acc: 0.6942\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 139us/step - loss: 0.5768 - acc: 0.6950\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.5755 - acc: 0.6945\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 141us/step - loss: 0.5742 - acc: 0.6931\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 138us/step - loss: 0.5731 - acc: 0.6951\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 138us/step - loss: 0.5719 - acc: 0.6942\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 142us/step - loss: 0.5707 - acc: 0.6950\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 147us/step - loss: 0.5694 - acc: 0.6951\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.5683 - acc: 0.6958\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 147us/step - loss: 0.5672 - acc: 0.6962\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 132us/step - loss: 0.5660 - acc: 0.6964\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.5649 - acc: 0.6973\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 140us/step - loss: 0.5638 - acc: 0.6977\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 138us/step - loss: 0.5626 - acc: 0.6991\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 142us/step - loss: 0.5615 - acc: 0.6986\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 5s 381us/step - loss: 0.6130 - acc: 0.6955\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 147us/step - loss: 0.6088 - acc: 0.6955\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 138us/step - loss: 0.6055 - acc: 0.6955\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 143us/step - loss: 0.6025 - acc: 0.6955\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 146us/step - loss: 0.5998 - acc: 0.6955\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 144us/step - loss: 0.5974 - acc: 0.6955\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 146us/step - loss: 0.5951 - acc: 0.6955\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 143us/step - loss: 0.5931 - acc: 0.6955\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 149us/step - loss: 0.5912 - acc: 0.6956\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 143us/step - loss: 0.5895 - acc: 0.6956\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 144us/step - loss: 0.5879 - acc: 0.6955\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 143us/step - loss: 0.5863 - acc: 0.6951\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 138us/step - loss: 0.5849 - acc: 0.6952\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 142us/step - loss: 0.5835 - acc: 0.6939\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 137us/step - loss: 0.5821 - acc: 0.6934\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 137us/step - loss: 0.5808 - acc: 0.6938\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.5795 - acc: 0.6937\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 137us/step - loss: 0.5783 - acc: 0.6919\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 139us/step - loss: 0.5771 - acc: 0.6924\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 139us/step - loss: 0.5759 - acc: 0.6914\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 142us/step - loss: 0.5748 - acc: 0.6921\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 139us/step - loss: 0.5736 - acc: 0.6915\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 142us/step - loss: 0.5725 - acc: 0.6914\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 139us/step - loss: 0.5714 - acc: 0.6916\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 134us/step - loss: 0.5703 - acc: 0.6906\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.5692 - acc: 0.6909\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 140us/step - loss: 0.5681 - acc: 0.6907\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.5670 - acc: 0.6907\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 134us/step - loss: 0.5659 - acc: 0.6920\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 139us/step - loss: 0.5649 - acc: 0.6917\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 5s 391us/step - loss: 0.6178 - acc: 0.6955\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 145us/step - loss: 0.6134 - acc: 0.6955\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 141us/step - loss: 0.6097 - acc: 0.6955\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 141us/step - loss: 0.6065 - acc: 0.6955\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 145us/step - loss: 0.6035 - acc: 0.6955\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 143us/step - loss: 0.6009 - acc: 0.6955\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 142us/step - loss: 0.5985 - acc: 0.6955\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 142us/step - loss: 0.5964 - acc: 0.6955\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.5944 - acc: 0.6955\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 140us/step - loss: 0.5926 - acc: 0.6955\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 140us/step - loss: 0.5908 - acc: 0.6955\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 137us/step - loss: 0.5891 - acc: 0.6955\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 142us/step - loss: 0.5878 - acc: 0.6955\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.5863 - acc: 0.6949\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 142us/step - loss: 0.5849 - acc: 0.6949\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 141us/step - loss: 0.5835 - acc: 0.6942\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 143us/step - loss: 0.5822 - acc: 0.6941\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 137us/step - loss: 0.5809 - acc: 0.6944\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 140us/step - loss: 0.5798 - acc: 0.6933\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 134us/step - loss: 0.5786 - acc: 0.6935\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 133us/step - loss: 0.5774 - acc: 0.6924\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 137us/step - loss: 0.5762 - acc: 0.6919\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 137us/step - loss: 0.5751 - acc: 0.6917\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 138us/step - loss: 0.5740 - acc: 0.6923\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 144us/step - loss: 0.5729 - acc: 0.6928\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 139us/step - loss: 0.5718 - acc: 0.6927\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 143us/step - loss: 0.5707 - acc: 0.6942\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 144us/step - loss: 0.5696 - acc: 0.6942\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 141us/step - loss: 0.5686 - acc: 0.6952\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 141us/step - loss: 0.5675 - acc: 0.6952\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 5s 398us/step - loss: 0.6220 - acc: 0.6827\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 140us/step - loss: 0.6074 - acc: 0.6955\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 142us/step - loss: 0.6042 - acc: 0.6955\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 149us/step - loss: 0.6016 - acc: 0.6955\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 146us/step - loss: 0.5990 - acc: 0.6955\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 144us/step - loss: 0.5966 - acc: 0.6955\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 141us/step - loss: 0.5945 - acc: 0.6955\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 145us/step - loss: 0.5926 - acc: 0.6955\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 138us/step - loss: 0.5907 - acc: 0.6956\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 144us/step - loss: 0.5890 - acc: 0.6955\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 139us/step - loss: 0.5874 - acc: 0.6955\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 140us/step - loss: 0.5858 - acc: 0.6951\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 148us/step - loss: 0.5843 - acc: 0.6952\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 143us/step - loss: 0.5830 - acc: 0.6949\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 143us/step - loss: 0.5816 - acc: 0.6947\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 148us/step - loss: 0.5803 - acc: 0.6946\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 153us/step - loss: 0.5789 - acc: 0.6929\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 147us/step - loss: 0.5777 - acc: 0.6940\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 146us/step - loss: 0.5765 - acc: 0.6929\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 142us/step - loss: 0.5753 - acc: 0.6929\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 146us/step - loss: 0.5740 - acc: 0.6935\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 143us/step - loss: 0.5729 - acc: 0.6924\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 141us/step - loss: 0.5718 - acc: 0.6920\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 142us/step - loss: 0.5706 - acc: 0.6920\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 149us/step - loss: 0.5695 - acc: 0.6930\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 149us/step - loss: 0.5684 - acc: 0.6925\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 146us/step - loss: 0.5673 - acc: 0.6932\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 146us/step - loss: 0.5662 - acc: 0.6936\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 147us/step - loss: 0.5651 - acc: 0.6951\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 146us/step - loss: 0.5640 - acc: 0.6943\n",
            "Epoch 1/30\n",
            "12272/12272 [==============================] - 5s 405us/step - loss: 0.6110 - acc: 0.6956\n",
            "Epoch 2/30\n",
            "12272/12272 [==============================] - 2s 147us/step - loss: 0.6059 - acc: 0.6956\n",
            "Epoch 3/30\n",
            "12272/12272 [==============================] - 2s 150us/step - loss: 0.6028 - acc: 0.6956\n",
            "Epoch 4/30\n",
            "12272/12272 [==============================] - 2s 146us/step - loss: 0.6002 - acc: 0.6956\n",
            "Epoch 5/30\n",
            "12272/12272 [==============================] - 2s 145us/step - loss: 0.5977 - acc: 0.6956\n",
            "Epoch 6/30\n",
            "12272/12272 [==============================] - 2s 146us/step - loss: 0.5954 - acc: 0.6956\n",
            "Epoch 7/30\n",
            "12272/12272 [==============================] - 2s 145us/step - loss: 0.5934 - acc: 0.6957\n",
            "Epoch 8/30\n",
            "12272/12272 [==============================] - 2s 149us/step - loss: 0.5915 - acc: 0.6957\n",
            "Epoch 9/30\n",
            "12272/12272 [==============================] - 2s 145us/step - loss: 0.5897 - acc: 0.6957\n",
            "Epoch 10/30\n",
            "12272/12272 [==============================] - 2s 145us/step - loss: 0.5880 - acc: 0.6957\n",
            "Epoch 11/30\n",
            "12272/12272 [==============================] - 2s 143us/step - loss: 0.5864 - acc: 0.6957\n",
            "Epoch 12/30\n",
            "12272/12272 [==============================] - 2s 146us/step - loss: 0.5849 - acc: 0.6960\n",
            "Epoch 13/30\n",
            "12272/12272 [==============================] - 2s 145us/step - loss: 0.5836 - acc: 0.6957\n",
            "Epoch 14/30\n",
            "12272/12272 [==============================] - 2s 148us/step - loss: 0.5821 - acc: 0.6954\n",
            "Epoch 15/30\n",
            "12272/12272 [==============================] - 2s 165us/step - loss: 0.5809 - acc: 0.6959\n",
            "Epoch 16/30\n",
            "12272/12272 [==============================] - 2s 161us/step - loss: 0.5796 - acc: 0.6960\n",
            "Epoch 17/30\n",
            "12272/12272 [==============================] - 2s 167us/step - loss: 0.5783 - acc: 0.6957\n",
            "Epoch 18/30\n",
            "12272/12272 [==============================] - 2s 157us/step - loss: 0.5770 - acc: 0.6942\n",
            "Epoch 19/30\n",
            "12272/12272 [==============================] - 2s 155us/step - loss: 0.5758 - acc: 0.6949\n",
            "Epoch 20/30\n",
            "12272/12272 [==============================] - 2s 136us/step - loss: 0.5747 - acc: 0.6946\n",
            "Epoch 21/30\n",
            "12272/12272 [==============================] - 2s 144us/step - loss: 0.5736 - acc: 0.6957\n",
            "Epoch 22/30\n",
            "12272/12272 [==============================] - 2s 137us/step - loss: 0.5724 - acc: 0.6961\n",
            "Epoch 23/30\n",
            "12272/12272 [==============================] - 2s 144us/step - loss: 0.5713 - acc: 0.6955\n",
            "Epoch 24/30\n",
            "12272/12272 [==============================] - 2s 140us/step - loss: 0.5702 - acc: 0.6952\n",
            "Epoch 25/30\n",
            "12272/12272 [==============================] - 2s 135us/step - loss: 0.5690 - acc: 0.6955\n",
            "Epoch 26/30\n",
            "12272/12272 [==============================] - 2s 140us/step - loss: 0.5679 - acc: 0.6970\n",
            "Epoch 27/30\n",
            "12272/12272 [==============================] - 2s 144us/step - loss: 0.5668 - acc: 0.6976\n",
            "Epoch 28/30\n",
            "12272/12272 [==============================] - 2s 145us/step - loss: 0.5658 - acc: 0.6976\n",
            "Epoch 29/30\n",
            "12272/12272 [==============================] - 2s 145us/step - loss: 0.5646 - acc: 0.6967\n",
            "Epoch 30/30\n",
            "12272/12272 [==============================] - 2s 141us/step - loss: 0.5637 - acc: 0.6979\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 6s 456us/step - loss: 0.5057 - acc: 0.7519\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 199us/step - loss: 0.3966 - acc: 0.8329\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 196us/step - loss: 0.3679 - acc: 0.8420\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 203us/step - loss: 0.3529 - acc: 0.8509\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 200us/step - loss: 0.3446 - acc: 0.8517\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 3s 206us/step - loss: 0.3378 - acc: 0.8568\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 198us/step - loss: 0.3339 - acc: 0.8576\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 3s 205us/step - loss: 0.3290 - acc: 0.8572\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 197us/step - loss: 0.3241 - acc: 0.8615\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 3s 209us/step - loss: 0.3211 - acc: 0.8626\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 3s 210us/step - loss: 0.3121 - acc: 0.8658\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 3s 207us/step - loss: 0.3102 - acc: 0.8672\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 204us/step - loss: 0.3022 - acc: 0.8736\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 202us/step - loss: 0.2990 - acc: 0.8747\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 202us/step - loss: 0.2925 - acc: 0.8775\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 203us/step - loss: 0.2843 - acc: 0.8813\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 201us/step - loss: 0.2785 - acc: 0.8857\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 199us/step - loss: 0.2687 - acc: 0.8914\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 199us/step - loss: 0.2638 - acc: 0.8930\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 202us/step - loss: 0.2590 - acc: 0.8960\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 3s 211us/step - loss: 0.2514 - acc: 0.8972\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 197us/step - loss: 0.2392 - acc: 0.9060\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 202us/step - loss: 0.2296 - acc: 0.9124\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 203us/step - loss: 0.2228 - acc: 0.9138\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 186us/step - loss: 0.2181 - acc: 0.9152\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 192us/step - loss: 0.2080 - acc: 0.9210\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 193us/step - loss: 0.1987 - acc: 0.9255\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 197us/step - loss: 0.1920 - acc: 0.9306\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 200us/step - loss: 0.1810 - acc: 0.9333\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 204us/step - loss: 0.1765 - acc: 0.9372\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 6s 465us/step - loss: 0.4914 - acc: 0.7619\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 201us/step - loss: 0.3938 - acc: 0.8320\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 203us/step - loss: 0.3643 - acc: 0.8491\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 193us/step - loss: 0.3537 - acc: 0.8509\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 192us/step - loss: 0.3433 - acc: 0.8561\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 197us/step - loss: 0.3388 - acc: 0.8554\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 194us/step - loss: 0.3306 - acc: 0.8619\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 201us/step - loss: 0.3258 - acc: 0.8603\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 203us/step - loss: 0.3218 - acc: 0.8636\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 202us/step - loss: 0.3153 - acc: 0.8667\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 3s 205us/step - loss: 0.3119 - acc: 0.8675\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 3s 205us/step - loss: 0.3092 - acc: 0.8691\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 201us/step - loss: 0.2992 - acc: 0.8720\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 200us/step - loss: 0.2975 - acc: 0.8761\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 199us/step - loss: 0.2907 - acc: 0.8791\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 203us/step - loss: 0.2847 - acc: 0.8847\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 199us/step - loss: 0.2789 - acc: 0.8847\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 3s 207us/step - loss: 0.2686 - acc: 0.8928\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 202us/step - loss: 0.2623 - acc: 0.8953\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 200us/step - loss: 0.2567 - acc: 0.8972\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 198us/step - loss: 0.2484 - acc: 0.9008\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 201us/step - loss: 0.2373 - acc: 0.9072\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 3s 206us/step - loss: 0.2315 - acc: 0.9091\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 3s 205us/step - loss: 0.2222 - acc: 0.9148\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 200us/step - loss: 0.2117 - acc: 0.9212\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 198us/step - loss: 0.2050 - acc: 0.9256\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 201us/step - loss: 0.1956 - acc: 0.9272\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 3s 207us/step - loss: 0.1903 - acc: 0.9329\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 3s 206us/step - loss: 0.1783 - acc: 0.9368\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 3s 205us/step - loss: 0.1719 - acc: 0.9388\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 6s 479us/step - loss: 0.5045 - acc: 0.7576\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 203us/step - loss: 0.4000 - acc: 0.8284\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 3s 210us/step - loss: 0.3680 - acc: 0.8412\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 3s 209us/step - loss: 0.3542 - acc: 0.8489\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 3s 208us/step - loss: 0.3474 - acc: 0.8519\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 3s 207us/step - loss: 0.3437 - acc: 0.8535\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 3s 212us/step - loss: 0.3403 - acc: 0.8536\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 3s 214us/step - loss: 0.3314 - acc: 0.8589\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 3s 211us/step - loss: 0.3258 - acc: 0.8611\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 3s 204us/step - loss: 0.3208 - acc: 0.8621\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 203us/step - loss: 0.3180 - acc: 0.8672\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 203us/step - loss: 0.3130 - acc: 0.8688\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 3s 208us/step - loss: 0.3070 - acc: 0.8700\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 3s 211us/step - loss: 0.3009 - acc: 0.8747\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 3s 204us/step - loss: 0.2962 - acc: 0.8765\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 3s 208us/step - loss: 0.2902 - acc: 0.8788\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 3s 207us/step - loss: 0.2816 - acc: 0.8824\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 3s 206us/step - loss: 0.2752 - acc: 0.8871\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 203us/step - loss: 0.2685 - acc: 0.8895\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 202us/step - loss: 0.2638 - acc: 0.8935\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 200us/step - loss: 0.2520 - acc: 0.9026\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 3s 205us/step - loss: 0.2476 - acc: 0.9028\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 3s 208us/step - loss: 0.2374 - acc: 0.9072\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 3s 207us/step - loss: 0.2279 - acc: 0.9113\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 203us/step - loss: 0.2211 - acc: 0.9186\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 202us/step - loss: 0.2129 - acc: 0.9199\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 3s 210us/step - loss: 0.2035 - acc: 0.9263\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 201us/step - loss: 0.1941 - acc: 0.9278\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 202us/step - loss: 0.1871 - acc: 0.9320\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 203us/step - loss: 0.1791 - acc: 0.9359\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 6s 480us/step - loss: 0.4995 - acc: 0.7584\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 203us/step - loss: 0.3970 - acc: 0.8330\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 3s 206us/step - loss: 0.3656 - acc: 0.8456\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 3s 206us/step - loss: 0.3538 - acc: 0.8500\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 3s 210us/step - loss: 0.3443 - acc: 0.8545\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 3s 207us/step - loss: 0.3343 - acc: 0.8567\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 202us/step - loss: 0.3300 - acc: 0.8580\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 201us/step - loss: 0.3292 - acc: 0.8588\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 3s 205us/step - loss: 0.3208 - acc: 0.8642\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 201us/step - loss: 0.3170 - acc: 0.8657\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 203us/step - loss: 0.3104 - acc: 0.8664\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 201us/step - loss: 0.3053 - acc: 0.8719\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 3s 211us/step - loss: 0.3001 - acc: 0.8726\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 3s 221us/step - loss: 0.2957 - acc: 0.8765\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 3s 219us/step - loss: 0.2866 - acc: 0.8794\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 3s 215us/step - loss: 0.2818 - acc: 0.8825\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 3s 213us/step - loss: 0.2717 - acc: 0.8871\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 199us/step - loss: 0.2663 - acc: 0.8929\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 202us/step - loss: 0.2576 - acc: 0.8972\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 3s 205us/step - loss: 0.2490 - acc: 0.9016\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 3s 206us/step - loss: 0.2421 - acc: 0.9051\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 203us/step - loss: 0.2358 - acc: 0.9085\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 202us/step - loss: 0.2263 - acc: 0.9134\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 3s 205us/step - loss: 0.2196 - acc: 0.9162\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 204us/step - loss: 0.2074 - acc: 0.9235\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 202us/step - loss: 0.2014 - acc: 0.9248\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 199us/step - loss: 0.1956 - acc: 0.9274\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 204us/step - loss: 0.1877 - acc: 0.9318\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 3s 208us/step - loss: 0.1789 - acc: 0.9373\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 199us/step - loss: 0.1739 - acc: 0.9388\n",
            "Epoch 1/30\n",
            "12272/12272 [==============================] - 6s 485us/step - loss: 0.4946 - acc: 0.7621\n",
            "Epoch 2/30\n",
            "12272/12272 [==============================] - 3s 205us/step - loss: 0.3956 - acc: 0.8294\n",
            "Epoch 3/30\n",
            "12272/12272 [==============================] - 2s 196us/step - loss: 0.3691 - acc: 0.8439\n",
            "Epoch 4/30\n",
            "12272/12272 [==============================] - 2s 199us/step - loss: 0.3534 - acc: 0.8523\n",
            "Epoch 5/30\n",
            "12272/12272 [==============================] - 2s 201us/step - loss: 0.3443 - acc: 0.8531\n",
            "Epoch 6/30\n",
            "12272/12272 [==============================] - 3s 210us/step - loss: 0.3433 - acc: 0.8537\n",
            "Epoch 7/30\n",
            "12272/12272 [==============================] - 2s 201us/step - loss: 0.3291 - acc: 0.8607\n",
            "Epoch 8/30\n",
            "12272/12272 [==============================] - 2s 200us/step - loss: 0.3253 - acc: 0.8594\n",
            "Epoch 9/30\n",
            "12272/12272 [==============================] - 2s 200us/step - loss: 0.3199 - acc: 0.8637\n",
            "Epoch 10/30\n",
            "12272/12272 [==============================] - 3s 210us/step - loss: 0.3136 - acc: 0.8639\n",
            "Epoch 11/30\n",
            "12272/12272 [==============================] - 3s 214us/step - loss: 0.3124 - acc: 0.8679\n",
            "Epoch 12/30\n",
            "12272/12272 [==============================] - 3s 214us/step - loss: 0.3052 - acc: 0.8734\n",
            "Epoch 13/30\n",
            "12272/12272 [==============================] - 3s 209us/step - loss: 0.2981 - acc: 0.8736\n",
            "Epoch 14/30\n",
            "12272/12272 [==============================] - 3s 209us/step - loss: 0.2909 - acc: 0.8788\n",
            "Epoch 15/30\n",
            "12272/12272 [==============================] - 3s 210us/step - loss: 0.2857 - acc: 0.8814\n",
            "Epoch 16/30\n",
            "12272/12272 [==============================] - 3s 217us/step - loss: 0.2816 - acc: 0.8831\n",
            "Epoch 17/30\n",
            "12272/12272 [==============================] - 3s 213us/step - loss: 0.2707 - acc: 0.8902\n",
            "Epoch 18/30\n",
            "12272/12272 [==============================] - 3s 211us/step - loss: 0.2663 - acc: 0.8924\n",
            "Epoch 19/30\n",
            "12272/12272 [==============================] - 3s 212us/step - loss: 0.2599 - acc: 0.8963\n",
            "Epoch 20/30\n",
            "12272/12272 [==============================] - 3s 211us/step - loss: 0.2502 - acc: 0.8992\n",
            "Epoch 21/30\n",
            "12272/12272 [==============================] - 3s 209us/step - loss: 0.2430 - acc: 0.9026\n",
            "Epoch 22/30\n",
            "12272/12272 [==============================] - 3s 213us/step - loss: 0.2326 - acc: 0.9082\n",
            "Epoch 23/30\n",
            "12272/12272 [==============================] - 3s 208us/step - loss: 0.2282 - acc: 0.9094\n",
            "Epoch 24/30\n",
            "12272/12272 [==============================] - 3s 208us/step - loss: 0.2196 - acc: 0.9171\n",
            "Epoch 25/30\n",
            "12272/12272 [==============================] - 3s 211us/step - loss: 0.2106 - acc: 0.9194\n",
            "Epoch 26/30\n",
            "12272/12272 [==============================] - 3s 207us/step - loss: 0.2003 - acc: 0.9254\n",
            "Epoch 27/30\n",
            "12272/12272 [==============================] - 3s 210us/step - loss: 0.1951 - acc: 0.9279\n",
            "Epoch 28/30\n",
            "12272/12272 [==============================] - 3s 210us/step - loss: 0.1858 - acc: 0.9354\n",
            "Epoch 29/30\n",
            "12272/12272 [==============================] - 3s 210us/step - loss: 0.1782 - acc: 0.9383\n",
            "Epoch 30/30\n",
            "12272/12272 [==============================] - 3s 214us/step - loss: 0.1695 - acc: 0.9405\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 6s 463us/step - loss: 0.5074 - acc: 0.7498\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 180us/step - loss: 0.4054 - acc: 0.8233\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 0.3759 - acc: 0.8370\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 176us/step - loss: 0.3593 - acc: 0.8470\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 0.3487 - acc: 0.8514\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 180us/step - loss: 0.3426 - acc: 0.8536\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 179us/step - loss: 0.3376 - acc: 0.8545\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 171us/step - loss: 0.3313 - acc: 0.8584\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 0.3278 - acc: 0.8584\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 0.3235 - acc: 0.8619\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 178us/step - loss: 0.3175 - acc: 0.8659\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 178us/step - loss: 0.3138 - acc: 0.8637\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 0.3092 - acc: 0.8700\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 180us/step - loss: 0.3053 - acc: 0.8683\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 181us/step - loss: 0.2984 - acc: 0.8750\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 176us/step - loss: 0.2936 - acc: 0.8772\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 178us/step - loss: 0.2885 - acc: 0.8782\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 186us/step - loss: 0.2821 - acc: 0.8830\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 0.2757 - acc: 0.8877\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 178us/step - loss: 0.2692 - acc: 0.8911\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 178us/step - loss: 0.2618 - acc: 0.8928\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 0.2558 - acc: 0.8966\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 179us/step - loss: 0.2490 - acc: 0.8996\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 0.2420 - acc: 0.9052\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 178us/step - loss: 0.2350 - acc: 0.9096\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 174us/step - loss: 0.2285 - acc: 0.9116\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 180us/step - loss: 0.2201 - acc: 0.9161\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 179us/step - loss: 0.2153 - acc: 0.9197\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 0.2085 - acc: 0.9206\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 181us/step - loss: 0.2010 - acc: 0.9260\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 6s 460us/step - loss: 0.5106 - acc: 0.7532\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 0.4026 - acc: 0.8254\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 0.3745 - acc: 0.8429\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 181us/step - loss: 0.3526 - acc: 0.8540\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 177us/step - loss: 0.3467 - acc: 0.8554\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 178us/step - loss: 0.3415 - acc: 0.8556\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 186us/step - loss: 0.3356 - acc: 0.8563\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 180us/step - loss: 0.3295 - acc: 0.8602\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 178us/step - loss: 0.3248 - acc: 0.8611\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 176us/step - loss: 0.3195 - acc: 0.8664\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 176us/step - loss: 0.3156 - acc: 0.8674\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 178us/step - loss: 0.3101 - acc: 0.8681\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 181us/step - loss: 0.3045 - acc: 0.8729\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 179us/step - loss: 0.3007 - acc: 0.8730\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 177us/step - loss: 0.2937 - acc: 0.8782\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 0.2890 - acc: 0.8801\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 175us/step - loss: 0.2830 - acc: 0.8836\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 180us/step - loss: 0.2764 - acc: 0.8844\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 0.2701 - acc: 0.8912\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 174us/step - loss: 0.2636 - acc: 0.8938\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 0.2572 - acc: 0.8976\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 0.2500 - acc: 0.9016\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 181us/step - loss: 0.2433 - acc: 0.9059\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 178us/step - loss: 0.2370 - acc: 0.9065\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 0.2303 - acc: 0.9108\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 180us/step - loss: 0.2224 - acc: 0.9144\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 181us/step - loss: 0.2156 - acc: 0.9188\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 185us/step - loss: 0.2083 - acc: 0.9223\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 180us/step - loss: 0.2034 - acc: 0.9239\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 179us/step - loss: 0.1963 - acc: 0.9281\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 6s 468us/step - loss: 0.5079 - acc: 0.7528\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 0.4097 - acc: 0.8206\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 174us/step - loss: 0.3786 - acc: 0.8387\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 178us/step - loss: 0.3635 - acc: 0.8440\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 0.3568 - acc: 0.8465\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 0.3482 - acc: 0.8509\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 174us/step - loss: 0.3429 - acc: 0.8545\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 177us/step - loss: 0.3376 - acc: 0.8562\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 179us/step - loss: 0.3336 - acc: 0.8563\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 176us/step - loss: 0.3298 - acc: 0.8603\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 177us/step - loss: 0.3227 - acc: 0.8624\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 177us/step - loss: 0.3184 - acc: 0.8647\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 0.3129 - acc: 0.8674\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 186us/step - loss: 0.3083 - acc: 0.8697\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 181us/step - loss: 0.3030 - acc: 0.8726\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 0.2980 - acc: 0.8756\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 192us/step - loss: 0.2907 - acc: 0.8805\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 190us/step - loss: 0.2843 - acc: 0.8829\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 195us/step - loss: 0.2795 - acc: 0.8860\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 193us/step - loss: 0.2712 - acc: 0.8903\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 190us/step - loss: 0.2655 - acc: 0.8915\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 180us/step - loss: 0.2572 - acc: 0.8963\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 179us/step - loss: 0.2508 - acc: 0.9025\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 0.2434 - acc: 0.9047\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 186us/step - loss: 0.2373 - acc: 0.9071\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 180us/step - loss: 0.2304 - acc: 0.9122\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 179us/step - loss: 0.2233 - acc: 0.9144\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 0.2163 - acc: 0.9177\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 0.2094 - acc: 0.9215\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 0.2022 - acc: 0.9258\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 6s 466us/step - loss: 0.5070 - acc: 0.7535\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 0.4095 - acc: 0.8243\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 0.3736 - acc: 0.8413\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 0.3611 - acc: 0.8472\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 174us/step - loss: 0.3504 - acc: 0.8513\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 176us/step - loss: 0.3434 - acc: 0.8549\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 180us/step - loss: 0.3371 - acc: 0.8548\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 178us/step - loss: 0.3326 - acc: 0.8573\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 178us/step - loss: 0.3278 - acc: 0.8607\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 181us/step - loss: 0.3232 - acc: 0.8598\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 179us/step - loss: 0.3190 - acc: 0.8650\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 189us/step - loss: 0.3124 - acc: 0.8685\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 185us/step - loss: 0.3081 - acc: 0.8716\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 184us/step - loss: 0.3033 - acc: 0.8720\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 0.2971 - acc: 0.8756\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 180us/step - loss: 0.2914 - acc: 0.8774\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 180us/step - loss: 0.2859 - acc: 0.8837\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 178us/step - loss: 0.2795 - acc: 0.8871\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 178us/step - loss: 0.2741 - acc: 0.8892\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 180us/step - loss: 0.2675 - acc: 0.8926\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 180us/step - loss: 0.2603 - acc: 0.8961\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 182us/step - loss: 0.2542 - acc: 0.8977\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 180us/step - loss: 0.2465 - acc: 0.9036\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 178us/step - loss: 0.2394 - acc: 0.9067\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 178us/step - loss: 0.2345 - acc: 0.9076\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 177us/step - loss: 0.2266 - acc: 0.9125\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 179us/step - loss: 0.2197 - acc: 0.9169\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 179us/step - loss: 0.2142 - acc: 0.9188\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 183us/step - loss: 0.2066 - acc: 0.9240\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 185us/step - loss: 0.1994 - acc: 0.9270\n",
            "Epoch 1/30\n",
            "12272/12272 [==============================] - 6s 480us/step - loss: 0.5043 - acc: 0.7519\n",
            "Epoch 2/30\n",
            "12272/12272 [==============================] - 2s 181us/step - loss: 0.4035 - acc: 0.8241\n",
            "Epoch 3/30\n",
            "12272/12272 [==============================] - 2s 182us/step - loss: 0.3731 - acc: 0.8410\n",
            "Epoch 4/30\n",
            "12272/12272 [==============================] - 2s 180us/step - loss: 0.3555 - acc: 0.8500\n",
            "Epoch 5/30\n",
            "12272/12272 [==============================] - 2s 184us/step - loss: 0.3504 - acc: 0.8494\n",
            "Epoch 6/30\n",
            "12272/12272 [==============================] - 2s 180us/step - loss: 0.3424 - acc: 0.8544\n",
            "Epoch 7/30\n",
            "12272/12272 [==============================] - 2s 181us/step - loss: 0.3361 - acc: 0.8548\n",
            "Epoch 8/30\n",
            "12272/12272 [==============================] - 2s 178us/step - loss: 0.3293 - acc: 0.8598\n",
            "Epoch 9/30\n",
            "12272/12272 [==============================] - 2s 179us/step - loss: 0.3275 - acc: 0.8576\n",
            "Epoch 10/30\n",
            "12272/12272 [==============================] - 2s 180us/step - loss: 0.3222 - acc: 0.8617\n",
            "Epoch 11/30\n",
            "12272/12272 [==============================] - 2s 179us/step - loss: 0.3157 - acc: 0.8650\n",
            "Epoch 12/30\n",
            "12272/12272 [==============================] - 2s 188us/step - loss: 0.3131 - acc: 0.8684\n",
            "Epoch 13/30\n",
            "12272/12272 [==============================] - 2s 182us/step - loss: 0.3074 - acc: 0.8709\n",
            "Epoch 14/30\n",
            "12272/12272 [==============================] - 2s 183us/step - loss: 0.3006 - acc: 0.8729\n",
            "Epoch 15/30\n",
            "12272/12272 [==============================] - 2s 180us/step - loss: 0.2975 - acc: 0.8748\n",
            "Epoch 16/30\n",
            "12272/12272 [==============================] - 2s 178us/step - loss: 0.2905 - acc: 0.8802\n",
            "Epoch 17/30\n",
            "12272/12272 [==============================] - 2s 179us/step - loss: 0.2860 - acc: 0.8818\n",
            "Epoch 18/30\n",
            "12272/12272 [==============================] - 2s 179us/step - loss: 0.2787 - acc: 0.8843\n",
            "Epoch 19/30\n",
            "12272/12272 [==============================] - 2s 182us/step - loss: 0.2736 - acc: 0.8889\n",
            "Epoch 20/30\n",
            "12272/12272 [==============================] - 2s 179us/step - loss: 0.2662 - acc: 0.8935\n",
            "Epoch 21/30\n",
            "12272/12272 [==============================] - 2s 183us/step - loss: 0.2595 - acc: 0.8955\n",
            "Epoch 22/30\n",
            "12272/12272 [==============================] - 2s 181us/step - loss: 0.2528 - acc: 0.8990\n",
            "Epoch 23/30\n",
            "12272/12272 [==============================] - 2s 180us/step - loss: 0.2458 - acc: 0.9012\n",
            "Epoch 24/30\n",
            "12272/12272 [==============================] - 2s 185us/step - loss: 0.2396 - acc: 0.9056\n",
            "Epoch 25/30\n",
            "12272/12272 [==============================] - 2s 179us/step - loss: 0.2327 - acc: 0.9095\n",
            "Epoch 26/30\n",
            "12272/12272 [==============================] - 2s 180us/step - loss: 0.2265 - acc: 0.9108\n",
            "Epoch 27/30\n",
            "12272/12272 [==============================] - 2s 181us/step - loss: 0.2186 - acc: 0.9165\n",
            "Epoch 28/30\n",
            "12272/12272 [==============================] - 2s 178us/step - loss: 0.2123 - acc: 0.9214\n",
            "Epoch 29/30\n",
            "12272/12272 [==============================] - 2s 180us/step - loss: 0.2061 - acc: 0.9229\n",
            "Epoch 30/30\n",
            "12272/12272 [==============================] - 2s 182us/step - loss: 0.1991 - acc: 0.9264\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 5s 396us/step - loss: 0.6234 - acc: 0.6955\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 99us/step - loss: 0.6136 - acc: 0.6955\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 101us/step - loss: 0.6116 - acc: 0.6955\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 98us/step - loss: 0.6098 - acc: 0.6955\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 98us/step - loss: 0.6081 - acc: 0.6955\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 99us/step - loss: 0.6065 - acc: 0.6955\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 100us/step - loss: 0.6050 - acc: 0.6955\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 98us/step - loss: 0.6036 - acc: 0.6955\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 101us/step - loss: 0.6023 - acc: 0.6955\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 98us/step - loss: 0.6010 - acc: 0.6955\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 5s 393us/step - loss: 0.6452 - acc: 0.6317\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 99us/step - loss: 0.6063 - acc: 0.6955\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 99us/step - loss: 0.6042 - acc: 0.6955\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 0.6026 - acc: 0.6955\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 99us/step - loss: 0.6010 - acc: 0.6955\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 0.5995 - acc: 0.6955\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 0.5980 - acc: 0.6955\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 0.5968 - acc: 0.6955\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 0.5955 - acc: 0.6955\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 0.5943 - acc: 0.6955\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 5s 396us/step - loss: 0.6385 - acc: 0.6668\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 98us/step - loss: 0.6138 - acc: 0.6955\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 0.6117 - acc: 0.6955\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 0.6100 - acc: 0.6955\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 90us/step - loss: 0.6084 - acc: 0.6955\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 0.6068 - acc: 0.6955\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 91us/step - loss: 0.6054 - acc: 0.6955\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 98us/step - loss: 0.6040 - acc: 0.6955\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 88us/step - loss: 0.6027 - acc: 0.6955\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 91us/step - loss: 0.6014 - acc: 0.6955\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 5s 401us/step - loss: 0.6806 - acc: 0.5811\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 0.6117 - acc: 0.6955\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 100us/step - loss: 0.6095 - acc: 0.6955\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 100us/step - loss: 0.6081 - acc: 0.6955\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 0.6068 - acc: 0.6955\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 103us/step - loss: 0.6056 - acc: 0.6955\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 99us/step - loss: 0.6043 - acc: 0.6955\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 0.6032 - acc: 0.6955\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 102us/step - loss: 0.6021 - acc: 0.6955\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 0.6011 - acc: 0.6955\n",
            "Epoch 1/10\n",
            "12272/12272 [==============================] - 5s 408us/step - loss: 0.7059 - acc: 0.5551\n",
            "Epoch 2/10\n",
            "12272/12272 [==============================] - 1s 106us/step - loss: 0.6129 - acc: 0.6956\n",
            "Epoch 3/10\n",
            "12272/12272 [==============================] - 1s 98us/step - loss: 0.6100 - acc: 0.6956\n",
            "Epoch 4/10\n",
            "12272/12272 [==============================] - 1s 96us/step - loss: 0.6082 - acc: 0.6956\n",
            "Epoch 5/10\n",
            "12272/12272 [==============================] - 1s 98us/step - loss: 0.6066 - acc: 0.6956\n",
            "Epoch 6/10\n",
            "12272/12272 [==============================] - 1s 101us/step - loss: 0.6050 - acc: 0.6956\n",
            "Epoch 7/10\n",
            "12272/12272 [==============================] - 1s 98us/step - loss: 0.6035 - acc: 0.6956\n",
            "Epoch 8/10\n",
            "12272/12272 [==============================] - 1s 101us/step - loss: 0.6021 - acc: 0.6956\n",
            "Epoch 9/10\n",
            "12272/12272 [==============================] - 1s 101us/step - loss: 0.6008 - acc: 0.6956\n",
            "Epoch 10/10\n",
            "12272/12272 [==============================] - 1s 100us/step - loss: 0.5995 - acc: 0.6956\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 5s 447us/step - loss: 0.5384 - acc: 0.7273\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 130us/step - loss: 0.4379 - acc: 0.8076\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 129us/step - loss: 0.3894 - acc: 0.8360\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 0.3703 - acc: 0.8458\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 129us/step - loss: 0.3562 - acc: 0.8477\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 131us/step - loss: 0.3460 - acc: 0.8540\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 130us/step - loss: 0.3430 - acc: 0.8531\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 132us/step - loss: 0.3357 - acc: 0.8567\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 130us/step - loss: 0.3325 - acc: 0.8561\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 0.3316 - acc: 0.8571\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 6s 453us/step - loss: 0.5158 - acc: 0.7409\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 134us/step - loss: 0.4226 - acc: 0.8159\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.3848 - acc: 0.8395\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 133us/step - loss: 0.3590 - acc: 0.8519\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 0.3509 - acc: 0.8527\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 0.3403 - acc: 0.8579\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 0.3351 - acc: 0.8588\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 130us/step - loss: 0.3281 - acc: 0.8611\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.3297 - acc: 0.8623\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 139us/step - loss: 0.3236 - acc: 0.8622\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 6s 478us/step - loss: 0.5247 - acc: 0.7324\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.4381 - acc: 0.8069\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 0.3896 - acc: 0.8356\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 131us/step - loss: 0.3683 - acc: 0.8470\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 129us/step - loss: 0.3537 - acc: 0.8527\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.3577 - acc: 0.8480\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 132us/step - loss: 0.3432 - acc: 0.8552\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 131us/step - loss: 0.3387 - acc: 0.8552\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 133us/step - loss: 0.3382 - acc: 0.8567\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 133us/step - loss: 0.3331 - acc: 0.8562\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 6s 460us/step - loss: 0.5249 - acc: 0.7369\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 2s 131us/step - loss: 0.4360 - acc: 0.8060\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 2s 134us/step - loss: 0.3873 - acc: 0.8387\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 2s 132us/step - loss: 0.3662 - acc: 0.8468\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 2s 132us/step - loss: 0.3596 - acc: 0.8487\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 133us/step - loss: 0.3423 - acc: 0.8564\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 2s 132us/step - loss: 0.3363 - acc: 0.8582\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 132us/step - loss: 0.3350 - acc: 0.8584\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 132us/step - loss: 0.3343 - acc: 0.8569\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 2s 132us/step - loss: 0.3279 - acc: 0.8598\n",
            "Epoch 1/10\n",
            "12272/12272 [==============================] - 6s 467us/step - loss: 0.5340 - acc: 0.7319\n",
            "Epoch 2/10\n",
            "12272/12272 [==============================] - 2s 134us/step - loss: 0.4368 - acc: 0.8044\n",
            "Epoch 3/10\n",
            "12272/12272 [==============================] - 2s 130us/step - loss: 0.3897 - acc: 0.8343\n",
            "Epoch 4/10\n",
            "12272/12272 [==============================] - 2s 134us/step - loss: 0.3642 - acc: 0.8477\n",
            "Epoch 5/10\n",
            "12272/12272 [==============================] - 2s 131us/step - loss: 0.3495 - acc: 0.8501\n",
            "Epoch 6/10\n",
            "12272/12272 [==============================] - 2s 134us/step - loss: 0.3424 - acc: 0.8553\n",
            "Epoch 7/10\n",
            "12272/12272 [==============================] - 2s 133us/step - loss: 0.3378 - acc: 0.8545\n",
            "Epoch 8/10\n",
            "12272/12272 [==============================] - 2s 139us/step - loss: 0.3325 - acc: 0.8581\n",
            "Epoch 9/10\n",
            "12272/12272 [==============================] - 2s 133us/step - loss: 0.3272 - acc: 0.8596\n",
            "Epoch 10/10\n",
            "12272/12272 [==============================] - 2s 134us/step - loss: 0.3266 - acc: 0.8627\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 6s 456us/step - loss: 0.5310 - acc: 0.7310\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 0.4414 - acc: 0.7994\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 119us/step - loss: 0.4041 - acc: 0.8257\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 0.3739 - acc: 0.8409\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 0.3632 - acc: 0.8461\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 2s 122us/step - loss: 0.3536 - acc: 0.8487\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 0.3513 - acc: 0.8487\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 0.3451 - acc: 0.8510\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 0.3367 - acc: 0.8549\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 0.3360 - acc: 0.8518\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 6s 461us/step - loss: 0.5381 - acc: 0.7351\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 119us/step - loss: 0.4468 - acc: 0.7981\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 0.3972 - acc: 0.8321\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 0.3714 - acc: 0.8423\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 0.3610 - acc: 0.8465\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 118us/step - loss: 0.3538 - acc: 0.8513\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 117us/step - loss: 0.3492 - acc: 0.8537\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 120us/step - loss: 0.3433 - acc: 0.8545\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 117us/step - loss: 0.3358 - acc: 0.8581\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 119us/step - loss: 0.3324 - acc: 0.8594\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 6s 456us/step - loss: 0.5409 - acc: 0.7311\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 117us/step - loss: 0.4523 - acc: 0.7969\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 117us/step - loss: 0.4091 - acc: 0.8219\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 116us/step - loss: 0.3820 - acc: 0.8374\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 116us/step - loss: 0.3689 - acc: 0.8414\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 116us/step - loss: 0.3613 - acc: 0.8458\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 117us/step - loss: 0.3547 - acc: 0.8460\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 117us/step - loss: 0.3463 - acc: 0.8504\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 116us/step - loss: 0.3460 - acc: 0.8525\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 120us/step - loss: 0.3393 - acc: 0.8515\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 6s 456us/step - loss: 0.5350 - acc: 0.7280\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 115us/step - loss: 0.4486 - acc: 0.7968\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 120us/step - loss: 0.4031 - acc: 0.8260\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 119us/step - loss: 0.3791 - acc: 0.8400\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 0.3654 - acc: 0.8460\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 119us/step - loss: 0.3584 - acc: 0.8513\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 120us/step - loss: 0.3500 - acc: 0.8487\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 0.3431 - acc: 0.8569\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 116us/step - loss: 0.3378 - acc: 0.8545\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 119us/step - loss: 0.3352 - acc: 0.8582\n",
            "Epoch 1/10\n",
            "12272/12272 [==============================] - 6s 471us/step - loss: 0.5320 - acc: 0.7344\n",
            "Epoch 2/10\n",
            "12272/12272 [==============================] - 1s 120us/step - loss: 0.4442 - acc: 0.7954\n",
            "Epoch 3/10\n",
            "12272/12272 [==============================] - 1s 116us/step - loss: 0.3991 - acc: 0.8283\n",
            "Epoch 4/10\n",
            "12272/12272 [==============================] - 1s 121us/step - loss: 0.3773 - acc: 0.8417\n",
            "Epoch 5/10\n",
            "12272/12272 [==============================] - 1s 116us/step - loss: 0.3616 - acc: 0.8476\n",
            "Epoch 6/10\n",
            "12272/12272 [==============================] - 1s 114us/step - loss: 0.3491 - acc: 0.8544\n",
            "Epoch 7/10\n",
            "12272/12272 [==============================] - 1s 118us/step - loss: 0.3501 - acc: 0.8501\n",
            "Epoch 8/10\n",
            "12272/12272 [==============================] - 1s 117us/step - loss: 0.3407 - acc: 0.8547\n",
            "Epoch 9/10\n",
            "12272/12272 [==============================] - 1s 122us/step - loss: 0.3351 - acc: 0.8575\n",
            "Epoch 10/10\n",
            "12272/12272 [==============================] - 1s 116us/step - loss: 0.3324 - acc: 0.8562\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 6s 449us/step - loss: 0.6176 - acc: 0.6955\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 1s 103us/step - loss: 0.6100 - acc: 0.6955\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 1s 99us/step - loss: 0.6083 - acc: 0.6955\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 1s 102us/step - loss: 0.6067 - acc: 0.6955\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 1s 101us/step - loss: 0.6052 - acc: 0.6955\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 0.6039 - acc: 0.6955\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 1s 103us/step - loss: 0.6026 - acc: 0.6955\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 1s 104us/step - loss: 0.6013 - acc: 0.6955\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 1s 99us/step - loss: 0.6001 - acc: 0.6955\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 1s 102us/step - loss: 0.5990 - acc: 0.6955\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 1s 103us/step - loss: 0.5979 - acc: 0.6955\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 1s 100us/step - loss: 0.5968 - acc: 0.6955\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 1s 104us/step - loss: 0.5958 - acc: 0.6955\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 1s 100us/step - loss: 0.5948 - acc: 0.6956\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 1s 98us/step - loss: 0.5938 - acc: 0.6956\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 1s 100us/step - loss: 0.5929 - acc: 0.6956\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 0.5921 - acc: 0.6956\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 0.5912 - acc: 0.6956\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 1s 105us/step - loss: 0.5904 - acc: 0.6956\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 1s 98us/step - loss: 0.5896 - acc: 0.6952\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 1s 103us/step - loss: 0.5888 - acc: 0.6946\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 1s 100us/step - loss: 0.5880 - acc: 0.6946\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 1s 104us/step - loss: 0.5872 - acc: 0.6951\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 1s 98us/step - loss: 0.5865 - acc: 0.6951\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 1s 102us/step - loss: 0.5858 - acc: 0.6948\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 1s 99us/step - loss: 0.5851 - acc: 0.6941\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 1s 101us/step - loss: 0.5844 - acc: 0.6946\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 1s 98us/step - loss: 0.5837 - acc: 0.6929\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 1s 100us/step - loss: 0.5830 - acc: 0.6935\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 1s 98us/step - loss: 0.5824 - acc: 0.6933\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 6s 455us/step - loss: 0.6349 - acc: 0.6630\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 1s 103us/step - loss: 0.6072 - acc: 0.6955\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 1s 101us/step - loss: 0.6054 - acc: 0.6955\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 1s 100us/step - loss: 0.6038 - acc: 0.6955\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 0.6024 - acc: 0.6955\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 0.6011 - acc: 0.6955\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 1s 100us/step - loss: 0.5998 - acc: 0.6955\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 1s 98us/step - loss: 0.5986 - acc: 0.6955\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 1s 100us/step - loss: 0.5974 - acc: 0.6955\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 1s 98us/step - loss: 0.5963 - acc: 0.6953\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 1s 99us/step - loss: 0.5952 - acc: 0.6953\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 1s 99us/step - loss: 0.5942 - acc: 0.6949\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 1s 100us/step - loss: 0.5933 - acc: 0.6949\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 1s 101us/step - loss: 0.5923 - acc: 0.6948\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 1s 108us/step - loss: 0.5915 - acc: 0.6942\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 1s 99us/step - loss: 0.5906 - acc: 0.6939\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 1s 101us/step - loss: 0.5898 - acc: 0.6938\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 1s 99us/step - loss: 0.5890 - acc: 0.6937\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 1s 102us/step - loss: 0.5882 - acc: 0.6932\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 1s 101us/step - loss: 0.5875 - acc: 0.6928\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 1s 101us/step - loss: 0.5867 - acc: 0.6926\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 1s 105us/step - loss: 0.5860 - acc: 0.6931\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 1s 100us/step - loss: 0.5853 - acc: 0.6930\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 1s 104us/step - loss: 0.5846 - acc: 0.6930\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 0.5839 - acc: 0.6930\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 1s 103us/step - loss: 0.5833 - acc: 0.6932\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 1s 104us/step - loss: 0.5826 - acc: 0.6929\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 1s 99us/step - loss: 0.5820 - acc: 0.6929\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 1s 104us/step - loss: 0.5814 - acc: 0.6932\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 1s 100us/step - loss: 0.5808 - acc: 0.6932\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 6s 449us/step - loss: 0.7010 - acc: 0.5561\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 1s 98us/step - loss: 0.6082 - acc: 0.6955\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 1s 99us/step - loss: 0.6057 - acc: 0.6955\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 1s 99us/step - loss: 0.6044 - acc: 0.6955\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 1s 99us/step - loss: 0.6032 - acc: 0.6955\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 1s 99us/step - loss: 0.6020 - acc: 0.6955\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 1s 106us/step - loss: 0.6009 - acc: 0.6955\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 1s 102us/step - loss: 0.5999 - acc: 0.6955\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 1s 101us/step - loss: 0.5988 - acc: 0.6955\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 1s 103us/step - loss: 0.5978 - acc: 0.6955\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 1s 106us/step - loss: 0.5969 - acc: 0.6955\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 1s 104us/step - loss: 0.5960 - acc: 0.6955\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 1s 105us/step - loss: 0.5951 - acc: 0.6955\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 1s 108us/step - loss: 0.5942 - acc: 0.6955\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 1s 106us/step - loss: 0.5934 - acc: 0.6955\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 1s 107us/step - loss: 0.5926 - acc: 0.6957\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 1s 107us/step - loss: 0.5918 - acc: 0.6955\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 1s 104us/step - loss: 0.5910 - acc: 0.6954\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 1s 102us/step - loss: 0.5903 - acc: 0.6951\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 1s 102us/step - loss: 0.5896 - acc: 0.6953\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 1s 102us/step - loss: 0.5889 - acc: 0.6952\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 1s 104us/step - loss: 0.5881 - acc: 0.6949\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 1s 105us/step - loss: 0.5875 - acc: 0.6946\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 1s 103us/step - loss: 0.5868 - acc: 0.6951\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 1s 103us/step - loss: 0.5862 - acc: 0.6948\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 1s 110us/step - loss: 0.5855 - acc: 0.6955\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 1s 104us/step - loss: 0.5849 - acc: 0.6942\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 1s 104us/step - loss: 0.5843 - acc: 0.6943\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 1s 109us/step - loss: 0.5836 - acc: 0.6949\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 1s 109us/step - loss: 0.5831 - acc: 0.6947\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 6s 479us/step - loss: 0.6920 - acc: 0.5719\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 1s 100us/step - loss: 0.6078 - acc: 0.6955\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 1s 103us/step - loss: 0.6061 - acc: 0.6955\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 1s 99us/step - loss: 0.6049 - acc: 0.6955\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 1s 103us/step - loss: 0.6038 - acc: 0.6955\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 1s 100us/step - loss: 0.6028 - acc: 0.6955\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 1s 108us/step - loss: 0.6018 - acc: 0.6955\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 1s 106us/step - loss: 0.6008 - acc: 0.6955\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 1s 106us/step - loss: 0.5998 - acc: 0.6955\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 1s 108us/step - loss: 0.5989 - acc: 0.6955\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 1s 108us/step - loss: 0.5981 - acc: 0.6955\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 1s 106us/step - loss: 0.5972 - acc: 0.6955\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 1s 106us/step - loss: 0.5963 - acc: 0.6954\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 1s 104us/step - loss: 0.5956 - acc: 0.6953\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 1s 105us/step - loss: 0.5948 - acc: 0.6954\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 1s 106us/step - loss: 0.5941 - acc: 0.6952\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 1s 106us/step - loss: 0.5933 - acc: 0.6952\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 1s 107us/step - loss: 0.5925 - acc: 0.6952\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 1s 107us/step - loss: 0.5918 - acc: 0.6952\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 1s 107us/step - loss: 0.5911 - acc: 0.6956\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 1s 108us/step - loss: 0.5904 - acc: 0.6953\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 1s 107us/step - loss: 0.5898 - acc: 0.6954\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 1s 104us/step - loss: 0.5892 - acc: 0.6955\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 1s 106us/step - loss: 0.5885 - acc: 0.6957\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 1s 105us/step - loss: 0.5879 - acc: 0.6956\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 1s 105us/step - loss: 0.5872 - acc: 0.6951\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 1s 106us/step - loss: 0.5866 - acc: 0.6947\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 1s 107us/step - loss: 0.5860 - acc: 0.6941\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 1s 105us/step - loss: 0.5853 - acc: 0.6937\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 1s 107us/step - loss: 0.5848 - acc: 0.6937\n",
            "Epoch 1/30\n",
            "12272/12272 [==============================] - 6s 474us/step - loss: 0.6172 - acc: 0.6956\n",
            "Epoch 2/30\n",
            "12272/12272 [==============================] - 1s 109us/step - loss: 0.6139 - acc: 0.6956\n",
            "Epoch 3/30\n",
            "12272/12272 [==============================] - 1s 108us/step - loss: 0.6118 - acc: 0.6956\n",
            "Epoch 4/30\n",
            "12272/12272 [==============================] - 1s 108us/step - loss: 0.6100 - acc: 0.6956\n",
            "Epoch 5/30\n",
            "12272/12272 [==============================] - 1s 102us/step - loss: 0.6082 - acc: 0.6956\n",
            "Epoch 6/30\n",
            "12272/12272 [==============================] - 1s 103us/step - loss: 0.6066 - acc: 0.6956\n",
            "Epoch 7/30\n",
            "12272/12272 [==============================] - 1s 104us/step - loss: 0.6050 - acc: 0.6956\n",
            "Epoch 8/30\n",
            "12272/12272 [==============================] - 1s 106us/step - loss: 0.6035 - acc: 0.6956\n",
            "Epoch 9/30\n",
            "12272/12272 [==============================] - 1s 105us/step - loss: 0.6021 - acc: 0.6956\n",
            "Epoch 10/30\n",
            "12272/12272 [==============================] - 1s 107us/step - loss: 0.6008 - acc: 0.6956\n",
            "Epoch 11/30\n",
            "12272/12272 [==============================] - 1s 105us/step - loss: 0.5995 - acc: 0.6956\n",
            "Epoch 12/30\n",
            "12272/12272 [==============================] - 1s 107us/step - loss: 0.5983 - acc: 0.6956\n",
            "Epoch 13/30\n",
            "12272/12272 [==============================] - 1s 106us/step - loss: 0.5972 - acc: 0.6956\n",
            "Epoch 14/30\n",
            "12272/12272 [==============================] - 1s 107us/step - loss: 0.5961 - acc: 0.6956\n",
            "Epoch 15/30\n",
            "12272/12272 [==============================] - 1s 107us/step - loss: 0.5951 - acc: 0.6956\n",
            "Epoch 16/30\n",
            "12272/12272 [==============================] - 1s 105us/step - loss: 0.5941 - acc: 0.6956\n",
            "Epoch 17/30\n",
            "12272/12272 [==============================] - 1s 106us/step - loss: 0.5931 - acc: 0.6956\n",
            "Epoch 18/30\n",
            "12272/12272 [==============================] - 1s 107us/step - loss: 0.5921 - acc: 0.6955\n",
            "Epoch 19/30\n",
            "12272/12272 [==============================] - 1s 106us/step - loss: 0.5913 - acc: 0.6956\n",
            "Epoch 20/30\n",
            "12272/12272 [==============================] - 1s 107us/step - loss: 0.5904 - acc: 0.6956\n",
            "Epoch 21/30\n",
            "12272/12272 [==============================] - 1s 105us/step - loss: 0.5896 - acc: 0.6955\n",
            "Epoch 22/30\n",
            "12272/12272 [==============================] - 1s 105us/step - loss: 0.5888 - acc: 0.6953\n",
            "Epoch 23/30\n",
            "12272/12272 [==============================] - 1s 107us/step - loss: 0.5880 - acc: 0.6954\n",
            "Epoch 24/30\n",
            "12272/12272 [==============================] - 1s 107us/step - loss: 0.5872 - acc: 0.6953\n",
            "Epoch 25/30\n",
            "12272/12272 [==============================] - 1s 106us/step - loss: 0.5865 - acc: 0.6954\n",
            "Epoch 26/30\n",
            "12272/12272 [==============================] - 1s 105us/step - loss: 0.5857 - acc: 0.6953\n",
            "Epoch 27/30\n",
            "12272/12272 [==============================] - 1s 107us/step - loss: 0.5850 - acc: 0.6953\n",
            "Epoch 28/30\n",
            "12272/12272 [==============================] - 1s 103us/step - loss: 0.5843 - acc: 0.6951\n",
            "Epoch 29/30\n",
            "12272/12272 [==============================] - 1s 101us/step - loss: 0.5836 - acc: 0.6950\n",
            "Epoch 30/30\n",
            "12272/12272 [==============================] - 1s 106us/step - loss: 0.5829 - acc: 0.6954\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 6s 503us/step - loss: 0.5351 - acc: 0.7312\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 132us/step - loss: 0.4286 - acc: 0.8145\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 130us/step - loss: 0.3925 - acc: 0.8355\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 132us/step - loss: 0.3650 - acc: 0.8465\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 132us/step - loss: 0.3520 - acc: 0.8503\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 131us/step - loss: 0.3439 - acc: 0.8518\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 133us/step - loss: 0.3411 - acc: 0.8534\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 131us/step - loss: 0.3389 - acc: 0.8545\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.3303 - acc: 0.8574\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 130us/step - loss: 0.3318 - acc: 0.8582\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 134us/step - loss: 0.3255 - acc: 0.8615\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 131us/step - loss: 0.3218 - acc: 0.8615\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 129us/step - loss: 0.3241 - acc: 0.8600\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 129us/step - loss: 0.3176 - acc: 0.8627\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 133us/step - loss: 0.3172 - acc: 0.8620\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 133us/step - loss: 0.3130 - acc: 0.8648\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.3092 - acc: 0.8663\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 133us/step - loss: 0.3061 - acc: 0.8677\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 133us/step - loss: 0.3034 - acc: 0.8721\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.3022 - acc: 0.8715\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 137us/step - loss: 0.2972 - acc: 0.8760\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 139us/step - loss: 0.2996 - acc: 0.8725\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 138us/step - loss: 0.2895 - acc: 0.8792\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.2835 - acc: 0.8838\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 138us/step - loss: 0.2821 - acc: 0.8826\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.2769 - acc: 0.8861\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 137us/step - loss: 0.2733 - acc: 0.8887\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 137us/step - loss: 0.2665 - acc: 0.8901\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 137us/step - loss: 0.2633 - acc: 0.8940\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.2585 - acc: 0.8969\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 6s 514us/step - loss: 0.5288 - acc: 0.7328\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 137us/step - loss: 0.4339 - acc: 0.8100\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 139us/step - loss: 0.3915 - acc: 0.8338\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.3593 - acc: 0.8505\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.3477 - acc: 0.8554\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 137us/step - loss: 0.3505 - acc: 0.8544\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 138us/step - loss: 0.3377 - acc: 0.8572\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.3339 - acc: 0.8584\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.3292 - acc: 0.8580\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.3271 - acc: 0.8642\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.3213 - acc: 0.8633\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 134us/step - loss: 0.3197 - acc: 0.8654\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.3196 - acc: 0.8639\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.3149 - acc: 0.8669\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.3130 - acc: 0.8688\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.3077 - acc: 0.8695\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.3047 - acc: 0.8690\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.3014 - acc: 0.8739\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.2985 - acc: 0.8755\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.2929 - acc: 0.8785\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 140us/step - loss: 0.2891 - acc: 0.8809\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 137us/step - loss: 0.2896 - acc: 0.8818\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.2809 - acc: 0.8821\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.2775 - acc: 0.8850\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.2740 - acc: 0.8897\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.2692 - acc: 0.8895\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 134us/step - loss: 0.2628 - acc: 0.8927\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.2632 - acc: 0.8944\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.2533 - acc: 0.8988\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.2502 - acc: 0.9024\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 6s 517us/step - loss: 0.5309 - acc: 0.7275\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 134us/step - loss: 0.4376 - acc: 0.8066\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.3912 - acc: 0.8355\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.3668 - acc: 0.8468\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 134us/step - loss: 0.3598 - acc: 0.8475\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.3484 - acc: 0.8521\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.3460 - acc: 0.8551\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 137us/step - loss: 0.3394 - acc: 0.8561\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 134us/step - loss: 0.3371 - acc: 0.8577\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.3350 - acc: 0.8571\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.3293 - acc: 0.8589\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 137us/step - loss: 0.3283 - acc: 0.8572\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 140us/step - loss: 0.3265 - acc: 0.8598\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.3224 - acc: 0.8624\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.3177 - acc: 0.8652\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.3217 - acc: 0.8630\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.3124 - acc: 0.8672\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.3101 - acc: 0.8682\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.3133 - acc: 0.8672\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.3030 - acc: 0.8730\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.2973 - acc: 0.8756\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.2935 - acc: 0.8776\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.2943 - acc: 0.8780\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 137us/step - loss: 0.2906 - acc: 0.8796\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.2871 - acc: 0.8838\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.2788 - acc: 0.8854\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.2749 - acc: 0.8875\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.2721 - acc: 0.8897\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.2643 - acc: 0.8930\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.2640 - acc: 0.8963\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 6s 521us/step - loss: 0.5233 - acc: 0.7334\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.4343 - acc: 0.8078\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 138us/step - loss: 0.3895 - acc: 0.8366\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 134us/step - loss: 0.3635 - acc: 0.8456\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 134us/step - loss: 0.3544 - acc: 0.8505\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.3472 - acc: 0.8512\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 139us/step - loss: 0.3416 - acc: 0.8564\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 141us/step - loss: 0.3337 - acc: 0.8582\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 137us/step - loss: 0.3318 - acc: 0.8579\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 138us/step - loss: 0.3267 - acc: 0.8619\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 135us/step - loss: 0.3292 - acc: 0.8591\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 138us/step - loss: 0.3222 - acc: 0.8642\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 132us/step - loss: 0.3213 - acc: 0.8650\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 133us/step - loss: 0.3218 - acc: 0.8640\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 132us/step - loss: 0.3145 - acc: 0.8671\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 129us/step - loss: 0.3140 - acc: 0.8657\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 132us/step - loss: 0.3081 - acc: 0.8703\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 134us/step - loss: 0.3066 - acc: 0.8716\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 134us/step - loss: 0.3050 - acc: 0.8738\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 131us/step - loss: 0.2980 - acc: 0.8736\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 131us/step - loss: 0.2948 - acc: 0.8740\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 132us/step - loss: 0.2923 - acc: 0.8787\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 140us/step - loss: 0.2876 - acc: 0.8815\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 139us/step - loss: 0.2830 - acc: 0.8830\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 141us/step - loss: 0.2821 - acc: 0.8823\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 142us/step - loss: 0.2744 - acc: 0.8876\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 142us/step - loss: 0.2701 - acc: 0.8910\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 139us/step - loss: 0.2659 - acc: 0.8928\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 136us/step - loss: 0.2623 - acc: 0.8941\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 133us/step - loss: 0.2549 - acc: 0.8986\n",
            "Epoch 1/30\n",
            "12272/12272 [==============================] - 6s 522us/step - loss: 0.5171 - acc: 0.7431\n",
            "Epoch 2/30\n",
            "12272/12272 [==============================] - 2s 132us/step - loss: 0.4285 - acc: 0.8096\n",
            "Epoch 3/30\n",
            "12272/12272 [==============================] - 2s 129us/step - loss: 0.3803 - acc: 0.8431\n",
            "Epoch 4/30\n",
            "12272/12272 [==============================] - 2s 133us/step - loss: 0.3620 - acc: 0.8500\n",
            "Epoch 5/30\n",
            "12272/12272 [==============================] - 2s 133us/step - loss: 0.3506 - acc: 0.8545\n",
            "Epoch 6/30\n",
            "12272/12272 [==============================] - 2s 137us/step - loss: 0.3441 - acc: 0.8516\n",
            "Epoch 7/30\n",
            "12272/12272 [==============================] - 2s 134us/step - loss: 0.3395 - acc: 0.8545\n",
            "Epoch 8/30\n",
            "12272/12272 [==============================] - 2s 128us/step - loss: 0.3326 - acc: 0.8599\n",
            "Epoch 9/30\n",
            "12272/12272 [==============================] - 2s 133us/step - loss: 0.3320 - acc: 0.8601\n",
            "Epoch 10/30\n",
            "12272/12272 [==============================] - 2s 130us/step - loss: 0.3266 - acc: 0.8628\n",
            "Epoch 11/30\n",
            "12272/12272 [==============================] - 2s 133us/step - loss: 0.3302 - acc: 0.8571\n",
            "Epoch 12/30\n",
            "12272/12272 [==============================] - 2s 134us/step - loss: 0.3172 - acc: 0.8677\n",
            "Epoch 13/30\n",
            "12272/12272 [==============================] - 2s 130us/step - loss: 0.3153 - acc: 0.8665\n",
            "Epoch 14/30\n",
            "12272/12272 [==============================] - 2s 128us/step - loss: 0.3166 - acc: 0.8666\n",
            "Epoch 15/30\n",
            "12272/12272 [==============================] - 2s 133us/step - loss: 0.3130 - acc: 0.8668\n",
            "Epoch 16/30\n",
            "12272/12272 [==============================] - 2s 140us/step - loss: 0.3089 - acc: 0.8679\n",
            "Epoch 17/30\n",
            "12272/12272 [==============================] - 2s 135us/step - loss: 0.3040 - acc: 0.8712\n",
            "Epoch 18/30\n",
            "12272/12272 [==============================] - 2s 137us/step - loss: 0.3014 - acc: 0.8745\n",
            "Epoch 19/30\n",
            "12272/12272 [==============================] - 2s 135us/step - loss: 0.2990 - acc: 0.8733\n",
            "Epoch 20/30\n",
            "12272/12272 [==============================] - 2s 135us/step - loss: 0.2919 - acc: 0.8770\n",
            "Epoch 21/30\n",
            "12272/12272 [==============================] - 2s 137us/step - loss: 0.2899 - acc: 0.8794\n",
            "Epoch 22/30\n",
            "12272/12272 [==============================] - 2s 135us/step - loss: 0.2877 - acc: 0.8801\n",
            "Epoch 23/30\n",
            "12272/12272 [==============================] - 2s 137us/step - loss: 0.2812 - acc: 0.8823\n",
            "Epoch 24/30\n",
            "12272/12272 [==============================] - 2s 139us/step - loss: 0.2790 - acc: 0.8858\n",
            "Epoch 25/30\n",
            "12272/12272 [==============================] - 2s 136us/step - loss: 0.2753 - acc: 0.8867\n",
            "Epoch 26/30\n",
            "12272/12272 [==============================] - 2s 135us/step - loss: 0.2714 - acc: 0.8871\n",
            "Epoch 27/30\n",
            "12272/12272 [==============================] - 2s 138us/step - loss: 0.2633 - acc: 0.8935\n",
            "Epoch 28/30\n",
            "12272/12272 [==============================] - 2s 135us/step - loss: 0.2597 - acc: 0.8947\n",
            "Epoch 29/30\n",
            "12272/12272 [==============================] - 2s 136us/step - loss: 0.2580 - acc: 0.8959\n",
            "Epoch 30/30\n",
            "12272/12272 [==============================] - 2s 135us/step - loss: 0.2526 - acc: 0.9007\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 6s 519us/step - loss: 0.5329 - acc: 0.7313\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 0.4439 - acc: 0.7967\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 0.3992 - acc: 0.8285\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 0.3761 - acc: 0.8399\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 0.3604 - acc: 0.8473\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 0.3604 - acc: 0.8487\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 0.3476 - acc: 0.8541\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 0.3447 - acc: 0.8514\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 0.3427 - acc: 0.8527\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 0.3370 - acc: 0.8537\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 0.3321 - acc: 0.8547\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 0.3292 - acc: 0.8579\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 0.3263 - acc: 0.8600\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 0.3214 - acc: 0.8627\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 0.3190 - acc: 0.8609\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 0.3125 - acc: 0.8658\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 0.3100 - acc: 0.8677\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 0.3069 - acc: 0.8703\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 0.3028 - acc: 0.8704\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 0.2990 - acc: 0.8746\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 0.2961 - acc: 0.8747\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 0.2918 - acc: 0.8774\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 0.2876 - acc: 0.8786\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 0.2819 - acc: 0.8813\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 0.2786 - acc: 0.8831\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 0.2748 - acc: 0.8868\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 0.2691 - acc: 0.8897\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 0.2622 - acc: 0.8932\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 0.2566 - acc: 0.8976\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 0.2533 - acc: 0.8989\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 6s 506us/step - loss: 0.5332 - acc: 0.7321\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 1s 120us/step - loss: 0.4421 - acc: 0.8025\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 1s 118us/step - loss: 0.3993 - acc: 0.8287\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 1s 118us/step - loss: 0.3746 - acc: 0.8452\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 1s 118us/step - loss: 0.3613 - acc: 0.8491\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 1s 119us/step - loss: 0.3534 - acc: 0.8530\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 1s 120us/step - loss: 0.3447 - acc: 0.8539\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 1s 116us/step - loss: 0.3410 - acc: 0.8551\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 0.3370 - acc: 0.8571\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 1s 120us/step - loss: 0.3330 - acc: 0.8585\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 0.3268 - acc: 0.8615\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 1s 115us/step - loss: 0.3243 - acc: 0.8633\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 1s 119us/step - loss: 0.3190 - acc: 0.8645\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 1s 119us/step - loss: 0.3175 - acc: 0.8677\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 1s 117us/step - loss: 0.3126 - acc: 0.8662\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 1s 120us/step - loss: 0.3088 - acc: 0.8672\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 0.3047 - acc: 0.8703\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 0.3022 - acc: 0.8753\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 0.2987 - acc: 0.8723\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 0.2933 - acc: 0.8775\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 0.2882 - acc: 0.8787\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 1s 118us/step - loss: 0.2847 - acc: 0.8805\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 0.2812 - acc: 0.8839\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 0.2769 - acc: 0.8871\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 0.2731 - acc: 0.8888\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 1s 120us/step - loss: 0.2671 - acc: 0.8923\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 0.2616 - acc: 0.8945\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 0.2575 - acc: 0.8961\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 0.2520 - acc: 0.8965\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 0.2477 - acc: 0.9008\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 6s 524us/step - loss: 0.5338 - acc: 0.7322\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 0.4481 - acc: 0.7999\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 0.4070 - acc: 0.8244\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 0.3783 - acc: 0.8391\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 0.3666 - acc: 0.8437\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 0.3583 - acc: 0.8443\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 0.3528 - acc: 0.8505\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 0.3517 - acc: 0.8490\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 0.3470 - acc: 0.8505\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 0.3397 - acc: 0.8545\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 0.3351 - acc: 0.8565\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 0.3343 - acc: 0.8556\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 0.3280 - acc: 0.8612\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 0.3236 - acc: 0.8600\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 0.3221 - acc: 0.8614\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 0.3172 - acc: 0.8641\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 0.3147 - acc: 0.8651\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 2s 122us/step - loss: 0.3109 - acc: 0.8687\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 1s 120us/step - loss: 0.3071 - acc: 0.8691\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 2s 128us/step - loss: 0.3020 - acc: 0.8685\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 0.2971 - acc: 0.8746\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 0.2940 - acc: 0.8781\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 0.2893 - acc: 0.8785\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 0.2858 - acc: 0.8826\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 0.2797 - acc: 0.8854\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 0.2752 - acc: 0.8892\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 0.2699 - acc: 0.8901\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 2s 122us/step - loss: 0.2641 - acc: 0.8934\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 0.2578 - acc: 0.8951\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 2s 126us/step - loss: 0.2533 - acc: 0.8976\n",
            "Epoch 1/30\n",
            "12271/12271 [==============================] - 6s 523us/step - loss: 0.5432 - acc: 0.7288\n",
            "Epoch 2/30\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 0.4496 - acc: 0.7967\n",
            "Epoch 3/30\n",
            "12271/12271 [==============================] - 2s 123us/step - loss: 0.4025 - acc: 0.8285\n",
            "Epoch 4/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 0.3756 - acc: 0.8435\n",
            "Epoch 5/30\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 0.3654 - acc: 0.8465\n",
            "Epoch 6/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 0.3554 - acc: 0.8459\n",
            "Epoch 7/30\n",
            "12271/12271 [==============================] - 2s 122us/step - loss: 0.3492 - acc: 0.8538\n",
            "Epoch 8/30\n",
            "12271/12271 [==============================] - 2s 125us/step - loss: 0.3465 - acc: 0.8537\n",
            "Epoch 9/30\n",
            "12271/12271 [==============================] - 1s 119us/step - loss: 0.3385 - acc: 0.8532\n",
            "Epoch 10/30\n",
            "12271/12271 [==============================] - 1s 117us/step - loss: 0.3370 - acc: 0.8565\n",
            "Epoch 11/30\n",
            "12271/12271 [==============================] - 1s 120us/step - loss: 0.3307 - acc: 0.8602\n",
            "Epoch 12/30\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 0.3259 - acc: 0.8603\n",
            "Epoch 13/30\n",
            "12271/12271 [==============================] - 1s 120us/step - loss: 0.3249 - acc: 0.8612\n",
            "Epoch 14/30\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 0.3196 - acc: 0.8651\n",
            "Epoch 15/30\n",
            "12271/12271 [==============================] - 1s 119us/step - loss: 0.3178 - acc: 0.8624\n",
            "Epoch 16/30\n",
            "12271/12271 [==============================] - 2s 124us/step - loss: 0.3141 - acc: 0.8646\n",
            "Epoch 17/30\n",
            "12271/12271 [==============================] - 1s 117us/step - loss: 0.3076 - acc: 0.8699\n",
            "Epoch 18/30\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 0.3059 - acc: 0.8694\n",
            "Epoch 19/30\n",
            "12271/12271 [==============================] - 1s 119us/step - loss: 0.3041 - acc: 0.8712\n",
            "Epoch 20/30\n",
            "12271/12271 [==============================] - 1s 119us/step - loss: 0.2991 - acc: 0.8737\n",
            "Epoch 21/30\n",
            "12271/12271 [==============================] - 1s 120us/step - loss: 0.2923 - acc: 0.8770\n",
            "Epoch 22/30\n",
            "12271/12271 [==============================] - 1s 120us/step - loss: 0.2888 - acc: 0.8791\n",
            "Epoch 23/30\n",
            "12271/12271 [==============================] - 1s 118us/step - loss: 0.2842 - acc: 0.8796\n",
            "Epoch 24/30\n",
            "12271/12271 [==============================] - 1s 118us/step - loss: 0.2801 - acc: 0.8836\n",
            "Epoch 25/30\n",
            "12271/12271 [==============================] - 1s 118us/step - loss: 0.2743 - acc: 0.8871\n",
            "Epoch 26/30\n",
            "12271/12271 [==============================] - 1s 117us/step - loss: 0.2702 - acc: 0.8901\n",
            "Epoch 27/30\n",
            "12271/12271 [==============================] - 1s 117us/step - loss: 0.2654 - acc: 0.8916\n",
            "Epoch 28/30\n",
            "12271/12271 [==============================] - 1s 116us/step - loss: 0.2610 - acc: 0.8941\n",
            "Epoch 29/30\n",
            "12271/12271 [==============================] - 1s 119us/step - loss: 0.2529 - acc: 0.8995\n",
            "Epoch 30/30\n",
            "12271/12271 [==============================] - 1s 122us/step - loss: 0.2495 - acc: 0.9012\n",
            "Epoch 1/30\n",
            "12272/12272 [==============================] - 6s 523us/step - loss: 0.5361 - acc: 0.7342\n",
            "Epoch 2/30\n",
            "12272/12272 [==============================] - 1s 119us/step - loss: 0.4416 - acc: 0.8007\n",
            "Epoch 3/30\n",
            "12272/12272 [==============================] - 1s 121us/step - loss: 0.4017 - acc: 0.8269\n",
            "Epoch 4/30\n",
            "12272/12272 [==============================] - 1s 121us/step - loss: 0.3766 - acc: 0.8414\n",
            "Epoch 5/30\n",
            "12272/12272 [==============================] - 1s 120us/step - loss: 0.3612 - acc: 0.8466\n",
            "Epoch 6/30\n",
            "12272/12272 [==============================] - 1s 120us/step - loss: 0.3525 - acc: 0.8523\n",
            "Epoch 7/30\n",
            "12272/12272 [==============================] - 1s 119us/step - loss: 0.3470 - acc: 0.8544\n",
            "Epoch 8/30\n",
            "12272/12272 [==============================] - 1s 116us/step - loss: 0.3432 - acc: 0.8495\n",
            "Epoch 9/30\n",
            "12272/12272 [==============================] - 1s 117us/step - loss: 0.3375 - acc: 0.8582\n",
            "Epoch 10/30\n",
            "12272/12272 [==============================] - 1s 115us/step - loss: 0.3311 - acc: 0.8595\n",
            "Epoch 11/30\n",
            "12272/12272 [==============================] - 1s 120us/step - loss: 0.3318 - acc: 0.8612\n",
            "Epoch 12/30\n",
            "12272/12272 [==============================] - 1s 119us/step - loss: 0.3279 - acc: 0.8604\n",
            "Epoch 13/30\n",
            "12272/12272 [==============================] - 1s 119us/step - loss: 0.3251 - acc: 0.8622\n",
            "Epoch 14/30\n",
            "12272/12272 [==============================] - 2s 130us/step - loss: 0.3190 - acc: 0.8625\n",
            "Epoch 15/30\n",
            "12272/12272 [==============================] - 2s 127us/step - loss: 0.3155 - acc: 0.8646\n",
            "Epoch 16/30\n",
            "12272/12272 [==============================] - 2s 131us/step - loss: 0.3126 - acc: 0.8660\n",
            "Epoch 17/30\n",
            "12272/12272 [==============================] - 2s 128us/step - loss: 0.3085 - acc: 0.8694\n",
            "Epoch 18/30\n",
            "12272/12272 [==============================] - 2s 129us/step - loss: 0.3060 - acc: 0.8699\n",
            "Epoch 19/30\n",
            "12272/12272 [==============================] - 2s 133us/step - loss: 0.3006 - acc: 0.8704\n",
            "Epoch 20/30\n",
            "12272/12272 [==============================] - 2s 125us/step - loss: 0.2960 - acc: 0.8730\n",
            "Epoch 21/30\n",
            "12272/12272 [==============================] - 2s 124us/step - loss: 0.2937 - acc: 0.8745\n",
            "Epoch 22/30\n",
            "12272/12272 [==============================] - 2s 125us/step - loss: 0.2877 - acc: 0.8801\n",
            "Epoch 23/30\n",
            "12272/12272 [==============================] - 1s 121us/step - loss: 0.2835 - acc: 0.8834\n",
            "Epoch 24/30\n",
            "12272/12272 [==============================] - 1s 117us/step - loss: 0.2789 - acc: 0.8853\n",
            "Epoch 25/30\n",
            "12272/12272 [==============================] - 2s 122us/step - loss: 0.2754 - acc: 0.8865\n",
            "Epoch 26/30\n",
            "12272/12272 [==============================] - 2s 123us/step - loss: 0.2697 - acc: 0.8902\n",
            "Epoch 27/30\n",
            "12272/12272 [==============================] - 1s 121us/step - loss: 0.2663 - acc: 0.8915\n",
            "Epoch 28/30\n",
            "12272/12272 [==============================] - 1s 120us/step - loss: 0.2589 - acc: 0.8946\n",
            "Epoch 29/30\n",
            "12272/12272 [==============================] - 1s 119us/step - loss: 0.2543 - acc: 0.8999\n",
            "Epoch 30/30\n",
            "12272/12272 [==============================] - 2s 127us/step - loss: 0.2484 - acc: 0.8999\n",
            "Epoch 1/10\n",
            "15339/15339 [==============================] - 7s 437us/step - loss: 0.5246 - acc: 0.7395\n",
            "Epoch 2/10\n",
            "15339/15339 [==============================] - 2s 116us/step - loss: 0.4294 - acc: 0.8119\n",
            "Epoch 3/10\n",
            "15339/15339 [==============================] - 2s 118us/step - loss: 0.3913 - acc: 0.8343\n",
            "Epoch 4/10\n",
            "15339/15339 [==============================] - 2s 125us/step - loss: 0.3672 - acc: 0.8473\n",
            "Epoch 5/10\n",
            "15339/15339 [==============================] - 2s 127us/step - loss: 0.3552 - acc: 0.8495\n",
            "Epoch 6/10\n",
            "15339/15339 [==============================] - 2s 127us/step - loss: 0.3501 - acc: 0.8513\n",
            "Epoch 7/10\n",
            "15339/15339 [==============================] - 2s 124us/step - loss: 0.3449 - acc: 0.8536\n",
            "Epoch 8/10\n",
            "15339/15339 [==============================] - 2s 124us/step - loss: 0.3401 - acc: 0.8561\n",
            "Epoch 9/10\n",
            "15339/15339 [==============================] - 2s 125us/step - loss: 0.3341 - acc: 0.8575\n",
            "Epoch 10/10\n",
            "15339/15339 [==============================] - 2s 123us/step - loss: 0.3305 - acc: 0.8612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "QvMzIeMpWI9Y",
        "colab_type": "code",
        "outputId": "1288a450-2bd5-4326-c39e-83404cbe1a1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "cell_type": "code",
      "source": [
        "for k in grid_result.cv_results_.keys():\n",
        "    print(k)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean_fit_time\n",
            "std_fit_time\n",
            "mean_score_time\n",
            "std_score_time\n",
            "param_activation\n",
            "param_batch_size\n",
            "param_epochs\n",
            "param_lr\n",
            "param_optimizer\n",
            "params\n",
            "split0_test_accuracy\n",
            "split1_test_accuracy\n",
            "split2_test_accuracy\n",
            "split3_test_accuracy\n",
            "split4_test_accuracy\n",
            "mean_test_accuracy\n",
            "std_test_accuracy\n",
            "rank_test_accuracy\n",
            "split0_train_accuracy\n",
            "split1_train_accuracy\n",
            "split2_train_accuracy\n",
            "split3_train_accuracy\n",
            "split4_train_accuracy\n",
            "mean_train_accuracy\n",
            "std_train_accuracy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "lqZHAE1mWI9i",
        "colab_type": "code",
        "outputId": "2aeb955a-f1ec-470a-fceb-ec8d8c6c2f3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "cell_type": "code",
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_accuracy']\n",
        "stds = grid_result.cv_results_['std_test_accuracy']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.852794 using {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 10, 'lr': 0.001, 'optimizer': 'rmsprop'}\n",
            "0.485886 (0.225661) with: {'activation': 'relu', 'batch_size': 50, 'epochs': 10, 'lr': 0.001, 'optimizer': 'sgd'}\n",
            "0.698546 (0.006008) with: {'activation': 'relu', 'batch_size': 50, 'epochs': 10, 'lr': 0.001, 'optimizer': 'adam'}\n",
            "0.617315 (0.156448) with: {'activation': 'relu', 'batch_size': 50, 'epochs': 10, 'lr': 0.001, 'optimizer': 'rmsprop'}\n",
            "0.460917 (0.191602) with: {'activation': 'relu', 'batch_size': 50, 'epochs': 30, 'lr': 0.001, 'optimizer': 'sgd'}\n",
            "0.695547 (0.000040) with: {'activation': 'relu', 'batch_size': 50, 'epochs': 30, 'lr': 0.001, 'optimizer': 'adam'}\n",
            "0.749527 (0.066187) with: {'activation': 'relu', 'batch_size': 50, 'epochs': 30, 'lr': 0.001, 'optimizer': 'rmsprop'}\n",
            "0.539149 (0.191588) with: {'activation': 'relu', 'batch_size': 100, 'epochs': 10, 'lr': 0.001, 'optimizer': 'sgd'}\n",
            "0.704348 (0.015093) with: {'activation': 'relu', 'batch_size': 100, 'epochs': 10, 'lr': 0.001, 'optimizer': 'adam'}\n",
            "0.652063 (0.180612) with: {'activation': 'relu', 'batch_size': 100, 'epochs': 10, 'lr': 0.001, 'optimizer': 'rmsprop'}\n",
            "0.304453 (0.000040) with: {'activation': 'relu', 'batch_size': 100, 'epochs': 30, 'lr': 0.001, 'optimizer': 'sgd'}\n",
            "0.624943 (0.160695) with: {'activation': 'relu', 'batch_size': 100, 'epochs': 30, 'lr': 0.001, 'optimizer': 'adam'}\n",
            "0.787600 (0.075392) with: {'activation': 'relu', 'batch_size': 100, 'epochs': 30, 'lr': 0.001, 'optimizer': 'rmsprop'}\n",
            "0.694635 (0.001276) with: {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 10, 'lr': 0.001, 'optimizer': 'sgd'}\n",
            "0.846405 (0.005888) with: {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 10, 'lr': 0.001, 'optimizer': 'adam'}\n",
            "0.842297 (0.022250) with: {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 10, 'lr': 0.001, 'optimizer': 'rmsprop'}\n",
            "0.694048 (0.004296) with: {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 30, 'lr': 0.001, 'optimizer': 'sgd'}\n",
            "0.823000 (0.022398) with: {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 30, 'lr': 0.001, 'optimizer': 'adam'}\n",
            "0.838777 (0.009696) with: {'activation': 'sigmoid', 'batch_size': 50, 'epochs': 30, 'lr': 0.001, 'optimizer': 'rmsprop'}\n",
            "0.695547 (0.000040) with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 10, 'lr': 0.001, 'optimizer': 'sgd'}\n",
            "0.839885 (0.009594) with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 10, 'lr': 0.001, 'optimizer': 'adam'}\n",
            "0.852794 (0.007231) with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 10, 'lr': 0.001, 'optimizer': 'rmsprop'}\n",
            "0.693005 (0.002083) with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 30, 'lr': 0.001, 'optimizer': 'sgd'}\n",
            "0.839885 (0.010204) with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 30, 'lr': 0.001, 'optimizer': 'adam'}\n",
            "0.846665 (0.008206) with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 30, 'lr': 0.001, 'optimizer': 'rmsprop'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Wj4JTiuHWI9l",
        "colab_type": "code",
        "outputId": "d53c0a4f-8c1c-4e39-c67b-8c3ea24eb01b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "grid_result.score(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.845913179507235"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "metadata": {
        "id": "z-ykGLmxyeSq",
        "colab_type": "code",
        "outputId": "047d0db4-c149-4459-d7bf-90d5bf2f4215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Keras에는 f1 score가 없으므로 이를 사용하기 위해서 scikit learn을 이용\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "\n",
        "pred = grid_result.predict(X_test)\n",
        "\n",
        "f1_score(y_test, pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.693146417445483"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "metadata": {
        "id": "g9R9rRzN4JRM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "인공신경망망을 훈련 할 때 f1 점수는 분류 모델의 성능을 평가하는 데 중요한 척도이며, 특히 이진 정확도는 불균형 클래스에서 중요하다. Keras에서는 각 배치에서 f1 점수를 평가하기 때문에 2.0버전에서 제거 되었다. \n",
        "f1점수를 사용하기 위해서는 keras의 callback 기능을 활용하여 f1을 구현하여야 한다. \n",
        "callback 은 훈련 중에  데이터에 액세스 할 수 있어서  f1점수를 계산할 수 있다. ."
      ]
    },
    {
      "metadata": {
        "id": "BF5ZA_Gq40LA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# f1 score, recision, recall 구현\n",
        "from keras import backend as K\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "chsHI8DS88bI",
        "colab_type": "code",
        "outputId": "8dfed1f3-5bb6-4651-d59d-76d9d3337bdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "f1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.f1>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "DvuN5StByeVu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 새로운 모형을 만든다\n",
        "def create_model_adj(optimizer, lr, activation):\n",
        "    \n",
        "    model_adj = Sequential()\n",
        "    hl_1 = Dense(nb_units_hl_1, input_dim = nb_inputs)\n",
        "    model_adj.add(hl_1)\n",
        "    hl_1_act = Activation(activation)\n",
        "    model_adj.add(hl_1_act)\n",
        "    ol = Dense(nb_outputs)\n",
        "    model_adj.add(ol)\n",
        "    ol_act = Activation(activation)\n",
        "    model_adj.add(ol_act)\n",
        "    \n",
        "    if optimizer == 'rmsprop':\n",
        "        optim = RMSprop(lr=lr)\n",
        "    if optimizer == 'adam':\n",
        "        optim = Adam(lr=lr)\n",
        "\n",
        "    model_adj.compile(optimizer=optim, loss='binary_crossentropy', metrics=[f1])\n",
        "    \n",
        "    return model_adj"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8FW9P9ikyeZx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_adj = KerasClassifier(build_fn=create_model_adj)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sifF5Htw0977",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#앞서 분석한 최적화 파라메타를 이용\n",
        "\n",
        "optimizers = ['rmsprop']\n",
        "lr = [0.001]\n",
        "#act = ['sigmoid', 'tanh']\n",
        "act = ['sigmoid']\n",
        "\n",
        "epochs = [10]\n",
        "batches = [100]\n",
        "\n",
        "param_grid = dict(optimizer = optimizers, lr=lr, activation=act, epochs=epochs, batch_size=batches)\n",
        "\n",
        "#교차 검증을 위해 k-fold 객체를 생성한다. \n",
        "from sklearn.model_selection import StratifiedKFold \n",
        "kfold = StratifiedKFold(n_splits=5, random_state=20181121)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "siiKnHU_0991",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "grid = GridSearchCV(estimator=model_adj, param_grid=param_grid, scoring=['accuracy'], refit='accuracy', return_train_score=True, cv=kfold, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eH6B0TUE9KlJ",
        "colab_type": "code",
        "outputId": "6ffaf949-0f7b-43f6-d261-38af77c3b57f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "cell_type": "code",
      "source": [
        "grid"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=20181121, shuffle=False),\n",
              "       error_score='raise',\n",
              "       estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f1919de87f0>,\n",
              "       fit_params=None, iid=True, n_jobs=1,\n",
              "       param_grid={'optimizer': ['rmsprop'], 'lr': [0.001], 'activation': ['sigmoid', 'tanh'], 'epochs': [10], 'batch_size': [100]},\n",
              "       pre_dispatch='2*n_jobs', refit='accuracy', return_train_score=True,\n",
              "       scoring=['accuracy'], verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "metadata": {
        "id": "6but94_i6NP0",
        "colab_type": "code",
        "outputId": "3f53b0d3-6969-4d75-d8ba-dc897d17c0fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3977
        }
      },
      "cell_type": "code",
      "source": [
        "grid_result = grid.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 2s 150us/step - loss: 0.5336 - f1: 0.3850\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 107us/step - loss: 0.4387 - f1: 0.5927\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 0.4031 - f1: 0.6614\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 98us/step - loss: 0.3764 - f1: 0.6934\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 0.3617 - f1: 0.7045\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 0.3556 - f1: 0.7099\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 0.3485 - f1: 0.7103\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 98us/step - loss: 0.3449 - f1: 0.7132\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 98us/step - loss: 0.3398 - f1: 0.7116\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 0.3343 - f1: 0.7203\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 1s 108us/step - loss: 0.5340 - f1: 0.3732\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 0.4381 - f1: 0.5881\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 0.3967 - f1: 0.6690\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 0.3738 - f1: 0.6967\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 99us/step - loss: 0.3605 - f1: 0.7079\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 0.3539 - f1: 0.7087\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 0.3452 - f1: 0.7131\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 0.3426 - f1: 0.7170\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 0.3374 - f1: 0.7136\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 0.3329 - f1: 0.7261\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 1s 114us/step - loss: 0.5341 - f1: 0.3588\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 0.4491 - f1: 0.5743\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 0.4024 - f1: 0.6611\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 0.3820 - f1: 0.6838\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 0.3699 - f1: 0.6945\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 98us/step - loss: 0.3604 - f1: 0.7020\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 0.3539 - f1: 0.7082\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 0.3461 - f1: 0.7035\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 0.3446 - f1: 0.7109\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 0.3388 - f1: 0.7110\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 1s 114us/step - loss: 0.5331 - f1: 0.3717\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 0.4435 - f1: 0.5896\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 0.4012 - f1: 0.6659\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 0.3755 - f1: 0.6931\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 0.3649 - f1: 0.7073\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 104us/step - loss: 0.3565 - f1: 0.7051\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 107us/step - loss: 0.3484 - f1: 0.7124\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 106us/step - loss: 0.3448 - f1: 0.7098\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 105us/step - loss: 0.3408 - f1: 0.7137\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 107us/step - loss: 0.3358 - f1: 0.7189\n",
            "Epoch 1/10\n",
            "12272/12272 [==============================] - 2s 133us/step - loss: 0.5311 - f1: 0.3833\n",
            "Epoch 2/10\n",
            "12272/12272 [==============================] - 1s 106us/step - loss: 0.4384 - f1: 0.6063\n",
            "Epoch 3/10\n",
            "12272/12272 [==============================] - 1s 99us/step - loss: 0.3984 - f1: 0.6634\n",
            "Epoch 4/10\n",
            "12272/12272 [==============================] - 1s 95us/step - loss: 0.3758 - f1: 0.6971\n",
            "Epoch 5/10\n",
            "12272/12272 [==============================] - 1s 96us/step - loss: 0.3643 - f1: 0.7020\n",
            "Epoch 6/10\n",
            "12272/12272 [==============================] - 1s 95us/step - loss: 0.3564 - f1: 0.7086\n",
            "Epoch 7/10\n",
            "12272/12272 [==============================] - 1s 96us/step - loss: 0.3502 - f1: 0.7134\n",
            "Epoch 8/10\n",
            "12272/12272 [==============================] - 1s 98us/step - loss: 0.3452 - f1: 0.7185\n",
            "Epoch 9/10\n",
            "12272/12272 [==============================] - 1s 96us/step - loss: 0.3368 - f1: 0.7206\n",
            "Epoch 10/10\n",
            "12272/12272 [==============================] - 1s 96us/step - loss: 0.3349 - f1: 0.7159\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 1s 121us/step - loss: 4.9121 - f1: 0.0030\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 4.9010 - f1: 0.0022\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 4.9060 - f1: 5.0933e-04\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 4.8849 - f1: 0.0062\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 4.9064 - f1: 5.0933e-04\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 4.9060 - f1: 5.4329e-04\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 4.9060 - f1: 4.9390e-04\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 4.9060 - f1: 5.0933e-04\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 4.9060 - f1: 5.6202e-04\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 4.9060 - f1: 4.9390e-04\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 2s 127us/step - loss: 4.8098 - f1: 0.0365\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 4.8911 - f1: 0.0047\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 4.8352 - f1: 0.0193\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 4.8479 - f1: 0.0191\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 3.2467 - f1: 0.3526\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 1.3308 - f1: 0.5693\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 0.7349 - f1: 0.6088\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 0.6250 - f1: 0.6585\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 0.5729 - f1: 0.6611\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 0.5773 - f1: 0.6757\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 2s 132us/step - loss: 4.8144 - f1: 0.0264\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 4.9073 - f1: 0.0000e+00\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 94us/step - loss: 4.9073 - f1: 0.0000e+00\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 4.9073 - f1: 0.0000e+00\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 4.9073 - f1: 0.0000e+00\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 4.9073 - f1: 0.0000e+00\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 4.9073 - f1: 0.0000e+00\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 4.9073 - f1: 0.0000e+00\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 95us/step - loss: 4.9073 - f1: 0.0000e+00\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 4.9073 - f1: 0.0000e+00\n",
            "Epoch 1/10\n",
            "12271/12271 [==============================] - 2s 131us/step - loss: 4.8114 - f1: 0.0318\n",
            "Epoch 2/10\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 4.6182 - f1: 0.0844\n",
            "Epoch 3/10\n",
            "12271/12271 [==============================] - 1s 90us/step - loss: 1.9510 - f1: 0.4894\n",
            "Epoch 4/10\n",
            "12271/12271 [==============================] - 1s 90us/step - loss: 0.7521 - f1: 0.5765\n",
            "Epoch 5/10\n",
            "12271/12271 [==============================] - 1s 91us/step - loss: 0.6043 - f1: 0.6169\n",
            "Epoch 6/10\n",
            "12271/12271 [==============================] - 1s 93us/step - loss: 0.5887 - f1: 0.6602\n",
            "Epoch 7/10\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 0.5655 - f1: 0.6827\n",
            "Epoch 8/10\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 0.5721 - f1: 0.6765\n",
            "Epoch 9/10\n",
            "12271/12271 [==============================] - 1s 96us/step - loss: 0.5270 - f1: 0.7012\n",
            "Epoch 10/10\n",
            "12271/12271 [==============================] - 1s 97us/step - loss: 0.5477 - f1: 0.6962\n",
            "Epoch 1/10\n",
            "12272/12272 [==============================] - 2s 135us/step - loss: 4.8992 - f1: 0.0014\n",
            "Epoch 2/10\n",
            "12272/12272 [==============================] - 1s 96us/step - loss: 4.9056 - f1: 4.5270e-04\n",
            "Epoch 3/10\n",
            "12272/12272 [==============================] - 1s 96us/step - loss: 4.8760 - f1: 0.0068\n",
            "Epoch 4/10\n",
            "12272/12272 [==============================] - 1s 99us/step - loss: 4.9018 - f1: 0.0021\n",
            "Epoch 5/10\n",
            "12272/12272 [==============================] - 1s 97us/step - loss: 4.8936 - f1: 0.0038\n",
            "Epoch 6/10\n",
            "12272/12272 [==============================] - 1s 98us/step - loss: 4.7025 - f1: 0.0596\n",
            "Epoch 7/10\n",
            "12272/12272 [==============================] - 1s 98us/step - loss: 4.1466 - f1: 0.1758\n",
            "Epoch 8/10\n",
            "12272/12272 [==============================] - 1s 97us/step - loss: 1.5328 - f1: 0.5163\n",
            "Epoch 9/10\n",
            "12272/12272 [==============================] - 1s 97us/step - loss: 0.6230 - f1: 0.5962\n",
            "Epoch 10/10\n",
            "12272/12272 [==============================] - 1s 98us/step - loss: 0.5660 - f1: 0.6501\n",
            "Epoch 1/10\n",
            "15339/15339 [==============================] - 2s 144us/step - loss: 0.5201 - f1: 0.4164\n",
            "Epoch 2/10\n",
            "15339/15339 [==============================] - 2s 107us/step - loss: 0.4247 - f1: 0.6235\n",
            "Epoch 3/10\n",
            "15339/15339 [==============================] - 2s 106us/step - loss: 0.3850 - f1: 0.6827\n",
            "Epoch 4/10\n",
            "15339/15339 [==============================] - 2s 106us/step - loss: 0.3685 - f1: 0.7005\n",
            "Epoch 5/10\n",
            "15339/15339 [==============================] - 2s 107us/step - loss: 0.3579 - f1: 0.7066\n",
            "Epoch 6/10\n",
            "15339/15339 [==============================] - 2s 109us/step - loss: 0.3487 - f1: 0.7105\n",
            "Epoch 7/10\n",
            "15339/15339 [==============================] - 2s 107us/step - loss: 0.3430 - f1: 0.7103\n",
            "Epoch 8/10\n",
            "15339/15339 [==============================] - 2s 108us/step - loss: 0.3401 - f1: 0.7137\n",
            "Epoch 9/10\n",
            "15339/15339 [==============================] - 2s 108us/step - loss: 0.3346 - f1: 0.7180\n",
            "Epoch 10/10\n",
            "15339/15339 [==============================] - 2s 108us/step - loss: 0.3302 - f1: 0.7220\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fBEgFQiP-s6-",
        "colab_type": "code",
        "outputId": "e9ebd875-7974-4b71-b25d-49d576b06655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_accuracy']\n",
        "stds = grid_result.cv_results_['std_test_accuracy']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.847057 using {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 10, 'lr': 0.001, 'optimizer': 'rmsprop'}\n",
            "0.847057 (0.008710) with: {'activation': 'sigmoid', 'batch_size': 100, 'epochs': 10, 'lr': 0.001, 'optimizer': 'rmsprop'}\n",
            "0.706761 (0.133038) with: {'activation': 'tanh', 'batch_size': 100, 'epochs': 10, 'lr': 0.001, 'optimizer': 'rmsprop'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k_aKXp0j9zPT",
        "colab_type": "code",
        "outputId": "04f795e9-e2fa-4c87-d4cc-cf098cf18788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Keras에는 f1 score가 없으므로 이를 사용하기 위해서 scikit learn을 이용\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "\n",
        "pred = grid_result.predict(X_test)\n",
        "\n",
        "f1_score(y_test, pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6906187624750499"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "52W9n-A_y2dy",
        "colab_type": "code",
        "outputId": "70f0680d-1294-4863-f7e9-e4d0133cfc32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion = confusion_matrix(y_test, pred)\n",
        "print(\"오차 행렬:\\n{}\".format(confusion))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "오차 행렬:\n",
            "[[3474  130]\n",
            " [ 645  865]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cvi26TEV0Nia",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install mglearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-95aAZXIzMiw",
        "colab_type": "code",
        "outputId": "be0215c1-bf5a-4666-9304-143a6757fd1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "cell_type": "code",
      "source": [
        "import mglearn\n",
        "import matplotlib.pyplot as plt\n",
        "class_names = [0,1]\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.text(0.40, .7, confusion[0, 0], size=70, horizontalalignment='right')\n",
        "plt.text(0.40, .2, confusion[1, 0], size=70, horizontalalignment='right')\n",
        "plt.text(.90, .7, confusion[0, 1], size=70, horizontalalignment='right')\n",
        "plt.text(.90, 0.2, confusion[1, 1], size=70, horizontalalignment='right')\n",
        "plt.xticks([.25, .75], [\"predicted '0'\", \"predicted '1'\"], size=20)\n",
        "plt.yticks([.25, .75], [\"true '1'\", \"true '0'\"], size=20)\n",
        "plt.plot([.5, .5], [0, 1], '--', c='k')\n",
        "plt.plot([0, 1], [.5, .5], '--', c='k')\n",
        "\n",
        "plt.xlim(0, 1)\n",
        "plt.ylim(0, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg4AAAHbCAYAAACjoBI4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f190dbc3c18>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "8oSqGWRV26zU",
        "colab_type": "code",
        "outputId": "f9fb7944-7e81-41c6-88b6-89f79c0c9379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(confusion, annot=True, fmt=\"d\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f190dd1c6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAccAAAFKCAYAAABo0pS0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwOb/AZ3Ys7aV+N0XAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1929b905c0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "XOpezAGP3n3Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qt5sSRzwWI9o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 결론\n",
        "---\n",
        "히든층이 1개인 기본 모형에서 f1 점수가 0.68로 개선이 필요하다.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "YOu81aE6WI9o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ulvj5QsT39nq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3I-Lt8uJ4LNM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 다층 퍼셉트론(MLP)로 구현 \n",
        "-----\n",
        "    scikit learn의 MLPClassifier을 이용"
      ]
    },
    {
      "metadata": {
        "id": "RlmTGT7h39sL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "nb_hl= (100, 3)\n",
        "\n",
        "##MLP parameter을 dict 로 저장\n",
        "\n",
        "param_grid_dict = {'solver':['lbfgs', 'adam'], 'activation':['logistic'], 'learning_rate_init':[0.01, 0.001],\n",
        "                   'hidden_layer_sizes':(100, 2), 'random_state':[20181121]}\n",
        "\n",
        "\n",
        "grid = GridSearchCV(MLPClassifier(), param_grid=param_grid_dict, cv=5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HojGHSWE8LVE",
        "colab_type": "code",
        "outputId": "f40296c1-fbe1-4488-f97b-b4de313b340d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1513
        }
      },
      "cell_type": "code",
      "source": [
        "grid_result = grid.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZxmGTFgbCJf9",
        "colab_type": "code",
        "outputId": "4ceaf319-9fd2-4663-fffb-16528f9297a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "grid_result.score(X_test, y_test)\n",
        "grid_result.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'logistic',\n",
              " 'hidden_layer_sizes': 2,\n",
              " 'learning_rate_init': 0.01,\n",
              " 'random_state': 20181121,\n",
              " 'solver': 'adam'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "metadata": {
        "id": "uolH3iwrCIdk",
        "colab_type": "code",
        "outputId": "bb175003-51c0-485e-d46d-21575d5753e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Keras에는 f1 score가 없으므로 이를 사용하기 위해서 scikit learn을 이용\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "\n",
        "pred = grid_result.predict(X_test)\n",
        "\n",
        "f1_score(y_test, pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6766679826292933"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "metadata": {
        "id": "WsZQ2eQsCeHl",
        "colab_type": "code",
        "outputId": "971feea0-de66-4553-edd4-8a6379f0079d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion = confusion_matrix(y_test, pred)\n",
        "print(\"오차 행렬:\\n{}\".format(confusion))\n",
        "\n",
        "import seaborn as sns\n",
        "sns.heatmap(confusion, annot=True, fmt=\"d\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "오차 행렬:\n",
            "[[3438  166]\n",
            " [ 653  857]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f190dd18cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAccAAAFKCAYAAABo0pS0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f190db92d30>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "fs-tijfTCfqM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}